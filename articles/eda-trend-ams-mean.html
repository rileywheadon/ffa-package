<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title> • ffaframework</title>
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Roboto-0.4.10/font.css" rel="stylesheet">
<link href="../deps/JetBrains_Mono-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Roboto_Slab-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ffaframework</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><h6 class="dropdown-header" data-toc-skip>EDA</h6></li>
    <li><a class="dropdown-item" href="../articles/change-points.html">Change Points</a></li>
    <li><a class="dropdown-item" href="../articles/trend-mean.html">Trends in AMS Mean</a></li>
    <li><a class="dropdown-item" href="../articles/trend-variability.html">Trends in AMS Variability</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>FFA</h6></li>
    <li><a class="dropdown-item" href="../articles/stationary-ffa.html">Stationary FFA</a></li>
    <li><a class="dropdown-item" href="../articles/non-stationary-ffa.html">Nonstationary FFA</a></li>
  </ul>
</li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-wiki" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Wiki</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-wiki">
<li><h6 class="dropdown-header" data-toc-skip>EDA</h6></li>
    <li><a class="dropdown-item" href="../articles/eda-introduction.html">Introduction</a></li>
    <li><a class="dropdown-item" href="../articles/eda-change-points.html">Change Points</a></li>
    <li><a class="dropdown-item" href="../articles/eda-trend-ams-mean.html">Trends in AMS Mean</a></li>
    <li><a class="dropdown-item" href="../articles/eda-trend-ams-variability.html">Trends in AMS Variability</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>FFA</h6></li>
    <li><a class="dropdown-item" href="../articles/ffa-introduction.html">Introduction</a></li>
    <li><a class="dropdown-item" href="../articles/ffa-probability-distributions.html">Probability Distributions</a></li>
    <li><a class="dropdown-item" href="../articles/ffa-model-selection.html">Model Selection</a></li>
    <li><a class="dropdown-item" href="../articles/parameter-estimation.html">Parameter Estimation</a></li>
    <li><a class="dropdown-item" href="../articles/ffa-uncertainty-quantification.html">Uncertainty Quantification</a></li>
    <li><a class="dropdown-item" href="../articles/ffa-model-assessment.html">Model Assessment</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../articles/matlab-version.html">MATLAB Version</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/rileywheadon/ffa-package/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1></h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rileywheadon/ffa-package/blob/master/vignettes/articles/eda-trend-ams-mean.Rmd" class="external-link"><code>vignettes/articles/eda-trend-ams-mean.Rmd</code></a></small>
      <div class="d-none name"><code>eda-trend-ams-mean.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="detecting-and-characterizing-trends-in-the-mean">Detecting and Characterizing Trends in the Mean<a class="anchor" aria-label="anchor" href="#detecting-and-characterizing-trends-in-the-mean"></a>
</h2>
<p>This section describes the statistical tests (listed in alphabetical
order) used to detect and characterize significant trends in the mean of
the annual maximum series. These tests help identify a trend, identify
autocorrelation, and determine whether a trend is
deterministic/stochastic and linear/non-linear.</p>
<hr>
<div class="section level3">
<h3 id="bb-mk-test">BB-MK Test<a class="anchor" aria-label="anchor" href="#bb-mk-test"></a>
</h3>
<p>The <strong>Block Bootstrap Mann-Kendall (BB-MK) Test</strong>
assesses the presence of a statistically significant monotonic trend in
a time series. The BB-MK test is insensitive to <a href="https://en.wikipedia.org/wiki/Autocorrelation" class="external-link">autocorrelation</a>,
which is known to produce false positives in the <a href="#mann-kendall-mk-test">MK test</a>.</p>
<ul>
<li>Null hypothesis: No monotonic trend.</li>
<li>Alternative hypothesis: A monotonic upward or downward trend
exists.</li>
</ul>
<p>To conduct the BB-MK test, we rely on the results of the MK test and
the Spearman autocorrelation test.</p>
<div class="section level4">
<h4 id="steps">Steps<a class="anchor" aria-label="anchor" href="#steps"></a>
</h4>
<ol style="list-style-type: decimal">
<li>Compute the MK test statistic (see below).</li>
<li>Use the Spearman test (see below) to identify the least
insignificant lag <span class="math inline">\(k\)</span>.</li>
<li>Resample the time series in blocks of size <span class="math inline">\(k+1\)</span> without replacement.</li>
<li>Compute the MK test statistic for each bootstrapped sample.</li>
<li>Derive the empirical distribution of the MK test statistic from the
bootstrapped statistics.</li>
<li>Estimate the significance of the observed test statistic using the
empirical distribution.</li>
</ol>
</div>
<div class="section level4">
<h4 id="example-plot">Example Plot<a class="anchor" aria-label="anchor" href="#example-plot"></a>
</h4>
<p><img src="../reference/figures/plot-bbmk.svg"></p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="kpss-test">KPSS Test<a class="anchor" aria-label="anchor" href="#kpss-test"></a>
</h3>
<p>The <strong>KPSS Test</strong> determines whether an autoregressive
time series has a <a href="https://en.wikipedia.org/wiki/Unit_root" class="external-link">unit
root</a>. This test helps assess if the time series has a deterministic
linear trend.</p>
<ul>
<li>Null hypothesis: The time series has a deterministic linear
trend.</li>
<li>Alternative hypothesis: The time series has a unit root (stochastic
trend).</li>
</ul>
<p>The autoregressive time series shown below has a unit root if <span class="math inline">\(\sigma_{v}^2 &gt; 0\)</span>:</p>
<p><span class="math display">\[
\begin{align}
y_{t} &amp;= \mu_{t} + \beta t +  \epsilon_{t} \\[5pt]
\mu_{t} &amp;= \mu_{t-1} + v_{t} \\[5pt]
v_{t} &amp;\sim \mathcal{N}(0, \sigma_{v}^2)
\end{align}
\]</span></p>
<p>where:</p>
<ul>
<li>
<span class="math inline">\(\mu_{t}\)</span> is the <em>drift</em>,
or the deviation of <span class="math inline">\(y_{t}\)</span> from
<span class="math inline">\(0\)</span>. Under the null hypothesis, <span class="math inline">\(\mu_{t}\)</span> is constant (since <span class="math inline">\(v_{t}\)</span> is constant). Under the alternative
hypothesis, <span class="math inline">\(\mu_t\)</span> is a stochastic
process with a unit root.</li>
<li>
<span class="math inline">\(\beta t\)</span> is a <em>linear
trend</em>, which represents deterministic nonstationarity (e.g.,
climate change).</li>
<li>
<span class="math inline">\(\epsilon_{t}\)</span> is <em>stationary
noise</em>, corresponding to reversible fluctuations in <span class="math inline">\(y_{t}\)</span>. In hydrology, <span class="math inline">\(\epsilon_{t}\)</span> represents fluctuations in
streamflow due to natural variability.</li>
<li>
<span class="math inline">\(v_{t}\)</span> is <em>random walk
innovation</em>, or irreversible fluctuations in <span class="math inline">\(\mu_{t}\)</span>.</li>
</ul>
<div class="section level4">
<h4 id="steps-1">Steps<a class="anchor" aria-label="anchor" href="#steps-1"></a>
</h4>
<ol style="list-style-type: decimal">
<li><p>Fit a linear model to <span class="math inline">\(y_{t}\)</span>
and get the residuals <span class="math inline">\(\hat{r}_{t}\)</span>.</p></li>
<li>
<p>Compute the cumulative partial-sum statistics <span class="math inline">\(S_{k}\)</span> using the following formula:</p>
<p><span class="math display">\[
S_{k} = \sum_{t=1}^{k} \hat{r}_{t}
\]</span></p>
<p>Under the null hypothesis, <span class="math inline">\(S_{k}\)</span>
will behave like a random walk with finite variance.</p>
<p>If <span class="math inline">\(y_{t}\)</span> has a unit root, then
the sums will “drift” too much.</p>
</li>
<li>
<p>Estimate the long-run variance of the time series using a <a href="https://en.wikipedia.org/wiki/Newey%E2%80%93West_estimator" class="external-link">Newey-West
estimator</a>:</p>
<p><span class="math display">\[
\hat{\lambda}^2 = \hat{\gamma}_0 + 2 \sum_{j=1}^{q} \left(1 -
\frac{j}{q+1} \right) \hat{\gamma}_j
\]</span></p>
<p>Where <span class="math inline">\(q = \left\lfloor
\frac{3\sqrt{n}}{13} \right\rfloor\)</span> and each autocovariance
<span class="math inline">\(\hat{\gamma}_j\)</span> is:</p>
<p><span class="math display">\[
\hat{\gamma}_j = \frac{1}{n} \sum_{t = j+1}^{n} \hat{r}_t \hat{r}_{t-j}
\]</span></p>
</li>
<li>
<p>Compute the test statistic <span class="math inline">\(z_{K}\)</span>:</p>
<p><span class="math display">\[
z_{K} = \frac{1}{n^2\hat{\lambda }^2}\sum_{k=1}^{n}  S_{k}^2
\]</span></p>
</li>
<li><p>Since the test statistic <span class="math inline">\(z_{K}\)</span> is non-normally distributed, we
compute the p-value by interpolating the table of quantiles from <a href="https://doi.org/10.1111/j.1467-9574.2004.00272.x" class="external-link">Hobijn et
al. (2004)</a> shown below.</p></li>
</ol>
<table class="table">
<thead><tr class="header">
<th><span class="math inline">\(q\)</span></th>
<th>0.90</th>
<th>0.95</th>
<th>0.975</th>
<th>0.99</th>
</tr></thead>
<tbody><tr class="odd">
<td>Statistic</td>
<td>0.119</td>
<td>0.146</td>
<td>0.176</td>
<td>0.216</td>
</tr></tbody>
</table>
<p><strong>Warning</strong>: The interpolation only works for <span class="math inline">\(0.01 &lt; p &lt; 0.10\)</span> (p-values below
<span class="math inline">\(0.01\)</span> and above <span class="math inline">\(0.10\)</span> will be truncated) and significance
levels <span class="math inline">\(\alpha\)</span> between <span class="math inline">\(0.01\)</span> and <span class="math inline">\(0.10\)</span>.</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="mann-kendall-mk-test">Mann-Kendall (MK) Test<a class="anchor" aria-label="anchor" href="#mann-kendall-mk-test"></a>
</h3>
<p>The <strong>Mann-Kendall (MK) Test</strong> detects statistically
significant monotonic trends in a time series under the assumption of
independence (i.e. no autocorrelation).</p>
<ul>
<li>Null hypothesis: There is no monotonic trend.</li>
<li>Alternative hypothesis: A (upward or downward) monotonic trend
exists.</li>
</ul>
<p>Define <span class="math inline">\(\text{sign} (x)\)</span> to be
<span class="math inline">\(1\)</span> if <span class="math inline">\(x
&gt; 0\)</span>, <span class="math inline">\(0\)</span> if <span class="math inline">\(x = 0\)</span>, and <span class="math inline">\(-1\)</span> otherwise.</p>
<p>The test statistic <span class="math inline">\(S\)</span> is defined
as follows:</p>
<p><span class="math display">\[
S = \sum_{k-1}^{n-1}  \sum_{j - k + 1}^{n} \text{sign} (y_{j} - y_{k})
\]</span></p>
<p>Next, we need to compute <span class="math inline">\(\text{Var}(S)\)</span>, which depends on the
number of tied groups in the data. Let <span class="math inline">\(g\)</span> be the number of tied groups and <span class="math inline">\(t_{p}\)</span> be the number of observations in
the <span class="math inline">\(p\)</span>-th group.</p>
<p><span class="math display">\[\text{Var}(S) = \frac{1}{18}
\left[n(n-1)(2n + 1) - \sum_{p-1}^{g} t_{p}(t_{p} - 1)(2t_{p} + 5)
\right]\]</span></p>
<p>Then, compute the normally distributed test statistic <span class="math inline">\(Z_{MK}\)</span> as follows:</p>
<p><span class="math display">\[
Z_{MK} = \begin{cases}
\frac{S-1}{\sqrt{\text{Var}(S)}} &amp;\text{if } S &gt; 0 \\
0 &amp;\text{if }  S = 0 \\
\frac{S+1}{\sqrt{\text{Var}(S)}} &amp;\text{if } S &lt; 0
\end{cases}
\]</span></p>
<p>For a two-sided test, we reject the null hypothesis if <span class="math inline">\(|Z_{MK}| \geq Z_{1 - (\alpha/2) }\)</span> and
conclude that there is a statistically significant monotonic trend in
the data. For more information, see <a href="https://vsp.pnnl.gov/help/vsample/design_trend_mann_kendall.htm" class="external-link">here</a>.</p>
<hr>
</div>
<div class="section level3">
<h3 id="phillips-perron-pp-test">Phillips-Perron (PP) Test<a class="anchor" aria-label="anchor" href="#phillips-perron-pp-test"></a>
</h3>
<p>The <strong>PP Test</strong> identifies if an autoregressive time
series has a <a href="https://en.wikipedia.org/wiki/Unit_root" class="external-link">unit
root</a>.</p>
<ul>
<li>Null hypothesis: The time series has a unit root (stochastic
trend).</li>
<li>Alternative hypothesis: The time series has a deterministic linear
trend.</li>
</ul>
<p>Precisely, let <span class="math inline">\(x_{t}\)</span> be an <a href="https://en.wikipedia.org/wiki/Autoregressive_model" class="external-link">AR(1)</a>
model. Let <span class="math inline">\(y_{t}\)</span> be a function of
<span class="math inline">\(x_{t}\)</span> with drift <span class="math inline">\(\beta_{0}\)</span> and trend <span class="math inline">\(\beta_{1} t\)</span>.</p>
<p><span class="math display">\[
\begin{align}
y_{t} &amp;= \beta_{0} + \beta_{1} t + x_{t} \\[5pt]
x_{t} &amp;= \rho x_{t-1} + \epsilon_{t}
\end{align}
\]</span></p>
<ul>
<li>If <span class="math inline">\(\rho = 1\)</span>, then <span class="math inline">\(x_t\)</span> and hence <span class="math inline">\(y_t\)</span> has a <em>unit root</em> (null
hypothesis).</li>
<li>If <span class="math inline">\(\rho &lt; 1\)</span>, then <span class="math inline">\(y_t\)</span> is <em>trend stationary</em>
(alternative hypothesis).</li>
</ul>
<div class="section level4">
<h4 id="steps-2">Steps<a class="anchor" aria-label="anchor" href="#steps-2"></a>
</h4>
<ol style="list-style-type: decimal">
<li><p>Fit a linear autoregressive model to the time series <span class="math inline">\(y_{t}\)</span>. Let <span class="math inline">\(\hat{r}_{t}\)</span> be the residuals of this
model. From this model, we can determine <span class="math inline">\(\hat{\rho}\)</span> (the estimated coefficient on
<span class="math inline">\(y_{t-1}\)</span>) and <span class="math inline">\(\text{SE}(\hat{\rho})\)</span>.</p></li>
<li>
<p>Estimate the variance of the residuals <span class="math inline">\(\hat{\sigma}^2\)</span>:</p>
<p><span class="math display">\[
\hat{\sigma^2} = \frac{1}{n - 3} \sum_{t=1}^{n} \hat{r}_{t}^2
\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of data
points in the sample. We have <span class="math inline">\(n-3\)</span>
degrees of freedom since there are three parameters in the
autoregressive model (<span class="math inline">\(\beta_{0}\)</span>,
<span class="math inline">\(\beta_{1}\)</span>, and <span class="math inline">\(\rho\)</span>).</p>
</li>
<li>
<p>Estimate the long-run variance <span class="math inline">\(\hat{\lambda}^2\)</span> using a <a href="https://en.wikipedia.org/wiki/Newey%E2%80%93West_estimator" class="external-link">Newey-West</a>
style estimator. This estimator corrects for the additional variability
in <span class="math inline">\(\epsilon_{t}\)</span> caused by
autocorrelation and heteroskedasticity.</p>
<p><span class="math display">\[
\hat{\lambda}^2 = \hat{\gamma}_{0} + 2\sum_{j=1}^{q} \left(1 -
\frac{j}{q + 1} \right)  \gamma_{j}
\]</span></p>
<p>Each sample autocovariances <span class="math inline">\(\gamma_{j}\)</span> above is computed for up to
<span class="math inline">\(q = \left\lfloor
\sqrt[4]{\frac{n}{25}}\right\rfloor\)</span> lags:</p>
<p><span class="math display">\[
\hat{\gamma}_{j} = \frac{1}{n} \sum_{t = j + 1}^{n}
\hat{r}_{t}\hat{r}_{t-j}
\]</span></p>
</li>
<li>
<p>Compute the test statistic <span class="math inline">\(z_{\rho}\)</span> using the following formula:</p>
<p><span class="math display">\[
z_{\rho } = n(\hat{\rho} - 1) - \frac{n^2 \text{SE}(\hat{\rho})^2}{2
\hat{\sigma}^2}(\hat{\lambda }^2 - \hat{\gamma}_{0})
\]</span></p>
</li>
</ol>
<p>The test statistic <span class="math inline">\(z_{\rho}\)</span> is
not normally distributed. Instead, we compute the p-value by
interpolating a table from Fuller, W. A. (1996). This table is shown
below for sample sizes <span class="math inline">\(n\)</span> and
probabilities <span class="math inline">\(p\)</span>:</p>
<table style="width:100%;" class="table">
<colgroup>
<col width="16%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
<col width="9%">
</colgroup>
<thead><tr class="header">
<th>
<span class="math inline">\(n\)</span>  <span class="math inline">\(p\)</span>
</th>
<th>0.01</th>
<th>0.025</th>
<th>0.05</th>
<th>0.10</th>
<th>0.50</th>
<th>0.90</th>
<th>0.95</th>
<th>0.975</th>
<th>0.99</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>25</td>
<td>-22.5</td>
<td>-20.0</td>
<td>-17.9</td>
<td>-15.6</td>
<td>-8.49</td>
<td>-3.65</td>
<td>-2.51</td>
<td>-1.53</td>
<td>-0.46</td>
</tr>
<tr class="even">
<td>50</td>
<td>-25.8</td>
<td>-22.4</td>
<td>-19.7</td>
<td>-16.8</td>
<td>-8.80</td>
<td>-3.71</td>
<td>-2.60</td>
<td>-1.67</td>
<td>-0.67</td>
</tr>
<tr class="odd">
<td>100</td>
<td>-27.4</td>
<td>-23.7</td>
<td>-20.6</td>
<td>-17.5</td>
<td>-8.96</td>
<td>-3.74</td>
<td>-2.63</td>
<td>-1.74</td>
<td>-0.76</td>
</tr>
<tr class="even">
<td>250</td>
<td>-28.5</td>
<td>-24.4</td>
<td>-21.3</td>
<td>-17.9</td>
<td>-9.05</td>
<td>-3.76</td>
<td>-2.65</td>
<td>-1.79</td>
<td>-0.83</td>
</tr>
<tr class="odd">
<td>500</td>
<td>-28.9</td>
<td>-24.7</td>
<td>-21.5</td>
<td>-18.1</td>
<td>-9.08</td>
<td>-3.76</td>
<td>-2.66</td>
<td>-1.80</td>
<td>-0.86</td>
</tr>
<tr class="even">
<td>1000</td>
<td>-29.4</td>
<td>-25.0</td>
<td>-21.7</td>
<td>-18.3</td>
<td>-9.11</td>
<td>-3.77</td>
<td>-2.67</td>
<td>-1.81</td>
<td>-0.88</td>
</tr>
</tbody>
</table>
<p><strong>Warning</strong>: The interpolation only works for p-values
<span class="math inline">\(p &gt; 0.01\)</span> (p-values below <span class="math inline">\(0.01\)</span> are truncated) and confidence levels
<span class="math inline">\(\alpha &gt; 0.01\)</span>.</p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="runs-test">Runs Test<a class="anchor" aria-label="anchor" href="#runs-test"></a>
</h3>
<p>The <strong>Runs Test</strong> checks whether the residuals of a
regression (e.g., trend approximation from <a href="#sens-trend-estimator">Sen’s estimator</a>) are randomly
distributed. If the Runs test identifies non-randomness in the
residuals, it is a strong indication that the nonstationarity in the
data is non-linear.</p>
<ul>
<li>Null hypothesis: Residuals are distributed randomly.</li>
<li>Alternative hypothesis: Residuals <em>are not</em> distributed
randomly (e.g., due to nonlinearity).</li>
</ul>
<div class="section level4">
<h4 id="steps-3">Steps<a class="anchor" aria-label="anchor" href="#steps-3"></a>
</h4>
<ol style="list-style-type: decimal">
<li><p>Classify the data based on whether it is above (<span class="math inline">\(+\)</span>) or below <span class="math inline">\((-)\)</span> the median. All data points that are
equal to the median are removed.</p></li>
<li><p>Compute the number of contiguous blocks of <span class="math inline">\(+\)</span> or <span class="math inline">\(-\)</span> (known as <em>runs</em>) in the data.
For example, the sequence <span class="math inline">\(+++--+++-+-\)</span> has six runs with length
<span class="math inline">\((3, 2, 3, 1, 1, 1)\)</span>.</p></li>
<li>
<p>Let <span class="math inline">\(R\)</span> be the number of runs
in <span class="math inline">\(N\)</span> data points (with category
counts <span class="math inline">\(N_{+}\)</span> and <span class="math inline">\(N_{-}\)</span>). Then, under the null hypothesis,
<span class="math inline">\(R\)</span> is asymptotically normal
with:</p>
<p><span class="math display">\[
\mathbb{E}[R] = \frac{2N_{+}N_{-}}{N} + 1, \quad
\text{Var}(R) = \frac{2N_{+}N_{-}(2N_{+}N_{-} - N)}{N^2(N - 1)}
\]</span></p>
</li>
<li><p>Compute the p-value by normalizing <span class="math inline">\(R\)</span> using the expectation and variance
given above.</p></li>
</ol>
</div>
<div class="section level4">
<h4 id="example-plot-1">Example Plot<a class="anchor" aria-label="anchor" href="#example-plot-1"></a>
</h4>
<p><img src="../reference/figures/plot-runs.svg"></p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="sens-trend-estimator">Sen’s Trend Estimator<a class="anchor" aria-label="anchor" href="#sens-trend-estimator"></a>
</h3>
<p><strong>Sen’s Trend Estimator</strong> approximates the slope of a
regression line. Unlike <a href="https://en.wikipedia.org/wiki/Least_squares" class="external-link">Least Squares</a>,
Sen’s trend estimator uses a non-parametric approach which makes it
robust to outliers.</p>
<div class="section level4">
<h4 id="steps-4">Steps<a class="anchor" aria-label="anchor" href="#steps-4"></a>
</h4>
<ol style="list-style-type: decimal">
<li>
<p>For all pairs <span class="math inline">\((x_i, y_i)\)</span> and
<span class="math inline">\((x_j, y_j)\)</span> where <span class="math inline">\(x_i \neq x_j\)</span>, compute slopes:</p>
<p><span class="math display">\[
m_{ij} = \frac{y_j - y_i}{x_j - x_i}
\]</span></p>
</li>
<li><p>Take the median of all slopes: <span class="math inline">\(\hat{m}\)</span>.</p></li>
<li><p>Estimate the <span class="math inline">\(y\)</span>-intercept
<span class="math inline">\(\hat{b}\)</span> as the median of <span class="math inline">\(y_{i} - \hat{m}x_{i}\)</span> for all <span class="math inline">\(i\)</span>.</p></li>
</ol>
</div>
<div class="section level4">
<h4 id="example-plot-2">Example Plot<a class="anchor" aria-label="anchor" href="#example-plot-2"></a>
</h4>
<p><img src="../reference/figures/plot-sens.svg"></p>
<hr>
</div>
</div>
<div class="section level3">
<h3 id="spearman-test">Spearman Test<a class="anchor" aria-label="anchor" href="#spearman-test"></a>
</h3>
<p>The <strong>Spearman test</strong> identifies autocorrelation in a
time series <span class="math inline">\(y_{t}\)</span>. A
<em>significant lag</em> is a number <span class="math inline">\(i\)</span> such that the correlation between <span class="math inline">\(y_{t}\)</span> and <span class="math inline">\(y_{t-i}\)</span> is statistically significant. The
<em>least insignificant lag</em> is the smallest <span class="math inline">\(i\)</span> that is <em>not</em> a significant
lag.</p>
<ul>
<li>Null hypothesis: The least insignificant lag is <span class="math inline">\(1\)</span>.</li>
<li>Alternative hypothesis: The least insignificant lag is greater than
<span class="math inline">\(1\)</span>.</li>
</ul>
<p>To carry out the Spearman test, we use the following procedure:</p>
<ol style="list-style-type: decimal">
<li>Compute Spearman’s correlation coefficient <span class="math inline">\(\rho_{i}\)</span> for <span class="math inline">\(y_{t}\)</span> and <span class="math inline">\(y_{t-i}\)</span> for all <span class="math inline">\(0 \leq  i &lt;  n\)</span>.</li>
<li>Compute the <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_{i}\)</span> for each correlation coefficient
<span class="math inline">\(\rho _{i}\)</span> using the formula: <span class="math display">\[
t_{i}= \rho_{i} \sqrt{\frac{n-2}{1 - \rho _{i}^2}}
\]</span> The test statistic <span class="math inline">\(t_{i}\)</span>
has the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom.</li>
<li>Find the smallest <span class="math inline">\(i\)</span> such that
<span class="math inline">\(p_{i} &gt; \alpha\)</span>. Then <span class="math inline">\(i\)</span> is the least insignificant lag at
confidence level <span class="math inline">\(\alpha\)</span>.</li>
</ol>
<p>For more information, see the Wikipedia pages on <a href="https://en.wikipedia.org/wiki/Autocorrelation" class="external-link">Autocorrelation</a>
and <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" class="external-link">Spearman’s
Rho</a>.</p>
<div class="section level4">
<h4 id="example-plot-3">Example Plot<a class="anchor" aria-label="anchor" href="#example-plot-3"></a>
</h4>
<p><img src="../reference/figures/plot-spearman.svg"></p>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Riley Wheadon, Cuauhtémoc Vidrio-Sahagún, Alain Pietroniro, Jianxun He.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
