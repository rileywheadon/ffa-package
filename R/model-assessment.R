#' Evaluate Goodness-of-Fit for Fitted Flood Models
#'
#' Computes multiple performance metrics and diagnostic indicators to assess the quality of
#' a fitted flood frequency model This includes residual statistics, information criteria,
#' and coverage-based metrics using bootstrapped confidence intervals.
#'
#' @param data Numeric; a vector of annual maximum streamflow data.
#'
#' @param years Numeric; a vector of years with the same length as `data`.
#'
#' @param model Character; string specifying the probability model. The first three 
#'   letters denote the family: `GUM`, `NOR`, `LNO`, `GEV`, `GLO`, `GNO`, `PE3`, 
#'   `LP3`, or `WEI`. A trailing signature of `10` or `100` indicates a linear trend 
#'   in location; `11` or `110` indicates linear trends in both location and scale.
#'
#' @param params Numeric; a vector of fitted model parameters generated by
#'   \link{pelxxx} or \link{mle.estimation}.
#'
#' @param uncertainty List; quantiles and confidence intervals
#'   generated by \link{sb.uncertainty} or \link{rfpl.uncertainty}. 
#'
#' @param pp.formula Character (1); string specifying the plotting position formula. 
#'   One of `"Weibull"`, `"Blom"`, `"Cunnane"`, `"Gringorten"`, or `"Hazen"`
#'   (default is "Weibull").
#'
#' @param alpha Numeric (1); the significance level (default is 0.05).
#'
#' @return List; model assessment metrics:
#' - `estimates`: Quantile estimates for empirical return periods.
#' - `R2`: Coefficient of determination from linear regression of estimates vs. data.
#' - `RMSE`: Root mean squared error of quantile estimates.
#' - `Bias`: Mean bias of quantile estimates.
#' - `AIC`: Akaike Information Criterion.
#' - `BIC`: Bayesian Information Criterion.
#' - `AIC_MLL`: Akaike Information Criterion, computed using the maximum log-likelihood.
#' - `BIC_MLL`: Bayesian Information Criterion, computed using the maximum log-likelihood.
#' - `AW`: Average width of the confidence interval(s).
#' - `POC`: Percent of observations covered by the confidence interval(s).
#' - `CWI`: Confidence width index, a metric that combines `AW` and `POC`.
#'
#' @seealso \link{sb.uncertainty}, \link{rfpl.uncertainty}, 
#'   \link[stats]{lm}, \link[stats]{approx}
#'
#' @examples 
#' # Initialize example data, years, and params
#' data <- rnorm(n = 100, mean = 100, sd = 10)
#' years <- seq(from = 1901, to = 2000)
#' params <- c(100, 10)
#'
#' # Perform uncertainty analysis
#' uncertainty <- sb.uncertainty(data, years, "NOR", "L-moments")
#'
#' # Perform model assessment
#' model.assessment(data, years, "NOR", params, uncertainty)
#'
#' @importFrom stats approx
#' @export

model.assessment <- function(
  data,
  years,
  model,
  params,
  uncertainty,
  pp.formula = "Weibull",
  alpha = 0.05
) {

	# Get the name and signature for the model 
	name <- substr(model, 1, 3)
	signature <- if(nchar(model) == 3) NULL else substr(model, 4, 5)

	# Sort the data vector
	n <- length(data)                          
	data_sorted <- data[order(data, decreasing = TRUE)]  

	# Sort the years on the decomposed data (this gets the "true" plotting positions)
	data_decomposed <- ams.decomposition(data, years, signature)
	years_sorted <- years[order(data_decomposed, decreasing = TRUE)]

	# Determine empirical exceedance probabilities using the plotting position 
	p_empirical <- switch(
		pp.formula, 
		Weibull = (1:n) / (n + 1),
		Blom =  ((1:n) - 0.375) / (n + 0.25),
		Cunnane = ((1:n) - 0.4) / (n + 0.2),
		Gringorten = ((1:n) - 0.44) / (n + 0.12),
		Hazen = ((1:n) - 0.5) / n
	)

	t_return <- 1 / p_empirical               

	# Compute the estimates, using the years as a covariate if necessary
	estimates <- sapply(1:n, function(i) {
		covariate <- get.covariates(years_sorted[i])
		qntxxx(name, signature, 1 - p_empirical[i], params, covariate)
	})

	# Run linear regression (stationary models only)
	R2 <- summary(lm(estimates ~ data_sorted))$r.squared
	RMSE <- sqrt(mean((estimates - data_sorted)^2))
	bias <- mean(estimates - data_sorted)

	# Compute the AIC and BIC
	info <- models.info(model)
	AIC <- n * log(RMSE) + (2 * info$n.params)
	BIC <- n * log(RMSE) + (log(n) * info$n.params)

	# Compute the MLL AIC and BIC
	MLL = mle.estimation(data, years, model)$mll
	AIC_MLL = (2 * info$n.params) - (2 * MLL)
	BIC_MLL = (info$n.params * log(n)) - (2 * MLL)

	# Filter t_return and x to indices where t_return is between 2 and 100
	idx <- (t_return > 2 & t_return < 100)
	t_return <- t_return[idx]
	data_sorted <- data_sorted[idx]
		
	# Define w, the width of the confidence interval at each year
	w <- numeric(length(idx))

	# Define covers, the count of data points within the confidence interval
	covers <- 0

	# Interpolate confidence intervals at empirical return periods
	if (nchar(model == 3)) {

		# Use any of the confidence intervals for a stationary model
		uncertainty <- uncertainty[[1]]
		ci_lower <- approx(log(uncertainty$t), uncertainty$ci_lower, log(t_return))
		ci_upper <- approx(log(uncertainty$t), uncertainty$ci_upper, log(t_return))
		w <- ci_upper$y - ci_lower$y
		covers <- sum(data_sorted < ci_upper$y & data_sorted > ci_lower$y)

	} else {

		# Iterate through the confidence intervals for the non-stationary models 
		for (i in 1:length(w)) {

			uncertainty <- uncertainty[[i]]
			ci_lower <- approx(log(uncertainty$t), uncertainty$ci_lower, log(t_return[i]))
			ci_upper <- approx(log(uncertainty$t), uncertainty$ci_upper, log(t_return[i]))
			w[i] <- ci_upper$y - ci_lower$y

			# Add 1 to covers if data point i is within its confidence interval
			if (data_sorted[i] < ci_upper$y & data_sorted[i] > ci_lower$y) {
				covers <- covers + 1
			}
		}
	}

	# Compute the AW, POC, and CWI
	AW <- mean(w)
	POC <- 100 * covers / length(w)
	CWI <- AW * exp((1 - alpha) - (POC / 100))^2

	# Return assessment results in a list
	list(
		estimates = estimates,
		R2 = R2,
		RMSE = RMSE,
		bias = bias,
		AIC = AIC,	
		BIC = BIC,
		AIC_MLL = AIC_MLL,
		BIC_MLL = BIC_MLL,
		AW = AW,
		POC = POC,
		CWI = CWI
	)

}
