#' Evaluate Goodness-of-Fit for Fitted Flood Models
#'
#' Computes multiple performance metrics and diagnostic indicators to assess the 
#' quality of a fitted flood frequency model. This includes accuracy (residual 
#' statistics), fitting efficiency (information criteria), and uncertainty
#' (coverage-based metrics using confidence intervals).
#'
#' @inheritParams param-data
#' @inheritParams param-distribution
#' @inheritParams param-params
#'
#' @param uncertainty List; estimated reutrn levels and confidence intervals
#'   generated by [uncertainty_bootstrap()] or [uncertainty_rfpl()]. 
#'
#' @inheritParams param-years
#' @inheritParams param-structure
#' @inheritParams param-alpha
#'
#' @param pp_formula Character (1); string specifying the plotting position formula. 
#'   Must be one of `"Weibull"`, `"Blom"`, `"Cunnane"`, `"Gringorten"`, or `"Hazen"`
#'
#' @return List containing model assessment metrics:
#' - `data`: The `data` argument.
#' - `estimates`: Quantile estimates for empirical return periods.
#' - `R2`: Coefficient of determination from linear regression of estimates vs. data.
#' - `RMSE`: Root mean squared error of quantile estimates.
#' - `bias`: Mean bias of quantile estimates.
#' - `AIC`: Akaike Information Criterion.
#' - `BIC`: Bayesian Information Criterion.
#' - `AIC_MLL`: Akaike Information Criterion, computed using MLE.
#' - `BIC_MLL`: Bayesian Information Criterion, computed using MLE.
#' - `AW`: Average width of the confidence interval(s).
#' - `POC`: Percent of observations covered by the confidence interval(s).
#' - `CWI`: Confidence width index, a metric that combines `AW` and `POC`.
#'
#' @seealso [uncertainty_bootstrap()], [uncertainty_rfpl()], [fit_maximum_likelihood()]
#'
#' @examples 
#' # Initialize example data and params
#' data <- rnorm(n = 100, mean = 100, sd = 10)
#' params <- c(100, 10)
#'
#' # Perform uncertainty analysis
#' uncertainty <- uncertainty_bootstrap(data, "NOR", "L-moments")
#'
#' # Evaluate model diagnostics
#' model_diagnostics(data, "NOR", params, uncertainty)
#'
#' @importFrom stats approx
#' @export

model_diagnostics <- function(
  data,
  distribution,
  params,
  uncertainty,
  years = NULL,
  structure = NULL,
  alpha = 0.05,
  pp_formula = "Weibull"
) {

	data <- validate_numeric("data", data, optional = FALSE)
	distribution <- validate_enum("distribution", distribution)
	params <- validate_params(distribution, params, structure)
	years <- validate_numeric("years", years, size = length(data))
	structure <- validate_structure(structure)
	pp_formula <- validate_enum("pp_formula", pp_formula)

	# Get the number of data points 
	n <- length(data)                          

	# Get information about the distribution
	info <- model_info(distribution, structure)

	# Initialize a list to store the results
	results <- list(data = data)

	# Compare with the method of plotting positions (S-FFA only)
	if (!structure$location && !structure$scale) {

		# Get the first and only slice of the uncertainty object for SFFA
		uncertainty <- uncertainty[[1]]
		slice <- uncertainty$slice
		
		# Sort the data vector
		data_sorted <- data[order(data, decreasing = TRUE)]

		# Determine empirical exceedance probabilities using the plotting position 
		p_empirical <- switch(
			pp_formula, 
			Weibull = (1:n) / (n + 1),
			Blom =  ((1:n) - 0.375) / (n + 0.25),
			Cunnane = ((1:n) - 0.4) / (n + 0.2),
			Gringorten = ((1:n) - 0.44) / (n + 0.12),
			Hazen = ((1:n) - 0.5) / n,
			stop("Unknown plotting position formula.")
		)

		returns <- 1 / p_empirical               

		# Compute the estimates using the appropriate quantile function
		estimates <- quantile_fast(1 - p_empirical, distribution, params, slice, structure)

		# Run linear regression against the sorted data
		R2 <- summary(lm(estimates ~ data_sorted))$r.squared
		RMSE <- sqrt(mean((estimates - data_sorted)^2))
		bias <- mean(estimates - data_sorted)

		# Compute the AIC and BIC
		AIC <- n * log(RMSE) + (2 * info$n_params)
		BIC <- n * log(RMSE) + (log(n) * info$n_params)
		
		# Filter returns and x to indices where returns is between 2 and 100
		idx <- which(returns > 2 & returns < 100)
		returns <- returns[idx]
		data_sorted <- data_sorted[idx]

		# Use log-linear interpolation to get confidence intervals for each return period
		ci_lower <- approx(log(uncertainty$periods), uncertainty$ci_lower, log(returns))
		ci_upper <- approx(log(uncertainty$periods), uncertainty$ci_upper, log(returns))

		# Compute the width and coverage of the confidence intervals
		widths <- ci_upper$y - ci_lower$y
		covers <- sum(data_sorted < ci_upper$y & data_sorted > ci_lower$y)

		# Compute the AW, POC, and CWI
		AW <- mean(widths)
		POC <- 100 * covers / length(widths)
		CWI <- AW * exp((1 - alpha) - (POC / 100))^2

		# Add summary statistics to results
		results$estimates <- estimates
		results$R2 <- R2
		results$RMSE <- RMSE
		results$bias <- bias
		results$AIC <- AIC
		results$BIC <- BIC
		results$AW <- AW
		results$POC <- POC
		results$CWI <- CWI

	} 

	# Compute the MLL AIC and BIC (S-FFA and NS-FFA)
	MLL = fit_maximum_likelihood(data, distribution, years = years, structure = structure)$mll
	results$MLL_AIC = (2 * info$n_params) - (2 * MLL)
	results$MLL_BIC = (info$n_params * log(n)) - (2 * MLL)

	# Return assessment results in a list
	results	

}
