#' Evaluate Goodness-of-Fit for Fitted Flood Models
#'
#' Computes multiple performance metrics and diagnostic indicators to assess the 
#' quality of a fitted flood frequency model This includes residual statistics,
#' information criteria, and coverage-based metrics using confidence intervals.
#'
#' @inheritParams param-data
#' @inheritParams param-model
#' @inheritParams param-params
#'
#' @param uncertainty List; estimated reutrn levels and confidence intervals
#'   generated by \link{uncertainty_bootstrap} or \link{uncertainty_rfpl}. 
#'
#' @inheritParams param-years
#' @inheritParams param-trend
#' @inheritParams param-alpha
#'
#' @param pp.formula Character (1); string specifying the plotting position formula. 
#'   Must be one of `"Weibull"`, `"Blom"`, `"Cunnane"`, `"Gringorten"`, or `"Hazen"`
#'
#'
#' @return List containing model assessment metrics:
#' - `data`: The `data` argument.
#' - `estimates`: Quantile estimates for empirical return periods.
#' - `R2`: Coefficient of determination from linear regression of estimates vs. data.
#' - `RMSE`: Root mean squared error of quantile estimates.
#' - `bias`: Mean bias of quantile estimates.
#' - `AIC`: Akaike Information Criterion.
#' - `BIC`: Bayesian Information Criterion.
#' - `AIC_MLL`: Akaike Information Criterion, computed using MLE.
#' - `BIC_MLL`: Bayesian Information Criterion, computed using MLE.
#' - `AW`: Average width of the confidence interval(s).
#' - `POC`: Percent of observations covered by the confidence interval(s).
#' - `CWI`: Confidence width index, a metric that combines `AW` and `POC`.
#'
#' @seealso \link{uncertainty_bootstrap}, \link{uncertainty_rfpl}, 
#'   \link{fit_maximum_likelihood}
#'
#' @examples 
#' # Initialize example data and params
#' data <- rnorm(n = 100, mean = 100, sd = 10)
#' params <- c(100, 10)
#'
#' # Perform uncertainty analysis
#' uncertainty <- uncertainty_bootstrap(data, "NOR", "L-moments")
#'
#' # Evaluate model diagnostics
#' model_diagnostics(data, "NOR", params, uncertainty)
#'
#' @importFrom stats approx
#' @export

model_diagnostics <- function(
  data,
  model,
  params,
  uncertainty,
  years = NULL,
  trend = NULL,
  alpha = 0.05,
  pp.formula = "Weibull"
) {

	data <- validate_data(data)
	model <- validate_model(model)
	params <- validate_params(params, model, trend)
	years <- validate_years(years)
	trend <- validate_trend(trend)
	alpha <- validate_alpha(alpha)

	# Get the slice from the uncertainty object
	slice <- uncertainty$slice
	
	# Get the number of data points 
	n <- length(data)                          

	# Get information about the distribution
	info <- model_info(model, trend)

	# Initialize a list to store the results
	results <- list(data = data)

	# Compare with the method of plotting positions (S-FFA only)
	if (!trend$location && !trend$scale) {

		# Sort the data vector
		data_sorted <- data[order(data, decreasing = TRUE)]

		# Determine empirical exceedance probabilities using the plotting position 
		p_empirical <- switch(
			pp.formula, 
			Weibull = (1:n) / (n + 1),
			Blom =  ((1:n) - 0.375) / (n + 0.25),
			Cunnane = ((1:n) - 0.4) / (n + 0.2),
			Gringorten = ((1:n) - 0.44) / (n + 0.12),
			Hazen = ((1:n) - 0.5) / n,
			stop("Unknown plotting position formula.")
		)

		t_return <- 1 / p_empirical               

		# Compute the estimates using the appropriate quantile function
		estimates <- quantile_fast(1 - p_empirical, model, params, slice, trend)

		# Run linear regression against the sorted data
		R2 <- summary(lm(estimates ~ data_sorted))$r.squared
		RMSE <- sqrt(mean((estimates - data_sorted)^2))
		bias <- mean(estimates - data_sorted)

		# Compute the AIC and BIC
		AIC <- n * log(RMSE) + (2 * info$n.params)
		BIC <- n * log(RMSE) + (log(n) * info$n.params)
		
		# Filter t_return and x to indices where t_return is between 2 and 100
		idx <- which(t_return > 2 & t_return < 100)
		t_return <- t_return[idx]
		data_sorted <- data_sorted[idx]

		# Use log-linear interpolation to get confidence intervals for each return period
		ci_lower <- approx(log(uncertainty$t), uncertainty$ci_lower, log(t_return))
		ci_upper <- approx(log(uncertainty$t), uncertainty$ci_upper, log(t_return))

		# Compute the width and coverage of the confidence intervals
		widths <- ci_upper$y - ci_lower$y
		covers <- sum(data_sorted < ci_upper$y & data_sorted > ci_lower$y)

		# Compute the AW, POC, and CWI
		AW <- mean(widths)
		POC <- 100 * covers / length(widths)
		CWI <- AW * exp((1 - alpha) - (POC / 100))^2

		# Add summary statistics to results
		results$estimates <- estimates
		results$R2 <- R2
		results$RMSE <- RMSE
		results$bias <- bias
		results$AIC <- AIC
		results$BIC <- BIC
		results$AW <- AW
		results$POC <- POC
		results$CWI <- CWI

	} 

	# Compute the MLL AIC and BIC (S-FFA and NS-FFA)
	MLL = fit_maximum_likelihood(data, model, years = years, trend = trend)$mll
	results$MLL_AIC = (2 * info$n.params) - (2 * MLL)
	results$MLL_BIC = (info$n.params * log(n)) - (2 * MLL)

	# Return assessment results in a list
	results	

}
