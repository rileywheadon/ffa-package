#' Evaluate Goodness-of-Fit for Fitted Flood Models
#'
#' Computes multiple performance metrics and diagnostic indicators to assess the quality of
#' a fitted flood frequency model This includes residual statistics, information criteria,
#' and coverage-based metrics using bootstrapped confidence intervals.
#'
#' @param data Numeric; a vector of annual maximum streamflow data.
#'
#' @param years Numeric; a vector of years with the same length as `data`.
#'
#' @param model Character (1); three character distribution code. Must be one of: 
#'   `"GUM"`, `"NOR"`, `"LNO"`, `"GEV"`, `"GLO"`, `"GNO"`, `"PE3"`, `"LP3"`, or `"WEI"`.
#'
#' @param trend List; information about non-stationary trend(s) to use:
#' - `location` Logical (1); if TRUE, there is a trend in the location parameter.
#' - `scale` Logical (1); if TRUE, there is a trend in the scale parameter.
#'
#' @param params Numeric; a vector of fitted model parameters generated by
#'   \link{fit_lmom_fast} or \link{fit_maximum_likelihood}.
#'
#' @param uncertainty List; estimated reutrn levels and confidence intervals
#'   generated by \link{sb.uncertainty} or \link{rfpl.uncertainty}. 
#'
#' @param pp.formula Character (1); string specifying the plotting position formula. 
#'   One of `"Weibull"`, `"Blom"`, `"Cunnane"`, `"Gringorten"`, or `"Hazen"`
#'   (default is "Weibull").
#'
#' @param alpha Numeric (1); the significance level (default is 0.05).
#'
#' @return List; model assessment metrics:
#' - `estimates`: Quantile estimates for empirical return periods.
#' - `R2`: Coefficient of determination from linear regression of estimates vs. data.
#' - `RMSE`: Root mean squared error of quantile estimates.
#' - `bias`: Mean bias of quantile estimates.
#' - `AIC`: Akaike Information Criterion.
#' - `BIC`: Bayesian Information Criterion.
#' - `AIC_MLL`: Akaike Information Criterion, computed using the maximum log-likelihood.
#' - `BIC_MLL`: Bayesian Information Criterion, computed using the maximum log-likelihood.
#' - `AW`: Average width of the confidence interval(s).
#' - `POC`: Percent of observations covered by the confidence interval(s).
#' - `CWI`: Confidence width index, a metric that combines `AW` and `POC`.
#'
#' @seealso \link{sb.uncertainty}, \link{rfpl.uncertainty}, 
#'   \link[stats]{lm}, \link[stats]{approx}
#'
#' @examples 
#' # Initialize example data, years, and params
#' data <- rnorm(n = 100, mean = 100, sd = 10)
#' years <- seq(from = 1901, to = 2000)
#' params <- c(100, 10)
#'
#' # Perform uncertainty analysis
#' uncertainty <- sb.uncertainty(data, years, "NOR", "L-moments")
#'
#' # Perform model assessment
#' model.assessment(data, years, "NOR", params, uncertainty)
#'
#' @importFrom stats approx
#' @export

model.assessment <- function(
  data,
  years,
  params,
  model,
  trend,
  uncertainty,
  pp.formula = "Weibull",
  alpha = 0.05
) {

	# Run parameter validation (see helpers.R)
	validate.data(data)
	validate.years(years)
	validate.params(params, model, trend)
	validate.model(model)
	validate.trend(trend)
	validate.alpha(alpha)

	# Get the number of data points 
	n <- length(data)                          

	# Get information about the distribution
	info <- model.info(model, trend)

	# Initialize a list to store the results
	results <- list()

	# Compare with the method of plotting positions (S-FFA only)
	if (!trend$location && !trend$scale) {

		# Sort the data vector
		data_sorted <- data[order(data, decreasing = TRUE)]

		# Determine empirical exceedance probabilities using the plotting position 
		p_empirical <- switch(
			pp.formula, 
			Weibull = (1:n) / (n + 1),
			Blom =  ((1:n) - 0.375) / (n + 0.25),
			Cunnane = ((1:n) - 0.4) / (n + 0.2),
			Gringorten = ((1:n) - 0.44) / (n + 0.12),
			Hazen = ((1:n) - 0.5) / n,
			stop("Unknown plotting position formula.")
		)

		t_return <- 1 / p_empirical               

		# Compute the estimates using the appropriate quantile function
		estimates <- qntxxx(model, trend, 1 - p_empirical, params)

		# Run linear regression against the sorted data
		R2 <- summary(lm(estimates ~ data_sorted))$r.squared
		RMSE <- sqrt(mean((estimates - data_sorted)^2))
		bias <- mean(estimates - data_sorted)

		# Compute the AIC and BIC
		AIC <- n * log(RMSE) + (2 * info$n.params)
		BIC <- n * log(RMSE) + (log(n) * info$n.params)
		
		# Filter t_return and x to indices where t_return is between 2 and 100
		idx <- which(t_return > 2 & t_return < 100)
		t_return <- t_return[idx]
		data_sorted <- data_sorted[idx]

		# Use log-linear interpolation to compute confidence intervals on each return period
		slice <- uncertainty[[1]]
		ci_lower <- approx(log(slice$t), slice$ci_lower, log(t_return))
		ci_upper <- approx(log(slice$t), slice$ci_upper, log(t_return))

		# Compute the width and coverage of the confidence intervals
		widths <- ci_upper$y - ci_lower$y
		covers <- sum(data_sorted < ci_upper$y & data_sorted > ci_lower$y)

		# Compute the AW, POC, and CWI
		AW <- mean(widths)
		POC <- 100 * covers / length(widths)
		CWI <- AW * exp((1 - alpha) - (POC / 100))^2

		# Add summary statistics to results
		results$estimates <- estimates
		results$R2 <- R2
		results$RMSE <- RMSE
		results$bias <- bias
		results$AIC <- AIC
		results$BIC <- BIC
		results$AW <- AW
		results$POC <- POC
		results$CWI <- CWI

	} 

	# Compute the MLL AIC and BIC (S-FFA and NS-FFA)
	MLL = fit_maximum_likelihood(data, years, model, trend)$mll
	results$MLL_AIC = (2 * info$n.params) - (2 * MLL)
	results$MLL_BIC = (info$n.params * log(n)) - (2 * MLL)

	# Return assessment results in a list
	results	

}
