[{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU Affero General Public License","title":"GNU Affero General Public License","text":"Version 3, 19 November 2007 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU Affero General Public License","text":"GNU Affero General Public License free, copyleft license software kinds works, specifically designed ensure cooperation community case network server software. licenses software practical works designed take away freedom share change works. contrast, General Public Licenses intended guarantee freedom share change versions program–make sure remains free software users. speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. Developers use General Public Licenses protect rights two steps: (1) assert copyright software, (2) offer License gives legal permission copy, distribute /modify software. secondary benefit defending users’ freedom improvements made alternate versions program, receive widespread use, become available developers incorporate. Many developers free software heartened encouraged resulting cooperation. However, case software used network servers, result may fail come . GNU General Public License permits making modified version letting public access server without ever releasing source code public. GNU Affero General Public License designed specifically ensure , cases, modified source code becomes available community. requires operator network server provide source code modified version running users server. Therefore, public use modified version, publicly accessible server, gives public access source code modified version. older license, called Affero General Public License published Affero, designed accomplish similar goals. different license, version Affero GPL, Affero released new version Affero GPL permits relicensing license. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU Affero General Public License","text":"“License” refers version 3 GNU Affero General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU Affero General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU Affero General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU Affero General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU Affero General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU Affero General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU Affero General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU Affero General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU Affero General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU Affero General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU Affero General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU Affero General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU Affero General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_13-remote-network-interaction-use-with-the-gnu-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Remote Network Interaction; Use with the GNU General Public License.","title":"GNU Affero General Public License","text":"Notwithstanding provision License, modify Program, modified version must prominently offer users interacting remotely computer network (version supports interaction) opportunity receive Corresponding Source version providing access Corresponding Source network server charge, standard customary means facilitating copying software. Corresponding Source shall include Corresponding Source work covered version 3 GNU General Public License incorporated pursuant following paragraph. Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU General Public License single combined work, convey resulting work. terms License continue apply part covered work, work combined remain governed version 3 GNU General Public License.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU Affero General Public License","text":"Free Software Foundation may publish revised /new versions GNU Affero General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU Affero General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU Affero General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU Affero General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU Affero General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU Affero General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU Affero General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU Affero General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. software can interact users remotely computer network, also make sure provides way users get source. example, program web application, interface display “Source” link leads users archive code. many ways offer source, different solutions better different programs; see section 13 specific requirements. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU AGPL, see https://www.gnu.org/licenses/.","code":"<one line to give the program's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>      This program is free software: you can redistribute it and/or modify     it under the terms of the GNU Affero General Public License as     published by the Free Software Foundation, either version 3 of the     License, or (at your option) any later version.      This program is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the     GNU Affero General Public License for more details.      You should have received a copy of the GNU Affero General Public License     along with this program.  If not, see <https://www.gnu.org/licenses/>."},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Change Point Detection","text":"vignette explore Kootenai River Porthill (08NH021) station, located border British Columbia Idaho. station located downstream Libby Dam, finished construction 1972. Data station provided CAN-08NH021.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-08NH021.csv\") head(df) #>   year  max #> 1 1928 2350 #> 2 1929 1680 #> 3 1930 1730 #> 4 1931 1470 #> 5 1932 2190 #> 6 1933 2640  plot_ams_data(df$max, df$year, title = \"Kootenai River at Porthill (08NH021)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"the-pettitt-test","dir":"Articles","previous_headings":"","what":"The Pettitt Test","title":"Change Point Detection","text":"rank-based test detects single abrupt change median time series. null hypothesis assumes change point. Use eda_pettitt_test function perform test. requires two arguments: data: annual maximum series (AMS) years: corresponding numeric vector years  Conclusion: p-value <0.001 provides strong evidence change point year 1972.","code":"pettitt_test <- eda_pettitt_test(df$max, df$year)  print(pettitt_test$p_value) #> [1] 0  print(pettitt_test$change_year) #> NULL  plot_pettitt_test(pettitt_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"the-mks-test","dir":"Articles","previous_headings":"","what":"The MKS Test","title":"Change Point Detection","text":"Mann-Kendall-Sneyers (MKS) test identifies trend changes data. Use eda_mks_test arguments .  Conclusion: p-value 0.015, evidence trend changes 1960 1985. Note: Since MKS test can identify multiple change points, reported p-value determined using significant change point.","code":"mks_test <- eda_mks_test(df$max, df$year)  print(mks_test$p_value) #> [1] 0.01495225  print(mks_test$change_df$year) #> NULL  plot_mks_test(mks_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"interpreting-and-selecting-change-points","dir":"Articles","previous_headings":"","what":"Interpreting and Selecting Change Points","title":"Change Point Detection","text":"example, Pettitt MKS tests suggest structural changes time series. Consider following guidelines choosing split data: Incorporate domain knowledge case-specific understanding. example, know water regulation structure built 1972 (Libby dam). supports results Pettitt test. Avoid overpartitioning. Pettitt MKS tests operate independently may detect multiple change points. minimize sample size issues reduce uncertainty, retain significant change points physical justification. Prioritize based p-value. Lower p-values indicate stronger evidence given weight.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"change-point-detection","dir":"Articles","previous_headings":"","what":"Change Point Detection","title":"Change Point Detection","text":"EDA module FFA Framework includes two statistical tests detecting change points annual maximum series data: Mann-Kendall-Sneyers (MKS) test Pettitt test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"mann-kendall-sneyers-test","dir":"Articles","previous_headings":"Change Point Detection","what":"Mann-Kendall-Sneyers Test","title":"Change Point Detection","text":"Mann-Kendall-Sneyers (MKS) test detects trend change time series: Null hypothesis: change points. Alternative hypothesis: one change points. Define \\(\\mathbb{}(y_{} > y_{j})\\) \\(1\\) \\(y_{} > y_{j}\\) \\(0\\) otherwise. Given time series \\(y_{1}, \\dots, y_{n}\\), compute progressive series \\(S^{F}_{t}\\): \\[ S^{F}_{t} = \\sum_{=}^{t} \\sum_{j=1}^{-1} \\mathbb{}(y_{} > y_{j}) \\] Next, reverse time series \\(y\\). gives us new time series \\(y'\\) \\(y_{}' = y_{n+1-}\\). compute regressive series \\(S^{B}_{t}\\), \\(\\text{rev}()\\) indicates vector reversed: \\[ S^{B}_{t} = \\text{rev}\\left( \\sum_{=}^{t} \\sum_{j=1}^{-1} \\mathbb{}(y'_{} > y'_{j})\\right) \\] , compute normalized progressive series \\(UF_{t}\\) normalized regressive series \\(UB_{t}\\): \\[ UF_{t} = \\frac{S^{F}_{t} - \\mathbb{E}[S^{F}_{t}]}{\\sqrt{\\text{Var}\\,(S^{F}_{t})}}, \\quad UB_{t} = \\frac{S^{B}_{t} - \\mathbb{E}[S^{B}_{t}]}{\\sqrt{\\text{Var}\\,(S^{B}_{t})}} \\] progressive regressive series, expectation variance follows: \\[ \\mathbb{E}[S^{F}_{t}] = \\mathbb{E}[S^{B}_{t}] = \\frac{t(t-1)}{4}, \\quad \\text{Var}(S^{F}_{t}) = \\text{Var}(S^{B}_{t}) = \\frac{t(t-1)(2t+5)}{72} \\] Finally, plot \\(UF_{t}\\) \\(UB_{t}\\) confidence bounds \\(\\alpha/2\\) \\(1 - (\\alpha /2)\\) quantiles standard normal distribution, \\(\\alpha\\) chosen significance level. crossing point \\(UF_{t}\\) \\(UB_{t}\\) lies outside confidence bounds potential change point.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"pettitt-test","dir":"Articles","previous_headings":"Change Point Detection","what":"Pettitt Test","title":"Change Point Detection","text":"Pettitt test detects abrupt changes mean time series. Null hypothesis: abrupt changes. Alternative hypothesis: one abrupt change. Define \\(\\text{sign}(x)\\) \\(1\\) \\(x > 0\\), \\(0\\) \\(x = 0\\), \\(-1\\) otherwise. Given time series \\(y_{1}, \\dots, y_{n}\\), compute following test statistic: \\[ U_{t} = \\sum_{=1}^{t} \\sum_{j=t+1}^{n} \\text{sign} (y_{j} - y_{}), \\quad K = \\max_{t}|U_{t}| \\] value \\(t\\) \\(U_{t} = K\\) potential change point. p-value potential change point can approximated using following formula one-sided test: \\[ p \\approx \\exp \\left(-\\frac{6K^2}{n^3 + n^2}\\right) \\] p-value less significance level \\(\\alpha\\), reject null hypothesis conclude evidence abrupt change mean potential change point.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"introduction-to-exploratory-data-analysis-eda","dir":"Articles","previous_headings":"","what":"Introduction to Exploratory Data Analysis (EDA)","title":"","text":"EDA module FFA Framework used evaluate whether available evidence supports assumption stationarity. , EDA module applies structured sequence statistical tests data detect statistically significant nonstationary signatures. statistical tests serve three purposes: Detect change points (.e., abrupt shifts trend changes). Detect trends mean identify deterministic/stochastic, linear/non-linear. Detect trends variability (.e., heteroskedasticity trends standard deviation). primary goal EDA inform choice stationary nonstationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"stationary-and-nonstationary-ffa","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA)","what":"Stationary and Nonstationary FFA","title":"","text":"Prior performing FFA, necessary choose stationary (S-FFA) nonstationary (NS-FFA) approach. using S-FFA, assumed time series independent identically distributed. Evidence change point(s) /time dependence violates assumptions stationarity indicates NS-FFA may necessary.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"identifying-change-points","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA) > The EDA Workflow","what":"Identifying Change Points","title":"","text":"change point abrupt shift (jump) temporal pattern switch (trend change) time series. Change points indicate inhomogeneous periods (nonstationarity), meaning single model may represent entire record adequately. Instead, piecewise analysis applied homogeneous subperiod. Pettitt test MKS test used identify abrupt shifts temporal pattern switches respectively. However, statistically significant result one tests conclusively identify change point. Type 1 errors issues data quality can cause Pettitt MKS tests identify spurious change points, type 2 errors can cause true change points go unnoticed. Therefore, always important use station-specific knowledge addition results tests.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"identifying-time-dependence","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA) > The EDA Workflow","what":"Identifying Time Dependence","title":"","text":"many types time dependence, FFA framework focuses identifying linear trends mean /variability using two groups statistical tests. Identifying trends mean: First, Mann-Kendall test used identify evidence linear trend mean. trend identified, Spearman test used check evidence autocorrelation, known cause issues Mann-Kendall test. autocorrelation identified, BB-MK test used place Mann-Kendall test identify linear trend mean. Finally, trend identified, PP KPSS tests used check trend deterministic stochastic. Identifying trends variability: variability time series can estimated computing sample standard deviation sequential subsets data (moving window). MW-MK test applies Mann-Kendall test variability time series identify linear trend. White test also used identify general time-dependence (e.g. nonlinear trends) variability. Trend estimation: Sen’s trend estimator robust, nonparametric estimator used estimate linear trend. can applied trends mean variability. linear trend estimated, fit can assessed using runs test, checks randomness residuals. residuals non-random, linear trend may suitable data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"detecting-and-characterizing-trends-in-the-mean","dir":"Articles","previous_headings":"","what":"Detecting and Characterizing Trends in the Mean","title":"","text":"section describes statistical tests (listed alphabetical order) used detect characterize significant trends mean annual maximum series. tests help identify trend, identify autocorrelation, determine whether trend deterministic/stochastic linear/non-linear.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"bb-mk-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"BB-MK Test","title":"","text":"Block Bootstrap Mann-Kendall (BB-MK) Test assesses presence statistically significant monotonic trend time series. BB-MK test insensitive autocorrelation, known produce false positives MK test. Null hypothesis: monotonic trend. Alternative hypothesis: monotonic upward downward trend exists. conduct BB-MK test, rely results MK test Spearman autocorrelation test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > BB-MK Test","what":"Steps","title":"","text":"Compute MK test statistic (see ). Use Spearman test (see ) identify least insignificant lag \\(k\\). Resample time series blocks size \\(k+1\\) without replacement. Compute MK test statistic bootstrapped sample. Derive empirical distribution MK test statistic bootstrapped statistics. Estimate significance observed test statistic using empirical distribution.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"kpss-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"KPSS Test","title":"","text":"KPSS Test determines whether autoregressive time series unit root. test helps assess time series deterministic linear trend. Null hypothesis: time series deterministic linear trend. Alternative hypothesis: time series unit root (stochastic trend). autoregressive time series shown unit root \\(\\sigma_{v}^2 > 0\\): \\[ \\begin{align} y_{t} &= \\mu_{t} + \\beta t +  \\epsilon_{t} \\\\[5pt] \\mu_{t} &= \\mu_{t-1} + v_{t} \\\\[5pt] v_{t} &\\sim \\mathcal{N}(0, \\sigma_{v}^2) \\end{align} \\] : \\(\\mu_{t}\\) drift, deviation \\(y_{t}\\) \\(0\\). null hypothesis, \\(\\mu_{t}\\) constant (since \\(v_{t}\\) constant). alternative hypothesis, \\(\\mu_t\\) stochastic process unit root. \\(\\beta t\\) linear trend, represents deterministic nonstationarity (e.g., climate change). \\(\\epsilon_{t}\\) stationary noise, corresponding reversible fluctuations \\(y_{t}\\). hydrology, \\(\\epsilon_{t}\\) represents fluctuations streamflow due natural variability. \\(v_{t}\\) random walk innovation, irreversible fluctuations \\(\\mu_{t}\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-1","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > KPSS Test","what":"Steps","title":"","text":"Fit linear model \\(y_{t}\\) get residuals \\(\\hat{r}_{t}\\). Compute cumulative partial-sum statistics \\(S_{k}\\) using following formula: \\[ S_{k} = \\sum_{t=1}^{k} \\hat{r}_{t} \\] null hypothesis, \\(S_{k}\\) behave like random walk finite variance. \\(y_{t}\\) unit root, sums “drift” much. Estimate long-run variance time series using Newey-West estimator: \\[ \\hat{\\lambda}^2 = \\hat{\\gamma}_0 + 2 \\sum_{j=1}^{q} \\left(1 - \\frac{j}{q+1} \\right) \\hat{\\gamma}_j \\] \\(q = \\left\\lfloor \\frac{3\\sqrt{n}}{13} \\right\\rfloor\\) autocovariance \\(\\hat{\\gamma}_j\\) : \\[ \\hat{\\gamma}_j = \\frac{1}{n} \\sum_{t = j+1}^{n} \\hat{r}_t \\hat{r}_{t-j} \\] Compute test statistic \\(z_{K}\\): \\[ z_{K} = \\frac{1}{n^2\\hat{\\lambda }^2}\\sum_{k=1}^{n}  S_{k}^2 \\] Since test statistic \\(z_{K}\\) non-normally distributed, compute p-value interpolating table quantiles Hobijn et al. (2004) shown . Warning: interpolation works \\(0.01 < p < 0.10\\) (p-values \\(0.01\\) \\(0.10\\) truncated) significance levels \\(\\alpha\\) \\(0.01\\) \\(0.10\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"mann-kendall-mk-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Mann-Kendall (MK) Test","title":"","text":"Mann-Kendall (MK) Test detects statistically significant monotonic trends time series assumption independence (.e. autocorrelation). Null hypothesis: monotonic trend. Alternative hypothesis: (upward downward) monotonic trend exists. Define \\(\\text{sign} (x)\\) \\(1\\) \\(x > 0\\), \\(0\\) \\(x = 0\\), \\(-1\\) otherwise. test statistic \\(S\\) defined follows: \\[ S = \\sum_{k-1}^{n-1}  \\sum_{j - k + 1}^{n} \\text{sign} (y_{j} - y_{k}) \\] Next, need compute \\(\\text{Var}(S)\\), depends number tied groups data. Let \\(g\\) number tied groups \\(t_{p}\\) number observations \\(p\\)-th group. \\[\\text{Var}(S) = \\frac{1}{18} \\left[n(n-1)(2n + 1) - \\sum_{p-1}^{g} t_{p}(t_{p} - 1)(2t_{p} + 5) \\right]\\] , compute normally distributed test statistic \\(Z_{MK}\\) follows: \\[ Z_{MK} = \\begin{cases} \\frac{S-1}{\\sqrt{\\text{Var}(S)}} &\\text{} S > 0 \\\\ 0 &\\text{}  S = 0 \\\\ \\frac{S+1}{\\sqrt{\\text{Var}(S)}} &\\text{} S < 0 \\end{cases} \\] two-sided test, reject null hypothesis \\(|Z_{MK}| \\geq Z_{1 - (\\alpha/2) }\\) conclude statistically significant monotonic trend data. information, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"phillips-perron-pp-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Phillips-Perron (PP) Test","title":"","text":"PP Test identifies autoregressive time series unit root. Null hypothesis: time series unit root (stochastic trend). Alternative hypothesis: time series deterministic linear trend. Precisely, let \\(x_{t}\\) AR(1) model. Let \\(y_{t}\\) function \\(x_{t}\\) drift \\(\\beta_{0}\\) trend \\(\\beta_{1} t\\). \\[ \\begin{align} y_{t} &= \\beta_{0} + \\beta_{1} t + x_{t} \\\\[5pt] x_{t} &= \\rho x_{t-1} + \\epsilon_{t} \\end{align} \\] \\(\\rho = 1\\), \\(x_t\\) hence \\(y_t\\) unit root (null hypothesis). \\(\\rho < 1\\), \\(y_t\\) trend stationary (alternative hypothesis).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-2","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Phillips-Perron (PP) Test","what":"Steps","title":"","text":"Fit linear autoregressive model time series \\(y_{t}\\). Let \\(\\hat{r}_{t}\\) residuals model. model, can determine \\(\\hat{\\rho}\\) (estimated coefficient \\(y_{t-1}\\)) \\(\\text{SE}(\\hat{\\rho})\\). Estimate variance residuals \\(\\hat{\\sigma}^2\\): \\[ \\hat{\\sigma^2} = \\frac{1}{n - 3} \\sum_{t=1}^{n} \\hat{r}_{t}^2 \\] \\(n\\) number data points sample. \\(n-3\\) degrees freedom since three parameters autoregressive model (\\(\\beta_{0}\\), \\(\\beta_{1}\\), \\(\\rho\\)). Estimate long-run variance \\(\\hat{\\lambda}^2\\) using Newey-West style estimator. estimator corrects additional variability \\(\\epsilon_{t}\\) caused autocorrelation heteroskedasticity. \\[ \\hat{\\lambda}^2 = \\hat{\\gamma}_{0} + 2\\sum_{j=1}^{q} \\left(1 - \\frac{j}{q + 1} \\right)  \\gamma_{j} \\] sample autocovariances \\(\\gamma_{j}\\) computed \\(q = \\left\\lfloor \\sqrt[4]{\\frac{n}{25}}\\right\\rfloor\\) lags: \\[ \\hat{\\gamma}_{j} = \\frac{1}{n} \\sum_{t = j + 1}^{n} \\hat{r}_{t}\\hat{r}_{t-j} \\] Compute test statistic \\(z_{\\rho}\\) using following formula: \\[ z_{\\rho } = n(\\hat{\\rho} - 1) - \\frac{n^2 \\text{SE}(\\hat{\\rho})^2}{2 \\hat{\\sigma}^2}(\\hat{\\lambda }^2 - \\hat{\\gamma}_{0}) \\] test statistic \\(z_{\\rho}\\) normally distributed. Instead, compute p-value interpolating table Fuller, W. . (1996). table shown sample sizes \\(n\\) probabilities \\(p\\): Warning: interpolation works p-values \\(p > 0.01\\) (p-values \\(0.01\\) truncated) confidence levels \\(\\alpha > 0.01\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"runs-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Runs Test","title":"","text":"Runs Test checks whether residuals regression (e.g., trend approximation Sen’s estimator) randomly distributed. Runs test identifies non-randomness residuals, strong indication nonstationarity data non-linear. Null hypothesis: Residuals distributed randomly. Alternative hypothesis: Residuals distributed randomly (e.g., due nonlinearity).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-3","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Runs Test","what":"Steps","title":"","text":"Classify data based whether (\\(+\\)) \\((-)\\) median. data points equal median removed. Compute number contiguous blocks \\(+\\) \\(-\\) (known runs) data. example, sequence \\(+++--+++-+-\\) six runs length \\((3, 2, 3, 1, 1, 1)\\). Let \\(R\\) number runs \\(N\\) data points (category counts \\(N_{+}\\) \\(N_{-}\\)). , null hypothesis, \\(R\\) asymptotically normal : \\[ \\mathbb{E}[R] = \\frac{2N_{+}N_{-}}{N} + 1, \\quad \\text{Var}(R) = \\frac{2N_{+}N_{-}(2N_{+}N_{-} - N)}{N^2(N - 1)} \\] Compute p-value normalizing \\(R\\) using expectation variance given .","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Sen’s Trend Estimator","title":"","text":"Sen’s Trend Estimator approximates slope regression line. Unlike Least Squares, Sen’s trend estimator uses non-parametric approach makes robust outliers.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-4","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Sen’s Trend Estimator","what":"Steps","title":"","text":"pairs \\((x_i, y_i)\\) \\((x_j, y_j)\\) \\(x_i \\neq x_j\\), compute slopes: \\[ m_{ij} = \\frac{y_j - y_i}{x_j - x_i} \\] Take median slopes: \\(\\hat{m}\\). Estimate \\(y\\)-intercept \\(\\hat{b}\\) median \\(y_{} - \\hat{m}x_{}\\) \\(\\).","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"spearman-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Spearman Test","title":"","text":"Spearman test identifies autocorrelation time series \\(y_{t}\\). significant lag number \\(\\) correlation \\(y_{t}\\) \\(y_{t-}\\) statistically significant. least insignificant lag smallest \\(\\) significant lag. Null hypothesis: least insignificant lag \\(1\\). Alternative hypothesis: least insignificant lag greater \\(1\\). carry Spearman test, use following procedure: Compute Spearman’s correlation coefficient \\(\\rho_{}\\) \\(y_{t}\\) \\(y_{t-}\\) \\(0 \\leq  <  n\\). Compute \\(p\\)-value \\(p_{}\\) correlation coefficient \\(\\rho _{}\\) using formula: \\[ t_{}= \\rho_{} \\sqrt{\\frac{n-2}{1 - \\rho _{}^2}} \\] test statistic \\(t_{}\\) \\(t\\)-distribution \\(n-2\\) degrees freedom. Find smallest \\(\\) \\(p_{} > \\alpha\\). \\(\\) least insignificant lag confidence level \\(\\alpha\\). information, see Wikipedia pages Autocorrelation Spearman’s Rho.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"detecting-trends-in-the-variability","dir":"Articles","previous_headings":"","what":"Detecting Trends in the Variability","title":"","text":"section describes methods used detect trends changes variability (e.g., variance standard deviation) annual maximum series data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"moving-window-mann-kendall-mw-mk-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Moving Window Mann-Kendall (MW-MK) Test","title":"","text":"MW-MK test detects statistically significant monotonic trends standard deviation data. Null hypothesis: significant trend standard deviation. Alternative hypothesis: Significant monotonic trend standard deviation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"steps","dir":"Articles","previous_headings":"Detecting Trends in the Variability > Moving Window Mann-Kendall (MW-MK) Test","what":"Steps","title":"","text":"compute standard deviations data, use moving window algorithm. Let \\(w\\) length moving window \\(s\\) step size. , Initialize moving window indices \\([1, w]\\). Compute sample standard deviation within window. Move window forward \\(s\\) steps. Repeat steps 2 3 window reaches end data. produces time series moving-window standard deviations. , Mann-Kendall Test used test monotonic trend standard deviation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Sen’s Trend Estimator","title":"","text":"Used estimate slope trend standard deviations (see ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"runs-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Runs Test","title":"","text":"Used check residuals trend fitted standard deviations randomness (see ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"white-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"White Test","title":"","text":"White Test detects changes variability (heteroskedasticity) time series. Null hypothesis: Constant variability (homoskedasticity). Alternative hypothesis: Time-dependent variability (heteroskedasticity).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"steps-1","dir":"Articles","previous_headings":"Detecting Trends in the Variability > White Test","what":"Steps","title":"","text":"Fit simple linear regression model using ordinary least squares: \\[y_{} = \\beta_{0} + \\beta_{1} x_{} + \\epsilon_{}\\] Compute squared residuals: \\[ \\hat{r}_i^2 = \\left(y_i - \\hat{y}_i\\right)^2 \\] Fit auxiliary regression model squared residuals. model includes regressor, square regressor, cross products regressors. Since \\(x\\) regressor, regression model simply: \\[ \\hat{r}_i^2 = \\alpha_0 + \\alpha_1 x_i + \\alpha_2 x_i^2 + u_i \\] Compute coefficient determination \\(R^2\\) auxiliary model. Compute test statistic \\(nR^2 \\sim \\chi_{d}^2\\) \\(n\\) number observations \\(d = 2\\) number regressors, excluding intercept. \\(nR^2 > \\chi^2_{1-\\alpha, d}\\), reject null hypothesis conclude time series exhibits heteroskedasticity.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"overview","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA)","what":"Overview","title":"","text":"Flood Frequency Analysis (FFA) uses probability distribution fitted extreme streamflow observations (e.g., annual maxima) estimate recurrence likelihood floods. perform FFA, require probability model corresponding parameter estimates based data. FFA relates flood peak magnitudes \\(Q\\) expected frequency occurrence, expressed return period. example, flood 10-year return period—commonly referred 10-year flood—1--10 chance equaled exceeded given year. corresponds annual exceedance probability \\(p_e = 0.1\\). Since FFA Framework uses annual maxima data, equates 90th percentile (.e., \\(0.90\\) quantile) fitted probability distribution. summary return periods, exceedance probabilities, associated quantiles used default FFA framework: Let \\(F(q)\\) cumulative distribution function (CDF) fitted model. function maps flood magnitudes exceedance probabilities: \\(p_e = 1 - F(q)\\). estimate flood magnitudes given exceedance probability, use inverse CDF, better known quantile function: \\(\\hat{q} = F^{-1}(p_e)\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"example-plot","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA) > Overview","what":"Example Plot","title":"","text":"FFA results typically visualized return period \\(x\\)-axis flood magnitude \\(y\\)-axis. plots can interpreted two directions: Estimate flood magnitude given return period. example, 50-year flood estimated \\(85\\ \\text{m}^3/\\text{s}\\). Estimate return period given flood magnitude. example, streamflow \\(50\\ \\text{m}^3/\\text{s}\\) expected occur roughly every 4 years. Note: explanation confidence bounds plot, see Uncertainty Quantification.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA)","what":"Handling Nonstationarity","title":"","text":"probability model considered nonstationary statistical properties (e.g., location scale) change time. cases, quantile function becomes time-dependent: \\(F^{-1}(p_e, t)\\). result, return levels exceedance probabilities vary time, static return period curve longer valid. address , FFA framework computes effective return periods, yield flood estimates specific year based time-varying distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"example-plot-1","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA) > Handling Nonstationarity","what":"Example Plot","title":"","text":"plot illustrates effective return levels years 1920, 1960, 2000. Remember, 100-year effective return level imply flood expected occur next 100 years. Instead, means given year, probability exceeding effective return level 1 100.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"nonparametric-models","dir":"Articles","previous_headings":"Model Assessment","what":"Nonparametric Models","title":"","text":"Plotting Position non-parametric estimator used derive empirical exceedance probabilities. using plotting position, can evaluate quality parametric model (assuming model stationary). compute plotting position, arrange sample observations descending order magnitude: \\(x_{n:n} \\geq  \\dots  \\geq  x_{1:n}\\). , empirical exceedance probabilities given following formula: \\[ p_{:n} = \\frac{-}{n+1 - 2a}, \\quad \\\\{1, \\dots , n\\} \\] coefficient \\(\\) depends plotting position formula: default, FFA framework uses Weibull formula, unbiased.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"r2---coefficient-of-determination","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"\\(R^2\\) - Coefficient of Determination","title":"","text":"compute \\(R^2\\) statistic, perform linear regression annual maximum series data predictions parametric model plotting positions. \\(R^2\\) statistic describes well parametric model captures variance data. Higher better. plot shows deviation estimated quantiles (red dots), data (black line).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"rmse---root-mean-squared-error","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"RMSE - Root-Mean Squared Error","title":"","text":"RMSE statistic describes average squared difference data predictions parametric model. Lower better.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"bias","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"Bias","title":"","text":"Bias statistic describes average difference data predictions parametric model. positive bias indicates model tends overestimate data negative bias indicates model tends underestimate data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"information-criterion","dir":"Articles","previous_headings":"Model Assessment","what":"Information Criterion","title":"","text":"Akaike Information Criterion (AIC) Bayesian Information Criterion (BIC) describe quality model based error (RMSE) number parameters (n_theta). Better models lower AIC/BIC, indicates less parameters lower error. Akaike/Bayesian information criterion can also computed using maximum log-likelihood maximum likelihood estimation. statistics reported AIC_MLL BIC_MLL.","code":"AIC <- (n * log(RMSE)) + (2 * n_theta) BIC <- (n * log(RMSE)) + (log(n) * n_theta) AIC_MLL <- (n * log(MLL)) + (2 * n_theta) BIC_MLL <- (n * log(MLL)) + (log(n) * n_theta)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"uncertainty-statistics","dir":"Articles","previous_headings":"Model Assessment","what":"Uncertainty Statistics","title":"","text":"FFA framework uses three statistics assess uncertainty flood quantile estimates: AW captures precision (narrower confidence intervals better). POC captures reliability (higher coverage observations better). CWI composite measure balancing precision reliability (lower better). use metrics together evaluate robustness flood frequency analysis.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"aw-average-width","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"AW – Average Width","title":"","text":"AW average width interpolated confidence intervals across return periods interest. smaller AW indicates precise quantile estimates. compute AW, use log-linear interpolation estimate confidence intervals empirical exceedance probabilities confidence intervals computed uncertainty quantification.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"poc-percent-of-coverage","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"POC – Percent of Coverage","title":"","text":"POC percentage observed quantiles fall within corresponding confidence intervals. higher POC indicates greater reliability confidence intervals.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"cwi-confidence-width-indicator","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"CWI – Confidence Width Indicator","title":"","text":"CWI composite metric penalizes wide /poorly calibrated confidence intervals. lower CWI better. Wide intervals low coverage increase penalty. Ideal confidence intervals narrow well-calibrated, resulting low CWI. CWI computed using following formula, alpha significance level.","code":"CWI <- AW * exp((1 - alpha) - POC / 100)^2;"},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"model-selection","dir":"Articles","previous_headings":"","what":"Model Selection","title":"","text":"module selects statistical model S-FFA NS-FFA based annual maximum series. S-FFA: time-invariant probability distribution selected candidate distributions. NS-FFA: distribution chosen along nonstationary structure capture evolution time. piecewise NS-FFA, series segmented subperiods, modeled either time-invariant time-varying distributions. framework uses L-moment ratio method identify best-fit distribution family comparing sample L-moments L-moments various distribution families. NS-FFA, series decomposed isolate stationary component following Vidrio-Sahagún (2022). decomposed sample used distribution selection, S-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"an-introduction-to-l-moments","dir":"Articles","previous_headings":"Model Selection","what":"An Introduction to L-Moments","title":"","text":"Definition 1: \\(k\\)-th Order Statistic statistical sample \\(k\\)-th smallest value. Definition 2: \\(r\\)-th Population L-moment \\(\\lambda_{r}\\) linear combination expectation order statistics. Let \\(X_{k:n}\\) \\(k\\)-th order statistic sample size \\(n\\). , \\[ \\lambda_{r} = \\frac{1}{r} \\sum_{k=0}^{r-1} (-1)^{k} \\binom{r-1}{k} \\mathbb{E}[X_{r-k:r}] \\] Definition 3: Probability Weighted Moment (PWM) encodes information value’s position cumulative distribution function. \\(r\\)-th PWM, denoted \\(\\beta_{r}\\), : \\[ \\beta_{r} = \\mathbb{E}[X \\cdot  F(X)^{r}] \\] ordered sample \\(x_{1:n} \\leq  \\dots  \\leq  x_{n:n}\\), sample PWM often estimated : \\[ b_{r} = \\frac{1}{n} \\sum_{=1}^{r} x_{:n} \\left(\\frac{-1}{n-1}\\right) ^{r} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"sample-l-moments-from-pwms-and-l-moment-ratios","dir":"Articles","previous_headings":"Model Selection > An Introduction to L-Moments","what":"Sample L-Moments (from PWMs) and L-Moment Ratios","title":"","text":"first four sample L-moments can computed linear combinations PWMs: \\[ \\begin{aligned} l_{1} &= b_{0} \\\\ l_{2} &= 2b_{1} - b_{0} \\\\ l_{3} &= 6b_{2} - 6b_{1} + b_{0} \\\\ l_{4} &= 20b_{3} - 30b_{2} + 12b_{1} - b_{0} \\end{aligned} \\] L-moments used compute Sample L-variance \\(t_{2}\\), Sample L-skewness \\(t_{3}\\) Sample L-kurtosis \\(t_{4}\\) using following formulas: \\[ \\begin{aligned} t_{2} &= l_{2} / l_{1} \\\\ t_{3} &= l_{3} / l_{2} \\\\ t_{4} &= l_{4} / l_{2} \\end{aligned} \\] , compare statistics, specifically L-skewness L-kurtosis theoretical values (given ) using one three different metrics select distribution. Note: Probability distributions two parameters constant L-skewness \\(\\tau_{3}\\) L-kurtosis \\(\\tau_{4}\\) regardless parameters. L-skewness L-kurtosis probability distributions three parameters function shape parameter \\(\\kappa\\). notation \\(\\tau_{3}(\\kappa)\\) \\(\\tau_{4}(\\kappa)\\) refers L-skewness L-kurtosis curves three parameter distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"example-plot","dir":"Articles","previous_headings":"Model Selection > An Introduction to L-Moments","what":"Example Plot","title":"","text":"Shown L-moment curves GEV, GLO, GNO, PE3/LP3, WEI distributions well L-moment ratios two parameter distributions GUM /LNO. L-moment diagram depicts “L-distance” selection metric, compares euclidian distance sample theoretical L-moment ratios. inset shows GEV distribution (yellow line) closest L-moments data.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"l-distance","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"1. L-Distance","title":"","text":"Euclidean distance sample \\((t_3, t_4)\\) theoretical \\((\\tau_3, \\tau_4)\\) candidate distribution. 3-parameter distributions, minimum distance along L-moment ratio curve.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"l-kurtosis","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"2. L-Kurtosis","title":"","text":"L-kurtosis method used three-parameter probability distributions. First, shape parameter \\(\\kappa^{*}\\) \\(t_{3} = \\tau _{3}(\\kappa ^{*})\\) identified. , difference sample L-kurtosis theoretical L-kurtosis computed using metric \\(|\\tau_{4}(\\kappa ^{*}) - t_{4} |\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"z-statistic","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"3. Z-statistic","title":"","text":"Z-statistic selection metric calculated follows (three-parameter distributions): Fit four-parameter Kappa (K4D) distribution sample. Generate \\(N_{\\text{sim}}\\) bootstrap samples fitted K4D distribution. Calculate sample L-kurtosis \\(t_{4}^{[]}\\) synthetic dataset. Calculate bias standard deviation bootstrap distribution: \\[ B_{4} = N_{\\text{sim} }^{-1} \\sum_{= 1}^{N_{\\text{sim} }} \\left(t_{4}^{[]} - t_{4}^{s}\\right) \\] \\[ \\sigma _{4} = \\left[(N_{\\text{sim} } - 1)^{-1} \\left\\{\\sum_{- 1}^{N_{\\text{sim} }} \\left(t_{4}^{[]} - t_{4}^{s}\\right)^2 - N_{\\text{sim} } B_{4}^2\\right\\} \\right] ^{\\frac{1}{2}} \\] Identify shape parameter \\(\\kappa^{*}\\) \\(t_{3} = \\tau _{3}(\\kappa ^{*})\\). Use bootstrap distribution compute Z-statistic distribution: \\[ z = \\frac{\\tau_{4} (\\kappa ^{*}) - t_{4} + B_{4} }{ \\sigma _{4}} \\] Choose distribution smallest Z-statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Model Selection","what":"Handling Nonstationarity","title":"","text":"nonstationarity detected, annual maximum series decomposed model selection. consider three nonstationary scenarios can identified EDA: Trend mean . Trend standard deviation . Trend mean standard deviation.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-1-trend-in-mean","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 1: Trend in mean","title":"","text":"Use Sen’s Trend Estimator approximate slope \\(b_1\\) intercept \\(b_0\\). Detrend: subtract linear function \\((b_{1} \\cdot \\text{Covariate})\\) time series, covariate time index calculated using formula \\((\\text{Years} - 1900) / 100\\). Ensure positivity: necessary, shift series adding constant \\(\\min(\\text{data}) = 1\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-2-trend-in-standard-deviation","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 2: Trend in standard deviation","title":"","text":"Generate time series standard deviations using moving windows method. Use Sen’s Trend Estimator identify slope \\(c_{1}\\) intercept \\(c_{0}\\) trend standard deviations. Normalize data mean \\(0\\), divide scale factor \\(g_{t}\\). \\[ g_{t} = \\frac{(c_{1} \\cdot  \\text{Covariate} ) + c_{0}}{c_{0}} \\] Add back long-term mean \\(\\mu\\), ensure positivity Scenario 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-3-trend-in-both-mean-and-standard-deviation","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 3: Trend in both mean and standard deviation","title":"","text":"Remove linear trend mean exactly Scenario 1. detrended series, generate rolling‐window STD series fit trend. Divide detrended data time-varying scale factor \\(g_{t}\\) (Scenario 2). Shift preserve series mean ensure positivity.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"","text":"module estimates parameters S-FFA NS-FFA. NS-FFA, parameter estimation also involves estimating regression coefficients time-varying parameters. framework supports three estimation methods: L-moments Maximum Likelihood (MLE) Generalized Maximum Likelihood (GMLE) Note: adopt GEV distribution convention Coles (2001)1, positive shape parameter \\(\\kappa\\) indicates heavy tail. differs convention used sources.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"l-moments","dir":"Articles","previous_headings":"Parameter Estimation","what":"L-Moments","title":"","text":"L-moments parameter estimation method implemented distributions S-FFA. method uses sample L-moments (\\(l_1\\), \\(l_2\\)) L-moment ratios (\\(t_3\\), \\(t_4\\)) estimate parameters. information L-moments, see . Warning: L-moment-based estimates can yield distributions support small values. However, typically issue quantile estimation mid- high-return periods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"maximum-likelihood-mle","dir":"Articles","previous_headings":"Parameter Estimation","what":"Maximum Likelihood (MLE)","title":"","text":"MLE implemented distributions across S-FFA NS-FFA. Maximum likelihood estimation aims maximize log-likelihood function \\(\\ell(x : \\theta)\\) data \\(x = x_{1}, \\dots , x_{n}\\) given parameters \\(\\theta\\). log-likelihood functions distribution defined . find optimal parameters, use nlminb function stats library. function implements “L-BFGS-B” algorithm box-constrained optimization.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"generalized-maximum-likelihood-gmle","dir":"Articles","previous_headings":"Parameter Estimation","what":"Generalized Maximum Likelihood (GMLE)","title":"","text":"GMLE used GEV models incorporating prior knowledge2 shape parameter \\(\\kappa\\) using Bayesian reasoning via maximum posteriori estimation, maximizes product likelihood prior distribution. Suppose \\(\\kappa\\) drawn \\(K \\sim \\text{Beta}(p, q)\\) \\(p\\) \\(q\\) determined using prior knowledge. prior PDF \\(f_{K}(\\kappa)\\) shown , \\(B(p, q)\\) Beta function. \\[ f_{K}(\\kappa) = \\frac{\\kappa ^{p - 1}(1 - \\kappa)^{q-1}}{B(p, q)} \\] case regular maximum likelihood estimation, likelihood function : \\[ f_{X}(x : \\mu, \\sigma, \\kappa) =\\prod_{=1}^{n} \\frac{1}{\\sigma}t_{}^{-1 - (1/\\kappa)} \\exp (-t_{}^{-1/\\kappa}), \\quad t_{} = 1 + \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma } \\right) \\] mentioned previously, want maximize product \\(\\mathcal{L} = f_{K}(\\kappa)f_{X}(x:\\mu ,\\sigma ,\\kappa)\\). ensure numerical stability, maximize \\(\\ln  (\\mathcal{L})\\) instead, following form: \\[ \\begin{aligned} \\ln(\\mathcal{L}) &= \\ln(f_{K}(\\kappa)) + \\ln(f_{X}(x:\\mu ,\\sigma ,\\kappa )) \\\\[10pt] \\ln(f_{K}(\\kappa)) &= (p - 1)\\ln \\kappa + (q-1) \\ln (1 - \\kappa)  - \\ln (B(p, q)) \\\\[5pt] \\ln(f_{X}(x:\\mu ,\\sigma ,\\kappa )) &= \\sum_{=1}^{n} \\left[-\\ln \\sigma - \\left(1 + \\frac{1}{\\kappa }\\right) \\ln t_{} - t_{}^{-1/\\kappa}\\right] \\end{aligned} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"candidate-probability-distributions","dir":"Articles","previous_headings":"","what":"Candidate Probability Distributions","title":"","text":"FFA framework considers nine candidate probability distributions: distribution also three nonstationary variants: trend location parameter \\(\\mu\\) (+1 parameter). trend scale parameter \\(\\sigma\\) (+1 parameter). trend location \\(\\mu\\) scale \\(\\sigma\\) (+2 parameters). FFA framework also uses four-parameter Kappa distribution (KAP) Z-statistic selection metric. Kappa distribution generalizes nine distributions listed .","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"gumbel-gum-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Gumbel (GUM) Distribution","title":"","text":"Support \\(-\\infty < x < \\infty\\) Quantiles \\(x(F) = \\mu - \\sigma \\log (-\\log F)\\) Likelihood Function probability density function (PDF) : \\[ f(x_{} : \\mu, \\sigma) = \\frac{1}{\\sigma} \\exp \\left(-z_{} - e^{-z_{}}\\right) , \\quad z_{} = \\frac{x_{} - \\mu}{\\sigma } \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma) = \\sum_{=1}^{n} \\left[-\\ln \\sigma - z_{} - e^{-z_{}} \\right] \\] L-Moments equations , \\(\\gamma \\approx 0.5772\\) Euler’s constant. \\(\\lambda_{1} = \\mu + \\sigma \\gamma\\) \\(\\lambda_{2} = \\sigma \\log 2\\) \\(\\tau_{3} = \\log(9/8)/\\log 2 \\approx 0.1699\\) \\(\\tau_{4} = (16 \\log 2 - 10\\log 3) / \\log 2 \\approx 0.1504\\) can also express parameters terms L-moments: \\(\\sigma = \\lambda_{2} / \\log 2\\) \\(\\mu = \\lambda_{1} - \\sigma \\gamma\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"normal-nor-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Normal (NOR) Distribution","title":"","text":"Support \\(-\\infty < x < \\infty\\) Quantiles \\(x(F) = \\mu  + \\sigma \\Phi^{-1}(F)\\) Likelihood Function probability density function (PDF) : \\[ f(x_{} : \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi }}e^{-z_{}^2/2} , \\quad z_{} = \\frac{x_{} - \\mu}{\\sigma } \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma) = \\sum_{=1}^{n} \\left[-\\ln (\\sigma \\sqrt{2\\pi }) - \\frac{z_{}^2}{2} \\right] \\] L-Moments \\(\\lambda_{1} = \\mu\\) \\(\\lambda_{2} = \\pi^{-1/2}\\sigma \\approx 0.5642\\sigma\\) \\(\\tau_{3} = 0\\) \\(\\tau_{4} = 30\\pi^{-1}\\arctan \\sqrt{2} - 9 \\approx 0.1226\\) can also express parameters terms L-moments: \\(\\mu = \\lambda_{1}\\) \\(\\sigma = \\pi^{1/2}\\lambda_{2}\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"log-normal-lno-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Log-Normal (LNO) Distribution","title":"","text":"Support \\(0 < x < \\infty\\) Quantiles \\(x(F) = \\exp(\\mu + \\sigma \\Phi^{-1}(F))\\) Likelihood Function derive likelihood, use fact : \\[ \\text{Data} \\sim \\text{LNO} \\Leftrightarrow \\ln (\\text{Data}) \\sim \\text{} \\] Precisely, require change variables formula, states : \\[ \\ell_{\\text{LNO}}(x ; \\mu, \\sigma) = \\ell_{\\text{}}(\\ln x ; \\mu , \\sigma) \\left|\\frac{d}{dx} \\ln  x\\right| = \\frac{\\ell_{\\text{}}(\\ln x ; \\mu , \\sigma)}{x} \\] L-Moments See Normal Distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-extreme-value-gev-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Extreme Value (GEV) Distribution","title":"","text":"Support \\[ \\begin{cases} \\mu + (\\sigma /\\kappa) \\leq x < \\infty & \\kappa > 0 \\\\[5pt] -\\infty < x < \\infty & \\kappa  = 0 \\\\[5pt] -\\infty < x \\leq \\mu + (\\sigma/\\kappa ) &\\kappa < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{dcases} \\mu + \\sigma (1 - (-\\log F)^{\\kappa })/\\kappa  &\\kappa \\neq 0\\\\[5pt] \\mu - \\sigma \\log (-\\log F) &\\kappa = 0 \\end{dcases} \\] Likelihood Function probability density function (PDF) (assume \\(t_{} > 0)\\): \\[ f(x_{} : \\mu, \\sigma, \\kappa) = \\frac{1}{\\sigma}t_{}^{-1 - (1/\\kappa)} \\exp (-t_{}^{-1/\\kappa}), \\quad t_{} = 1 + \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma } \\right) \\] Therefore, Log-likelihood : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[-\\ln \\sigma - \\left(1 + \\frac{1}{\\kappa }\\right) \\ln t_{} - t_{}^{-1/\\kappa}\\right] \\] L-Moments L-moments defined \\(\\kappa > -1\\): \\(\\lambda_{1} = \\mu + \\sigma (1 - \\Gamma (1 + \\kappa)) / \\kappa\\) \\(\\lambda_{2} = \\sigma (1 - 2^{-\\kappa })\\Gamma (1 + \\kappa) / \\kappa\\) \\(\\tau_{3} = 2(1 - 3^{-\\kappa})/(1 - 2^{-\\kappa}) - 3\\) \\(\\tau_{4} = [5(1 - 4^{-\\kappa })-10(1-3^{-\\kappa}) + 6(1-2^{-\\kappa })]/(1 - 2^{-\\kappa })\\) compute parameters L-moments, first compute \\(c\\): \\[ c = \\frac{2}{3 + \\tau_{3}} - \\frac{\\log 2}{\\log 3} \\] , use following approximation2: \\[ \\begin{cases} \\kappa \\approx 7.8590c + 2.9554c^2 \\\\[5pt] \\sigma \\approx \\lambda_{2}\\kappa / (1 - 2^{-\\kappa })\\Gamma (1 + \\kappa) \\\\[5pt] \\mu \\approx \\lambda_{1} - \\sigma (1 - \\Gamma (1 + \\kappa )) / \\kappa \\end{cases} \\] Note: sources often use different notation GEV distribution sign shape parameter \\(\\kappa\\) flipped.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-logistic-glo-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Logistic (GLO) Distribution","title":"","text":"Support \\[ \\begin{cases} -\\infty < x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa  > 0 \\\\[5pt] -\\infty  < x < \\infty  & \\kappa  = 0 \\\\[5pt] \\mu  + (\\sigma /\\kappa ) \\leq  x < \\infty  & \\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu +\\sigma [1 - ((1 - F) / F)^{\\kappa}] / \\kappa &\\kappa \\neq 0 \\\\[5pt] \\mu - \\sigma \\log ((1 - F) / F) & k = 0 \\end{cases} \\] Likelihood Function probability density function (PDF) (assume \\(t_{} > 0)\\): \\[ f(x_{} : \\mu , \\sigma , \\kappa ) = \\frac{1}{\\sigma }t_{}^{(1/\\kappa) - 1} \\left[1 + t_{}^{1/\\kappa}\\right]^{-2}, \\quad t_{} = 1 - \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma }\\right) \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[-\\ln \\sigma + \\left(\\frac{1}{\\kappa }-1\\right) \\ln t_{} - 2 \\ln \\left(1 + t_{}^{1/\\kappa }\\right) \\right] \\] L-Moments L-moments defined \\(-1 < \\kappa < 1\\): \\(\\lambda_{1} = \\mu +\\sigma [(1 / \\kappa) - (\\pi / \\sin (\\kappa\\pi))]\\) \\(\\lambda_{2} = \\sigma \\kappa \\pi / \\sin (\\kappa \\pi)\\) \\(\\tau_{3} = -\\kappa\\) \\(\\tau_{4} = (1 + 5\\kappa ^2) / 6\\) can also express parameters terms L-moments: \\(\\kappa = -\\tau_{3}\\) \\(\\sigma = \\lambda_{2}\\sin (\\kappa \\pi ) / \\kappa \\pi\\) \\(\\mu = \\lambda_{1} - \\sigma [(1 / \\kappa) - (\\pi / \\sin (\\kappa\\pi))]\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-normal-gno-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Normal (GNO) Distribution","title":"","text":"Support \\[ \\begin{cases} -\\infty < x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa  > 0 \\\\[5pt] -\\infty  < x < \\infty  & \\kappa  = 0 \\\\[5pt] \\mu  + (\\sigma /\\kappa ) \\leq  x < \\infty  & \\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu + \\sigma [1 - \\exp(-\\kappa \\Phi^{-1}(F))] / \\kappa &\\kappa \\neq 0 \\\\[5pt] \\mu + \\sigma \\Phi^{-1}(F) &\\kappa  = 0 \\end{cases} \\] Likelihood Function L-Moments L-moments defined values \\(\\kappa\\). \\(\\lambda_{1} = \\mu + \\sigma (1 - e^{\\kappa ^2/2}) / \\kappa\\) \\(\\lambda_{2} = \\sigma e^{-\\kappa ^2/ 2}[1 - 2\\Phi (-\\kappa  / \\sqrt{2})] / \\kappa\\) compute \\(\\tau_{3}\\) \\(\\tau_{4}\\) use following approximation: \\[ \\begin{aligned} \\tau_{3} &\\approx -\\kappa \\left(\\frac{A_{0} + A_{1}\\kappa ^2 + A_{2}\\kappa ^{4} + A_{3}\\kappa ^{6}}{1 + B_{1}\\kappa ^2 + B_{2}\\kappa ^{4} + B_{3}\\kappa ^{6}}\\right)  \\\\[5pt] \\tau_{4} &\\approx \\tau_{4}^{0} + \\kappa ^2 \\left(\\frac{C_{0} + C_{1}\\kappa ^2 + C_{2}\\kappa ^{4} + C_{3}\\kappa ^{6}}{1 + D_{1}\\kappa ^2 + D_{2}\\kappa ^{4} + D_{3}\\kappa ^{6}}\\right) \\end{aligned} \\] determine parameters L-moments also use rational approximation: \\[ \\kappa \\approx -\\tau_{3} \\left(\\frac{E_{0} + E_{1}\\tau_{3}^2 + E_{2}\\tau_{3}^{4} + E_{3}\\tau _{3}^{6}}{1 + F_{1}\\tau _{3}^2 + F_{2}\\tau _{3}^{4} + F_{3}\\tau _{3}^{6}}\\right) \\] , can find \\(\\mu\\) \\(\\sigma\\) function \\(\\kappa\\): \\[ \\sigma \\approx  \\frac{\\lambda_{2}\\kappa e^{-\\kappa ^2 / 2}}{1 - 2\\Phi (-\\kappa  / \\sqrt{2})}, \\quad \\mu  \\approx  \\lambda_{1} - \\frac{\\sigma }{\\kappa }\\left(1 - e^{-\\kappa ^2 / 2 }\\right) \\] coefficients (\\(A_{}\\), \\(B_{}\\), \\(C_{}\\), \\(D_{}\\), \\(E_{}\\), \\(F_{}\\), \\(\\tau_{4}^{0}\\)) defined Appendix .8 Hosking, 19973. Although appendix covers 3-parameter log-normal distribution, L-moments generalized normal distribution .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"pearson-type-iii-pe3-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Pearson Type III (PE3) Distribution","title":"","text":"Pearson Type III distribution typically reparameterized follows \\(\\kappa \\neq 0\\): \\[ \\begin{aligned} \\alpha &= 4 / \\kappa^2 \\\\[5pt] \\beta  &= \\sigma |\\kappa | / 2 \\\\[5pt] \\xi &= \\mu  - 2\\sigma /\\kappa \\end{aligned} \\] Support \\[ \\begin{cases} \\xi \\leq  x < \\infty &\\kappa > 0 \\\\[5pt] -\\infty < x < \\infty  &\\kappa =0 \\\\[5pt] -\\infty  < x \\leq \\xi &\\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu - \\alpha \\beta + q(F, \\alpha, \\beta) &\\kappa > 0\\\\[5pt] \\mu + \\sigma \\Phi^{-1}(F) &\\kappa  = 0\\\\[5pt] \\mu  + \\alpha \\beta  - q(1 - F, \\alpha, \\beta) &\\kappa < 0 \\end{cases} \\] equations , \\(q\\) quantile function Gamma distribution shape \\(\\alpha\\) scale \\(\\beta\\). \\(q\\) defined , \\(\\gamma\\) lower incomplete Gamma function. \\[q(F, \\alpha, \\beta) = \\beta \\gamma ^{-1}(\\alpha, p \\Gamma (\\alpha))\\] Likelihood Function probability density function (PDF) PE3 distribution given : \\[ f(x_{} : \\mu , \\sigma , \\kappa ) = \\frac{(x_{} - \\xi)^{\\alpha  - 1}e^{-(x_{} - \\xi )/\\beta }}{\\beta ^{\\alpha } \\Gamma (\\alpha )} \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[(\\alpha  - 1) \\ln |x_{} - \\xi | - \\frac{|x_{} - \\xi  |}{\\beta } - \\alpha \\ln\\beta  - \\ln \\Gamma (\\alpha )\\right] \\] L-Moments subsequent definitions assume \\(\\kappa > 0\\). \\(\\kappa < 0\\), L-moments can obtained changing signs \\(\\lambda_{1}\\), \\(\\tau_{3}\\), \\(\\xi\\) whenever appear. \\(\\kappa = 0\\), L-moments Normal Distribution. first two L-moments defined follows: \\(\\lambda_{1} = \\xi + \\alpha \\beta\\) \\(\\lambda_{2} = \\pi ^{-1/2} \\beta \\Gamma (\\alpha  + 0.5) / \\Gamma (\\alpha )\\) Rational approximation necessary determine \\(\\tau_{3}\\) \\(\\tau_{4}\\). \\(\\alpha \\geq 1\\): \\[ \\begin{aligned} \\tau_{3} &\\approx \\alpha^{-1/2} \\left(\\frac{A_{0} + A_{1}\\alpha^{-1} + A_{2}\\alpha^{-2} + A_{3}\\alpha^{-3}}{1 + B_{1}\\alpha^{-1} + B_{2}\\alpha ^{-2}}\\right)  \\\\[5pt] \\tau_{4} &\\approx \\frac{C_{0} + C_{1}\\alpha^{-1} + C_{2}\\alpha ^{-2} +C_{3}\\alpha ^{-3}}{1 + D_{1}\\alpha ^{-1} + D_{2}\\alpha ^{-2}} \\end{aligned} \\] \\(\\alpha < 1\\), use different set coefficients: \\[ \\begin{aligned} \\tau_{3} &\\approx \\frac{1 + E_{1}\\alpha  + E_{2}\\alpha ^2 + E_{3}\\alpha ^3}{1 + F_{1}\\alpha  + F_{2}\\alpha ^2 + F_{3}\\alpha ^3} \\\\[5pt] \\tau_{4} &\\approx \\frac{1 + G_{1}\\alpha + G_{2}\\alpha ^2 + G_{3}\\alpha ^3}{1 + H_{1}\\alpha + H_{2}\\alpha ^2 + H_{3}\\alpha ^3} \\end{aligned} \\] Coefficients given Appendix .9 Hosking, 19974. estimate parameters L-moments, use one two approximations \\(\\alpha\\) depending value \\(\\tau_{3}\\): \\[ \\alpha \\approx \\begin{dcases} \\frac{1 + 0.2906z}{z + 0.1882z^2 + 0.0442z^3}, &z = 3\\pi \\tau_{3}^2, &0 < |\\tau_{3}| < \\frac{1}{3} \\\\[5pt] \\frac{0.36067z - 0.59567z^2 + 0.25361z^3}{1 - 2.78861z + 2.56096z^2 - 0.77045z^3}, &z = 1 - |\\tau_{3}|, &\\frac{1}{3} \\leq |\\tau_{3}| < 1 \\end{dcases} \\] , can determine parameters approximated \\(\\alpha\\): \\[ \\begin{aligned} \\kappa &= 2\\alpha ^{-1/2} \\text{sign} (\\tau_{3}) \\\\[5pt] \\sigma &= \\lambda_{2} \\pi^{1/2}\\alpha ^{1/2} \\Gamma (\\alpha )/\\Gamma (\\alpha + 0.5)\\\\[5pt] \\mu &= \\lambda_{1 } \\end{aligned} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"log-pearson-type-iii-lp3-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Log-Pearson Type III (LP3) Distribution","title":"","text":"LP3 distribution uses reparameterization PE3 distribution. Support \\[ \\begin{cases} \\max(0, \\xi) \\leq  x < \\infty &\\kappa > 0 \\\\[5pt] 0 < x < \\infty  &\\kappa =0 \\\\[5pt] 0  < x \\leq \\max(0, \\xi) &\\kappa  < 0 \\end{cases} \\] Quantiles \\(x(F) = \\exp(x_{\\text{PE3}}(F ))\\), \\(x_{\\text{PE3}}(F)\\) quantile function PE3 distribution. Likelihood Function derive likelihood LP3 distribution, use fact : \\[ \\text{Data} \\sim \\text{LP3}  \\Leftrightarrow \\ln (\\text{Data}) \\sim \\text{PE3} \\] Precisely, require change variables formula, states : \\[ \\ell_{\\text{LP3}}(x ; \\mu, \\sigma, \\kappa) = \\ell_{\\text{PE3}}(\\ln x ; \\mu , \\sigma, \\kappa ) \\left|\\frac{d}{dx} \\ln  x\\right| = \\frac{\\ell_{\\text{PE3}}(\\ln x ; \\mu , \\sigma, \\kappa )}{x} \\] L-Moments PE3 distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"weibull-wei-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Weibull (WEI) Distribution","title":"","text":"Weibull distribution implemented reparameterized version generalized extreme value distribution: \\[ \\begin{aligned} \\kappa &= 1 / \\kappa_{\\text{GEV}} \\\\[5pt] \\sigma &= \\kappa \\sigma_{\\text{GEV} } \\\\[5pt] \\mu &= \\sigma + \\mu_{\\text{GEV} } \\end{aligned} \\] reparameterization, required \\(\\sigma > 0\\) \\(\\kappa > 0\\). Support \\(\\mu \\leq x < \\infty\\) Quantiles \\(x(F) = \\mu + \\sigma (-\\log (1 - F))^{1/\\kappa}\\) Likelihood Function probability density function (PDF) given \\(x_{} > \\mu\\): \\[ f(x_{} : \\mu, \\sigma, \\kappa) = \\frac{\\kappa}{\\sigma }\\left(\\frac{x_{} - \\mu}{\\sigma }\\right)^{\\kappa -1} \\exp \\left( - \\left(\\frac{x_{} - \\mu}{\\sigma }\\right)^{\\kappa } \\right) \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[\\ln \\kappa - \\kappa \\ln \\sigma +(\\kappa -1)\\ln (x_{}-\\mu ) - \\left(\\frac{x_{} - \\mu }{\\sigma }\\right) ^{\\kappa } \\right] \\] L-Moments First, reparameterize Weibull distribution recover GEV parameters: \\[ \\begin{aligned} \\kappa_{\\text{GEV}} &= 1 / \\kappa \\\\[5pt] \\sigma_{\\text{GEV}} &= \\sigma / \\kappa \\\\[5pt] \\end{aligned} \\] Next, compute L-moments GEV distribution \\(\\mu_{\\text{GEV}} = 0\\). , \\(\\lambda_{1} = \\mu + \\sigma - \\lambda_{1, \\text{GEV}}\\) \\(\\lambda_{2} = \\lambda_{2, \\text{GEV}}\\) \\(\\tau_{3} = -\\tau_{3, \\text{GEV}}\\) \\(\\tau_{4} = \\tau_{4, \\text{GEV} }\\) compute parameters L-moments, first flip sign \\(\\lambda_{1}\\) \\(\\tau_{3}\\). , estimate parameters GEV distribution get \\(\\hat{\\mu}_{\\text{GEV}}\\), \\(\\hat{\\sigma}_{\\text{GEV}}\\), \\(\\hat{\\kappa}_{\\text{GEV}}\\). Finally, reparameterize GEV parameters shown flip sign \\(\\mu\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"kappa-kap-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Kappa (KAP) Distribution","title":"","text":"Kappa distribution location \\(\\mu\\), scale \\(\\sigma\\), two shape parameters \\(\\kappa\\) \\(h\\). Support \\[ \\begin{cases} \\mu + \\sigma (1 - h^{-\\kappa}) \\leq x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa > 0, h > 0 \\\\[5pt] -\\infty < x \\leq \\mu + (\\sigma /\\kappa) & \\kappa > 0, h \\leq 0 \\\\[5pt] \\mu + \\sigma (1 - h^{-\\kappa}) \\leq x < \\infty &\\kappa \\leq 0, h > 0 \\\\[5pt] \\mu + (\\sigma / \\kappa ) \\leq x <\\infty &\\kappa  \\leq 0, h \\leq 0 \\end{cases} \\] Quantiles \\[ x(F) = \\mu + \\frac{\\sigma }{\\kappa }\\left[1 - \\left(\\frac{1 - F^{h}}{h}\\right)^{\\kappa }\\right] \\] L-Moments L-moments defined \\(h \\geq 0\\) \\(k > -1\\) \\(h < 0\\) \\(-1 < k < -1/h\\). \\(\\lambda_{1} = \\mu  + \\sigma (1 - g_{1})/\\kappa\\) \\(\\lambda_{2} = \\sigma(g_{1} - g_{2})/\\kappa\\) \\(\\tau_{3} = (-g_{1} + 3g_{2} - 2g_{3}) / (g_{1} - g_{2})\\) \\(\\tau_{4} = (-g_{1} + 6g_{2} - 10g_{3} + 5g_{4}) / (g_{1} - g_{2})\\) expression , \\(g_{r}\\) defined follows: \\[ g_{r} = \\begin{dcases} \\frac{r\\Gamma (1 + \\kappa )\\Gamma (r / h)}{h^{1 + \\kappa }\\Gamma (1 + \\kappa + r/h)} &h > 0 \\\\[5pt] \\frac{r\\Gamma (1 + \\kappa ) \\Gamma (-\\kappa  - r/h)}{(-h)^{1 + \\kappa }\\Gamma (1 - r/h)} &h < 0 \\end{dcases} \\] closed-form solution parameters terms L-moments. However, \\(\\tau_{3}\\) \\(\\tau_{4}\\) can computed terms \\(\\kappa\\) \\(h\\) using Newton-Raphson iteration.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"","text":"FFA framework implements three methods uncertainty quantification: Parametric bootstrap Regula-falsi profile likelihood (RFPL) Regula-falsi generalized profile likelihood (RFGPL)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"parametric-bootstrap","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Parametric Bootstrap","title":"","text":"parametric bootstrap flexible method uncertainty quantification works probability models parameter estimation methods. Let \\(n\\) size original dataset. Draw \\(N_{\\text{sim}}\\) bootstrap samples size \\(n\\) selected probability distribution. Fit probability distribution bootstrap sample using model selection method parameter estimation method used generate original distribution. Compute quantiles bootstrapped distributions. Generate confidence intervals using mean variance bootstrapped quantiles. Warning: parametric bootstrap known give unreasonably wide confidence intervals small datasets. FFA framework detects confidence interval 5+ times wider return levels , return error recommend RFPL uncertainty quantification1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"regula-falsi-profile-likelihood-rfpl","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Regula-Falsi Profile Likelihood (RFPL)","title":"","text":"Consider statistical model parameters \\((\\theta, \\psi_{1}, \\dots, \\psi_{n})\\). Profile Likelihood scalar parameter \\(\\theta\\) vector nuisance parameters \\(\\psi\\) defined : \\[ \\ell_{p}(\\theta) = \\max_{\\psi } \\ell(\\theta , \\psi) \\] Let \\(\\hat{\\theta}\\) MLE \\(\\theta\\). find confidence interval significance \\(1-\\alpha\\), find two solutions following equation (\\(\\chi_{1;1-\\alpha}^2\\) \\(1-\\alpha\\) quantile Chi-squared distribution): \\[ 2[\\ell_{p}(\\hat{\\theta }) - \\ell_{p}(\\theta )] = \\chi_{1;1-\\alpha }^2 \\] equivalent finding two points \\(\\theta_{L} < \\hat{\\theta} < \\theta_{U}\\) profile log-likelihood dropped \\(\\chi _{1;1-\\alpha }^2 / 2\\). find \\(\\theta_{L}\\) \\(\\theta_{U}\\) find roots \\(f(\\theta)\\) using secant-based algorithm. \\[ f(\\theta) = \\ell_{p}(\\theta) - \\left[\\ell_{p}(\\hat{\\theta}) - \\frac{\\chi_{1;1-\\alpha }^2}{2}\\right] \\] FFA framework, compute profile likelihood quantile \\(y\\) reparameterizing location parameter \\(\\mu\\). Let \\(q(p, \\mu, \\psi)\\) function takes exceedance probability \\(p\\), location parameter \\(\\mu\\) nuisance parameters \\(\\psi\\) returns quantile \\(y\\). quantile functions satisfy: \\[ y = q(p, \\mu, \\psi) = \\mu + q(p, 0, \\psi) \\] Therefore, can define \\(\\mu\\) function \\((p, y, \\psi)\\) shown : \\[ \\mu = y - q(p, 0, \\psi) \\] use relationship find profile likelihood \\(\\ell_{p}(y)\\) evaluating \\(\\mu(p, y, \\psi)\\) substituting log-likelihood functions listed . Warning: RFPL uncertainty quantification can numerically unstable datasets. FFA framework encounters issue, return error recommend parametric bootstrap2.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"handling-the-weibull-distribution","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Handling the Weibull Distribution","title":"","text":"Due support issues, use different reparameterization Weibull distribution: \\[ \\begin{aligned} &y = (\\mu_{0} + \\mu_{1}t) + (\\sigma_{0} + \\sigma_{1}t)(-\\log (1 - p))^{1/\\kappa}  \\\\[5pt] \\Rightarrow\\,&(\\sigma_{0} + \\sigma_{1}t) = \\frac{y - (\\mu_{0} + \\mu_{1}t)}{(-\\log (1 - p))^{1/\\kappa}} \\\\[5pt] \\Rightarrow\\,&\\sigma_{0} = \\frac{y - (\\mu_{0} + \\mu_{1}t)}{(-\\log (1 - p))^{1 / \\kappa }} - \\sigma_{1}t \\end{aligned} \\] derivation uses Weibull distribution trend mean variability. However, reparameterizations nonstationary structures can obtained easily setting \\(\\sigma_{1} = 0\\) /\\(\\mu_{1} = 0\\). solving \\(\\sigma_{0}\\) terms parameters, can use standard log-likelihood function.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"initialization-algorithm","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Initialization Algorithm","title":"","text":"can find roots \\(f\\), need identify initial values regula-falsi algorithm: Let \\(a_{0}\\) number \\(a_{0} < y\\) \\(f(a_{0}) < 0\\). Let \\(b_{0}\\) number \\(b_{0} > y\\) \\(f(b_{0}) < 0\\). find \\(a_{0}\\), start computing \\(f(^{*})\\) \\(^{*} = 0.95y\\). \\(f(^{*}) < 0\\), assign \\(a_{0} = ^{*}\\). Otherwise, update \\(^{*}\\) \\(0.95a^{*}\\) \\(f(^{*}) < 0\\). find \\(b_{0}\\), use similar process. However, instead iteratively revising \\(b^{*}\\) , revise \\(1.05b^{*}\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"iteration-algorithm","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Iteration Algorithm","title":"","text":"iteration \\(\\), compute following: \\[ c_{} = \\frac{a_{-1}f(b_{-1}) - b_{-1}f(a_{-1})}{f(b_{-1}) - f(a_{-1})} \\] Evaluate \\(\\ell_{p}(c_{})\\) maximizing nuisance parameters \\(\\psi\\), find \\(f(c_{})\\). \\(|f(c_{})| < \\epsilon\\) (\\(\\epsilon\\) small), stop. \\(c_{}\\) confidence interval bound. Otherwise, assign \\(a_{} = c_{}\\) \\(f(c_{}) < 0\\) \\(b_{} = c_{}\\) \\(f(c_{}) > 0\\) continue iteration \\(+ 1\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"regula-falsi-generalized-profile-likelihood-rfgpl","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Regula-Falsi Generalized Profile Likelihood (RFGPL)","title":"","text":"regula-falsi generalized profile likelihood (RFGPL) method performs regula-falsi algorithm shown GEV distributions \\(\\text{Beta}(p, q)\\) prior shape parameter \\(\\kappa\\). information generalized parameter estimation, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Handling Nonstationarity","title":"","text":"selected probability distribution nonstationary, quantiles (hence confidence intervals) bootstrapped distributions change time. See detailed discussion idea. default, FFA framework anchors uncertainty analysis last year dataset. However, model assessment requires confidence intervals every year dataset. Note: parametric bootstrap algorithm fastest algorithm computing confidence intervals years dataset probabilities used generate bootstrapped samples can reused. RFPL RFGPL algorithms far slower, since must run separately timestamp.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"changes-from-matlab-version","dir":"Articles","previous_headings":"","what":"Changes from MATLAB Version","title":"MATLAB Version","text":"page documents changes original MATLAB code.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"bug-fixes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Exploratory Data Analysis (EDA)","what":"Bug Fixes","title":"MATLAB Version","text":"show statistically significant change points Pettitt MKS plots. Fix bug causing MKS test identify one change point, even multiple change points found threshold statistical significance. Fix major bug causing MKS test identify change points based progressive series instead z-statistics crossing points. Remove unnecessary rounding moving window algorithm estimating variability. Re-implement Phillips-Perron KPSS tests account drift trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"framework-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Exploratory Data Analysis (EDA)","what":"Framework Changes","title":"MATLAB Version","text":"serial correlation identified, run Phillips-Perron KPSS tests. Add Runs test detect nonlinearity fitting Sen’s trend estimator. Run change point detection multiple stages prevent overpartitioning.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"distribution-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Distribution Changes","title":"MATLAB Version","text":"generalized Pareto (GPA) distribution removed, since likelihood function amenable maximum likelihood estimation. Issues occur GPA distribution intended peaks threshold modeling, use. R version uses three parameter Weibull distribution (location, scale, shape) parameters instead two parameter Weibull distribution (scale shape parameters). ensures consistency distributions, location parameters.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"model-selection-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Model Selection Changes","title":"MATLAB Version","text":"L-distance L-kurtosis selection methods improved using optimization algorithm find parameters closest L-moments data instead using brute force approach. computationally efficient gives precise results. procedure computing Z-statistic selection metric changed. L-moments dataset satisfy \\(\\tau_{4} \\leq (1 + 5\\tau _{3}^2)/6\\), Kappa distribution fitted candidate distributions use dataset omitted.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"parameter-estimation-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Parameter Estimation Changes","title":"MATLAB Version","text":"Parameterization PE3/LP3 distributions fails datasets MATLAB unable handle large numbers created gamma function. manage issue, MATLAB version used conventional moments (.e. sample mean/variance/skewness) occurred. avoid problem R version using lgamma (log-gamma) function. R implementation uses L-BFGS-B MLE/GMLE parameter estimation instead Nelder-Mead, since gradient well defined likelihood functions working . Additionally, L-BFGS-B method makes possible assign bounds variables. modification produced slight improvements MLL/GMLL datasets.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Uncertainty Quantification","title":"MATLAB Version","text":"Implement RFPL uncertainty quantification Weibull distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"model-assessment-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Model Assessment Changes","title":"MATLAB Version","text":"Use built-R function approx() perform log-linear interpolation return periods. MATLAB implementation uses hard-coded algorithm behaves unpredictably original interpolated \\(x\\)-values equal.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Nonstationary FFA","text":"vignette explore data Bow River Banff (05BB001), station Reference Hydrometric Basin Network. station unregulated, suggests trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"the-ns_structure-list","dir":"Articles","previous_headings":"Case Study","what":"The ns_structure List","title":"Nonstationary FFA","text":"vignette assumes scenario trend mean identified. specify trend one distribution parameters, create ns_structure (nonstationary model structure) list containing boolean items location scale. Setting items TRUE adds trend location/scale parameter respectively. Note: guidance trend detection, refer Trend Identification vignette.","code":"ns_structure <- list(location = TRUE, scale = FALSE)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"distribution-selection","dir":"Articles","previous_headings":"","what":"Distribution Selection","title":"Nonstationary FFA","text":"L-moment-based distribution selection remains applicable nonstationarity, requires dataset decomposition (detrending) prior analysis. select_* methods automatically (using data_decomposition method) ns_years ns_structure arguments supplied.  Note: sample log-sample points L-moment diagram based detrended data. Conclusion: generalized normal (GNO) distribution best-fit distribution sample.","code":"selection <- select_ldistance(     df$max,     ns_years = df$year,     ns_structure = ns_structure )  print(selection$recommendation) #> [1] \"GNO\"  plot_lmom_diagram(selection)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"Nonstationary FFA","text":"L-moments parameter estimation requires stationarity, use maximum likelihood estimation nonstationary model. fit_mle function implements maximum likelihood estimation stationary nonstationary distributions. two required arguments: data: annual maximum series observations. model: three-letter code corresponding probability distribution (ex. \"GNO\"). Since nonstationary model used, two additional arguments required: ns_years: corresponding vector years observations data. ns_structure: nonstationary structure object described .  Note: fitted parameters : \\((\\mu_0, \\mu_1, \\sigma, \\kappa)\\), time-dependent location modeled \\(\\mu(t) = \\mu_0 + \\mu_1 t\\). covariate \\(t\\) linear function years: \\((\\text{years} - 1900) / 100\\).","code":"fit <- fit_mle(     df$max,     \"GNO\",     ns_years = df$year,     ns_structure = ns_structure )  print(fit$params) #> [1] 224.0496619 -35.5153685  54.6324886  -0.3689085  print(fit$mll) #> [1] -590.7329  plot_nsffa_fit(fit, slices = c(1915, 2015))"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"Nonstationary FFA","text":"Uncertainty quantification important step NS-FFA well S-FFA. addition parametric bootstrap, framework implements regula-falsi profile likelihood (RFPL) method MLE. uncertainty_rfpl method two required arguments: data: annual maximum series observations. model: three-letter code corresponding probability distribution (ex. \"GNO\"). Since model nonstationary structure, three additional arguments required: ns_years: corresponding vector years observations data. ns_structure: nonstationary structure object described . ns_slices: years return levels computed.  Example Conclusion: 2025, \\(1/20\\) exceedance probability flood approximately \\(300\\text{m}^3/\\text{s}\\) greater. estimated return levels decreased approximately \\(50\\text{m}^3/\\text{s}\\) 1925 2025. Note: nonstationarity, return period reflects probability distribution fixed year rather long-run average. clarify difference stationary FFA, phrase “effective return period” used.","code":"uncertainty <- uncertainty_rfpl(     df$max,     \"GNO\",     ns_years = df$year,     ns_structure = ns_structure,     ns_slices = c(1915, 2015) )  plot_nsffa_estimates(fit, ci_list = uncertainty$ci_list)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Stationary FFA","text":"vignette explore data Athabasca River Athabasca (07BE001), unregulated hydrological monitoring station. statistical analysis data station reveal evidence trends mean variability data. Data station provided CAN-07BE001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-07BE001.csv\") head(df) #>   year  max #> 1 1913 1670 #> 2 1914 3090 #> 3 1915 2760 #> 4 1916 2080 #> 5 1917 2490 #> 6 1918 1470  plot_ams_data(df$max, df$year, title = \"Athabasca River at Athabasca (07BE001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"distribution-selection","dir":"Articles","previous_headings":"","what":"Distribution Selection","title":"Stationary FFA","text":"First, suitable probability distribution data selected using L-moments. select_ldistance chooses distribution theoretical L-skewness (\\(\\tau_3\\)) L-kurtosis (\\(\\tau_4\\)) closest sample, based Euclidean distance. select_lkurtosis selects distribution smallest difference sample theoretical L-kurtosis (three-parameter distributions ). select_zstatistic uses fitted 4-parameter Kappa distribution estimate sampling distribution L-kurtosis selects distribution smallest z-statistic.  Recommendation: Use generalized extreme value (GEV) distribution. Note: information distributions, see selection$metrics item.","code":"selection <- select_ldistance(df$max)  print(selection$recommendation) #> [1] \"GEV\"  plot_lmom_diagram(selection)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"Stationary FFA","text":"ffaframework package provides three methods parameter estimation: fit_lmoments: L-moments parameter estimation. fit_mle: Maximum likelihood parameter estimation. fit_gmle: Generalized maximum likelihood parameter estimation.  Conclusion: GEV distribution location = 1600, scale = 616, shape = 0.12 used.","code":"fit <- fit_lmoments(df$max, \"GEV\")  print(fit$params) #> [1] 1600.219872  616.666030    0.120747  plot_sffa_fit(fit)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"Stationary FFA","text":"probability distribution fitted, return levels (design events) can readily estimated. However, point estimates alone can misleading –informative report confidence intervals reflect estimation uncertainty. uncertainty_bootstrap function performs uncertainty quantification using parametric bootstrap method. requires three arguments: data: vector annual maximum series data. model: three-letter code probability distribution (ex. \"GEV\"). method: parameter estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". default, return levels computed 2-, 5-, 10-, 20-, 50-, 100- year return periods.  Example Conclusion: Every 10 years, can expect flood roughly \\(3{\\small,}200\\text{m}^3/\\text{s}\\) greater.","code":"uncertainty <- uncertainty_bootstrap(df$max, \"GEV\", \"L-moments\")  plot_sffa_estimates(fit, ci = uncertainty$ci)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"model-assessment","dir":"Articles","previous_headings":"","what":"Model Assessment","title":"Stationary FFA","text":"Model performance assessed using model_assessment, reports collection assessment statistics flood frequency analysis. plot_model_assessment compares empirical plotting positions (“Observed Quantiles”) predictions parametric model (“Model Quantiles”). black line represents perfect 1:1 correspondence model data.  Conclusion: parametric model generally matches plotting positions. small positive bias \\(3{\\small,}500\\text{m}^3/\\text{s}\\) \\(5{\\small,}000\\text{m}^3/\\text{s}\\).","code":"assessment <- model_assessment(df$max, \"GEV\", fit$params, ci = uncertainty$ci)  plot_model_assessment(assessment)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"list-of-tests","dir":"Articles","previous_headings":"","what":"List of Tests","title":"Trend Identification (Mean)","text":"Mean Trend Tests Stationarity Tests Variability Trend Tests Trend Estimation (Mean & Variability)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Trend Identification (Mean)","text":"vignette explore data Bow River Banff (05BB001) hydrological monitoring station. remoteness station means trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"mann-kendall-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Mann-Kendall Test","title":"Trend Identification (Mean)","text":"Mann-Kendall test non-parametric test used detect monotonic trends time series. null hypothesis, trend. Pass vector annual maximum series (AMS) data eda_mk_test() perform Mann-Kendall test. Conclusion: p-value \\(0.0067\\), reject null hypothesis. statistical evidence trend mean.","code":"mk_test <- eda_mk_test(df$max)  print(mk_test$p_value) #> [1] 0.006773098"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"spearman-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Spearman Test","title":"Trend Identification (Mean)","text":"Spearman test used check serial correlation, can cause Mann-Kendall test identify spurious trend. smallest lag serial correlation statistically significant known “least lag”.  Conclusion: least lag 1 provides evidence serial correlation.","code":"spearman_test <- eda_spearman_test(df$max)  print(spearman_test$least_lag) #> [1] 1  plot_spearman_test(spearman_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"further-tests","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Further Tests","title":"Trend Identification (Mean)","text":"Spearman test identified serial correlation, use BBMK test (eda_bbmk_test) check monotonic trend serial correlation. BBMK test uses reshuffling procedure remove serial correlation data. Phillips-Perron (eda_pp_test) KPSS (eda_kpss_test) tests used check unit root (stochastic trend) data. unit root extreme type serial correlation creates unpredictable variation data. Since find evidence serial correlation Spearman test, necessary apply tests. Phillips-Perron KPSS tests opposite hypotheses: Phillips-Perron assumes presence unit root null hypothesis, KPSS test .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Sen’s Trend Estimator","title":"Trend Identification (Mean)","text":"Mann-Kendall identified significant monotonic trend, estimate slope intercept. can estimate monotonic trend using Sen’s trend estimator, uses non-parametric approach robust outliers. eda_sens_trend() takes two arguments: annual maximum series corresponding vector years. , plot_ams_data() can used generate plot results. requires AMS data corresponding vector years. also takes optional arguments plot_mean plot_variability plotting trend mean variability respectively.  Note: covariate computed using formula \\((\\text{years} - 1900) / 100\\).","code":"sens_trend <- eda_sens_trend(df$max, df$year)  plot_ams_data(     df$max,     df$year,     plot_mean = \"Trend\",     title = \"Sen's Trend Estimator (AMS Mean)\" )"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"runs-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Runs Test","title":"Trend Identification (Mean)","text":"previous statistical tests assumed nonstationarity linear. runs test assess feasibility linearity assumption checking residuals randomness. residuals random (null hypothesis), evidence underlying trend linear. eda_runs_test() function takes residuals eda_sens_trend() first argument observation years second argument.  Conclusion: p-value \\(0.682\\), evidence linear trend suitable data.","code":"runs_test <- eda_runs_test(sens_trend$residuals, df$year)  print(runs_test$p_value) #> [1] 0.4392721  plot_runs_test(runs_test, title = \"Runs Test (AMS Mean)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Trend Identification (Mean)","text":"Mann-Kendall test identified evidence nonstationarity mean AMS. Spearman test find evidence serial correlation, validating results Mann-Kendall test. runs test found linear model suitable nonstationarity. Flood frequency analysis dataset requires time-dependent probability model. Recommendation: Use NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"list-of-tests","dir":"Articles","previous_headings":"","what":"List of Tests","title":"Trend Identification (Variability)","text":"Mean Trend Tests Stationarity Tests Variability Trend Tests Trend Estimation (Mean & Variability)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Trend Identification (Variability)","text":"vignette explore data Chilliwack River Chilliwack Lake (08MH016) hydrological monitoring station. remoteness station means trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-08MH016.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-08MH016.csv\") head(df) #>   year  max #> 1 1922 62.9 #> 2 1923 74.5 #> 3 1924 79.0 #> 4 1925 35.1 #> 5 1926 62.3 #> 6 1927 65.7  plot_ams_data(df$max, df$year, title = \"Chilliwack River at Chilliwack Lake (08MH016)\")"},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"mwmk-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"MWMK Test","title":"Trend Identification (Variability)","text":"MWMK test used detect trends variability time series. First, moving-window algorithm used estimate variability AMS data. , Mann-Kendall test applied series standard deviations check trend. data_mw_variability estimates moving-window standard deviations eda_mk_test function performs Mann-Kendall test. Conclusion: p-value \\(0.0015\\), reject null hypothesis. evidence linear trend variability data.","code":"mw <- data_mw_variability(df$max, df$year) mwmk_test <- eda_mk_test(mw$std) print(mwmk_test$p_value) #> [1] 0.001463998"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"white-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"White Test","title":"Trend Identification (Variability)","text":"White test checks heteroskedasticity, general time-dependence variability. null hypothesis homoskedasticity, constant variability data. Conclusion: p-value \\(0.1176\\), fail reject null hypothesis. statistical evidence heteroskedasticity.","code":"white_test <- eda_white_test(df$max, df$year) print(white_test$p_value) #> [1] 0.1175955"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"Sen’s Trend Estimator","title":"Trend Identification (Variability)","text":"previous tests provide evidence monotonic trend variability, estimate slope intercept trend. can estimate monotonic trend using Sen’s trend estimator, uses nonparametric approach robust outliers. eda_sens_trend() takes two arguments: data (either annual maximum series vector standard deviations) corresponding vector years. , plot_ams_data() can used generate plot results. requires AMS data corresponding vector years. also takes optional arguments plot_mean plot_variability plotting trend mean variability respectively.  Note: covariate computed using formula \\((\\text{years} - 1900) / 100\\).","code":"sens_trend <- eda_sens_trend(mw$std, mw$year)  plot_ams_data(     df$max,     df$year,     plot_mean = \"Constant\",     plot_variability = \"Trend\",     title = \"Sen's Trend Estimator (AMS Variability)\" )"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"runs-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"Runs Test","title":"Trend Identification (Variability)","text":"Sen’s trend estimator assumed nonstationarity linear. runs test assess feasibility linearity assumption checking residuals randomness. residuals random (null hypothesis), evidence underlying trend linear. eda_runs_test() function takes residuals eda_sens_trend() first argument observation years second argument.  Conclusion: p-value \\(0.3311\\), fail reject null hypothesis. evidence residuals random linear trend suitable data.","code":"runs_test <- eda_runs_test(sens_trend$residuals, mw$year)  print(runs_test$p_value) #> [1] 0.3311375  plot_runs_test(runs_test, title = \"Runs Test (AMS Variability)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Trend Identification (Variability)","text":"MWMK White tests find evidence nonstationarity variability AMS. runs test confirms linear model suitable nonstationarity. Flood frequency analysis dataset requires time-dependent probability model. Recommendation: Use NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Riley Wheadon. Author, maintainer. Cuauhtémoc Vidrio-Sahagún. Author. Alain Pietroniro. Author. Jianxun . Author.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Vidrio-Sahagún C, Ruschkowski J, J, Pietroniro (2024). “practice-oriented framework stationary nonstationary flood frequency analysis.” Environmental Modelling Software, 173(105940). doi:10.1016/j.envsoft.2024.105940.","code":"@Article{,   title = {A practice-oriented framework for stationary and nonstationary flood frequency analysis},   author = {Cuauhtémoc Vidrio-Sahagún and Jake Ruschkowski and Jianxun He and Alain Pietroniro},   journal = {Environmental Modelling and Software},   year = {2024},   volume = {173},   number = {105940},   doi = {10.1016/j.envsoft.2024.105940}, }"},{"path":"https://rileywheadon.github.io/ffa-package/index.html","id":"ffa-framework-wiki","dir":"","previous_headings":"","what":"Flood Frequency Analysis Framework","title":"Flood Frequency Analysis Framework","text":"FFA Framework open-source tool flood frequency analysis (FFA) designed support systematic repeatable workflows stationary nonstationary analysis. Development ongoing University Calgary University Saskatchewan Canada. recent version framework freely available R package. original version released stand-alone GUI MATLAB source code published Vidrio-Sahagún et al. (2024). list changes MATLAB version, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-05BB001 — CAN_05BB001","title":"CAN-05BB001 — CAN_05BB001","text":"dataframe annual maximum series observations station 05BB001, BOW RIVER BANFF Alberta, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-05BB001 — CAN_05BB001","text":"","code":"CAN_05BB001"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-05BB001 — CAN_05BB001","text":"dataframe 110 rows 2 columns spanning period 1909-2018.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-05BB001 — CAN_05BB001","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-05BB001 — CAN_05BB001","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-05BB001 — CAN_05BB001","text":"unregulated station RHBN. Whitfield & Pomeroy (2016) found floods may caused rain, snow, combination . Therefore, practitioners careful interpreting results FFA. Minimal human intervention basin means little justification change points. EDA finds evidence decreasing trend mean.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CAN-05BB001 — CAN_05BB001","text":"Whitfield P. H., Pomeroy J. W. (2016) Changes flood peaks mountain river: implications analysis 2013 flood Upper Bow River, Canada, Hydrological Processes, 30: 4657–4673. doi:10.1002/hyp.10957 .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-07BE001 — CAN_07BE001","title":"CAN-07BE001 — CAN_07BE001","text":"dataframe annual maximum series observations station 07BE001, ATHABASCA RIVER ATHABASCA Alberta, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-07BE001 — CAN_07BE001","text":"","code":"CAN_07BE001"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-07BE001 — CAN_07BE001","text":"dataframe 108 rows 2 columns spanning period 1913-2020.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-07BE001 — CAN_07BE001","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-07BE001 — CAN_07BE001","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-07BE001 — CAN_07BE001","text":"unregulated station RHBN. Additionally, MKS/Pettitt tests find evidence change points 0.05 significance level. Trend detection finds evidence trends mean variability. dataset excellent introductory example stationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08MH016 — CAN_08MH016","title":"CAN-08MH016 — CAN_08MH016","text":"dataframe annual maximum series observations station 08MH016, CHILLIWACK RIVER CHILLIWACK LAKE British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08MH016 — CAN_08MH016","text":"","code":"CAN_08MH016"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08MH016 — CAN_08MH016","text":"dataframe 95 rows 2 columns spanning period 1922-2016.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08MH016 — CAN_08MH016","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08MH016 — CAN_08MH016","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08MH016 — CAN_08MH016","text":"unregulated station RHBN. Additionally, MKS/Pettitt tests find evidence change points 0.05 significance level. Trend detection finds evidence increasing trend variability.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08NH021 — CAN_08NH021","title":"CAN-08NH021 — CAN_08NH021","text":"dataframe annual maximum series observations station 08NH021, KOOTENAI RIVER PORTHILL British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08NH021 — CAN_08NH021","text":"","code":"CAN_08NH021"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08NH021 — CAN_08NH021","text":"dataframe 91 rows 2 columns spanning period 1928-2018.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08NH021 — CAN_08NH021","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08NH021 — CAN_08NH021","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08NH021 — CAN_08NH021","text":"regulated station RHBN. Additionally, Libby dam constructed upstream station 1972. Pettitt test finds evidence change point 1972 0.05 significance level. MKS test finds evidence change points 1960 & 1985 0.05 significance level. dataset excellent introduction change point detection piecewise NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08NM050 — CAN_08NM050","title":"CAN-08NM050 — CAN_08NM050","text":"dataframe annual maximum series observations station 08NM050, OKANAGAN RIVER PENTICTON British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08NM050 — CAN_08NM050","text":"","code":"CAN_08NM050"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08NM050 — CAN_08NM050","text":"dataframe 97 rows 2 columns spanning period 1921-2017.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08NM050 — CAN_08NM050","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08NM050 — CAN_08NM050","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08NM050 — CAN_08NM050","text":"regulated station part RHBN. Okanagan River upstream station regulated since 1914 due construction first dam, followed second dam 1920, regulation system early 1950s, consisting four dams 38 km engineered channel. Rapid human settlement, development, agricultural activity also occurred watershed. dataset exhibits serial correlation trends mean variability. Since station heavily influenced reservoir operations, dataset intended teaching purposes—practical flood estimation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":null,"dir":"Reference","previous_headings":"","what":"Decompose Annual Maximum Series — data_decomposition","title":"Decompose Annual Maximum Series — data_decomposition","text":"Decomposes nonstationary annual maxima series derive stationary stochastic component, can used identify best-fit distribution using conventional stationary methods. decomposition procedure follows proposed Vidrio-Sahagún (2022), relies statistical representation nonstationary stochastic processes.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decompose Annual Maximum Series — data_decomposition","text":"","code":"data_decomposition(data, ns_years, ns_structure)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decompose Annual Maximum Series — data_decomposition","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decompose Annual Maximum Series — data_decomposition","text":"Numeric vector decomposed data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decompose Annual Maximum Series — data_decomposition","text":"Internally, function following: trend location, fit Sen's trend estimator subtract away fitted trend. trend scale, estimate variability data data_mw_variability(), fit Sen's trend estimator variability vector, rescale data remove trend. necessary, shift data minimum least 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decompose Annual Maximum Series — data_decomposition","text":"Vidrio-Sahagún, C. T., , J. (2022). decomposition-based nonstationary flood frequency analysis. Journal Hydrology, 612 (September 2022), 128186. doi:10.1016/j.jhydrol.2022.128186","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decompose Annual Maximum Series — data_decomposition","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE) data_decomposition(data, ns_years, ns_structure) #>   [1] 102.48618  75.49338  99.74332 105.94756 111.14916  81.37988  97.05781 #>   [8]  97.02208  96.57003  93.79310 105.55292 119.84636  82.81923 104.18640 #>  [15]  80.36503  93.70802  98.33514 104.22413  89.58643 103.34173 102.22271 #>  [22]  85.48077 105.83698 117.27727  97.35078  88.89977  98.03175  89.85637 #>  [29]  82.93328 107.34391  99.68818 100.29315 114.02480  98.84270  96.31536 #>  [36]  78.48746  94.72897  94.31990 108.06044  98.02072  90.86215  96.68674 #>  [43]  94.60457 101.50038 124.53960  97.38374 102.62853  97.96640  77.60025 #>  [50] 105.27133  94.15111  94.45562  96.64127  96.67811 101.81379  73.50738 #>  [57] 123.00711  92.50233  98.18111 106.72402  89.26269 106.98611  93.32063 #>  [64]  83.93697  85.88710 106.22919  96.82833 100.33093  78.38314  80.60329 #>  [71]  98.08517 108.54988  97.47665 108.22563 100.21480 100.97619  93.74237 #>  [78]  96.49655  93.80447 113.88418 107.55769 101.99468 100.00202  88.89021 #>  [85] 105.41115  68.11546  92.61488  98.44372  90.21832  98.21272 104.53487 #>  [92] 104.32399  93.38884  98.56437 110.36472  90.02529 102.96539 106.60318 #>  [99]  90.40153  89.42880"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Data from MSC GeoMet API — data_geomet","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"Gets annual maximum series data hydrological monitoring station MSC GeoMet API.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"","code":"data_geomet(station_id)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"station_id character scalar containing ID hydrological monitoring station. can search station IDs name, province, drainage basin, location .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"dataframe two columns: max: float, annual maximum series observation, m\\(^3\\)/s. year: integer, corresponding year.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"","code":"# Get data for the BOW RIVER AT BANFF (05BB001) df <- data_geomet(\"05BB001\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Local Package Data — data_local","title":"Fetch Local Package Data — data_local","text":"Fetch annual maximum series data hydrological monitoring station package data directory.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Local Package Data — data_local","text":"","code":"data_local(csv_file)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Local Package Data — data_local","text":"csv_file character scalar containing file name local dataset /inst/extdata. Must one : \"CAN-05BA001.csv\": BOW RIVER LAKE LOUISE \"CAN-05BB001.csv\": BOW RIVER BANFF \"CAN-07BE001.csv\": ATHABASCA RIVER ATHABASCA \"CAN-08MH016.csv\": CHILLIWACK RIVER CHILLIWACK LAKE \"CAN-08NH021.csv\": KOOTENAI RIVER PORTHILL \"CAN-08NM050.csv\": OKANAGAN RIVER PENTICTON \"CAN-08NM116.csv\": MISSION CREEK NEAR EAST KELOWNA","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Local Package Data — data_local","text":"dataframe two columns: max: float, annual maximum series observation, m\\(^3\\)/s. year: integer, corresponding year.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch Local Package Data — data_local","text":"","code":"# Get data for the BOW RIVER AT BANFF (05BB001) df <- data_local(\"CAN-05BB001.csv\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"Generates time series standard deviations using moving window algorithm, can used explore potential evidence nonstationarity variability dataset. returns list pairs window’s mean year window standard deviation. hyperparameters size step control behaviour moving window. Following simulation findings Vidrio-Sahagún (2022), default window size step set 10 5 years respectively. However, can changed user.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"","code":"data_mw_variability(data, years, size = 10L, step = 5L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. size Integer scalar. number years moving window. Must positive number less equal length(data) (default 10). step Integer scalar. offset (years) successive moving windows. Must positive number (default 5).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"list two entries: years: Numeric vector containing mean year within window. std: Numeric vector standard deviations within window.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"Vidrio-Sahagún, C. T., , J. (2022). decomposition-based nonstationary flood frequency analysis. Journal Hydrology, 612 (September 2022), 128186. doi:10.1016/j.jhydrol.2022.128186","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) data_mw_variability(data, years) #> $std #>  [1]  7.979322 11.091337 10.834792  7.833379  6.918857  8.207443  9.093049 #>  [8] 11.037079 10.865376  8.024952  8.950729 10.082149  9.835107  8.926596 #> [15] 13.342132 15.260867 11.322819  8.959743  7.579580 #>  #> $year #>  [1] 1905.5 1910.5 1915.5 1920.5 1925.5 1930.5 1935.5 1940.5 1945.5 1950.5 #> [11] 1955.5 1960.5 1965.5 1970.5 1975.5 1980.5 1985.5 1990.5 1995.5 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"Performs bootstrapped version Mann-Kendall trend test adjust serial correlation annual maximum series data. BBMK test uses Spearman’s serial correlation test identify least insignificant lag, applies shuffling procedure obtain empirical p-value confidence bounds Mann-Kendall test statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"","code":"eda_bbmk_test(data, alpha = 0.05, samples = 10000L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: Mann-Kendall S-statistic computed original series. bootstrap: Vector bootstrapped Mann-Kendall test statistics. p_value: Empirical two-sided p-value derived bootstrap distribution. bounds: Empirical confidence interval bounds bootstrap distribution. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"block size reshuffling equal least_lag estimated eda_spearman_test(). Bootstrap samples generated resampling blocks original data without replacement. procedure effectively removes serial correlation data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"Bayazit, M., 2015. Nonstationarity hydrological records recent trends trend analysis: state---art review. Environmental Processes 2 (3), 527–542. doi:10.1007/s40710-015-0081-7 Khaliq, M.N., Ouarda, T.B.M.J., Gachon, P., Sushama, L., St-Hilaire, ., 2009. Identification hydrological trends presence serial cross correlations: review selected methods application annual flow regimes Canadian rivers. Journal Hydrolology 368 (1–4), 117–130. doi:10.1016/j.jhydrol.2009.01.035 Sonali, P., Nagesh Kumar, D., 2013. Review trend detection methods application detect temperature changes India. Journal Hydrology 476, 212–227. doi:10.1016/j.jhydrol.2012.10.034","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_bbmk_test(data, samples = 1000L) #> $data #>   [1] 100.65487  89.01491  93.66822  79.36346 126.48932  88.46602  96.59362 #>   [8] 107.86363  87.29487 105.42142 100.75106 105.58514 104.15406  85.47700 #>  [15] 109.41206  96.61064  99.24426 100.40204 101.24301  90.01567 112.33390 #>  [22] 103.40424  95.27298 107.08753  84.71041 102.37425  86.87186 107.47029 #>  [29]  84.37482 100.71053  93.60465  91.54804 106.75245 111.53376  83.13495 #>  [36]  90.97185 113.17634 111.00190 112.03768  85.68729 113.82911 100.03126 #>  [43]  99.22113 104.41428 101.28923  91.69786  94.96407  88.06359  92.48277 #>  [50] 114.55841  91.71396 102.89774  95.19947  93.95171 114.60110 101.49679 #>  [57]  85.66679  99.89697  97.87764  90.93660  78.97848 118.93360  90.31874 #>  [64]  98.97397 102.39960 100.60899  78.22424  98.82140 101.12295 100.07886 #>  [71] 118.77744 121.58757 107.09715 107.66983  96.91789 110.12002  90.80948 #>  [78] 105.63380 103.22483 103.66674 111.29835  90.58502 102.17838 114.15412 #>  [85]  96.16267  98.25914  97.78255  89.90471 104.80725 116.04407  84.84975 #>  [92]  85.83976 108.76777 106.24132 121.12277  96.43876  89.35536 110.77117 #>  [99] 111.81576 101.98392 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There is no monotonic trend in the data.\" #>  #> $alternative_hypothesis #> [1] \"There is a monotonic trend in the data.\" #>  #> $statistic #> [1] 472 #>  #> $bootstrap #>    [1] -410 -276 -322 -136  538 1006  116  200  -44   80  148  234  -86   32 #>   [15]  360  146 -152  -28 -142   86 -134  550 -104 -148  166 -118  494 -124 #>   [29] -186  206  294 -338  262  270  148 -280 -174  522  342  106    2   78 #>   [43]    6  232 -146 -208  256  -58 -242  512   42  264  522 -218   88 -542 #>   [57] -244 -240   34  -42 -226  258  406 -300   80   76 -248  798 -642  434 #>   [71]  414 -138   34  616  500 -552  380 -568  286  110   44  334  390 -570 #>   [85]  266 -372  -42  434  516 -304  450  128  554   18 -356  738 -188 -374 #>   [99]  -96 -254  152  336  298 -532 -880   26 -128 -504 -442 -276  -28   36 #>  [113]  -76  -48  120  146  -94 -256  406   86 -180 -268  396  312  162  372 #>  [127] -372  336  -82  138   92 -146  576  -80  296   22  -76 -646  658 -532 #>  [141]  194 -214 -238  136  134  658 -156 -276  -54 -266 -508 -226  162  236 #>  [155]  148  236  112  106  488 -146  316 -562  190  428  694 -388  -10 -436 #>  [169]  256  710  610  106 -106   26   44  626  224 -264  112   14 -304   16 #>  [183]    2  -76  458  286 -256 -170 -526  448 -508  240  298  282  -36  728 #>  [197]  286   38 -344 -436 -430  348 -534 -270 -524   -2 -166  216 -406 -342 #>  [211]   80 -196  476  110  360  536  570 -204 -550 -348  154  288  158 -182 #>  [225] -136   20  370  288   74  164  404  -40 -224  708  230   44   48  204 #>  [239]  494 -324 -330 -138  -56 -132  116  528   20  240    4  -90 -350  -26 #>  [253] -952  274 -202  -98 -952  138 -442  490 -612   34  408  284 -248  122 #>  [267] -144  330 -104  690 -494 -444  -36 -936  196  230   82  390   92  -60 #>  [281]  152   66  104 -118 -150  -84   14 -420  252 -356  -26 -338   48 -276 #>  [295] -276  392  144  368 -176   20 -256  486  260  396 -382  562   16 -568 #>  [309] -418  -70  324  -66  310 -530  574  164  402 -340   46 -116   52 -192 #>  [323] -526  -12  386  -10  130  -50 -204  358  230  106 -544   54  320  276 #>  [337]  652 -528  -50  436 -192  134  -74 -130  -22 -482  330  230  408  324 #>  [351]  430  242  610  584 -132 -390  112 -518 -292  454  252   22  276 -230 #>  [365]  -70  422 -198  412  358  204 -386 -366 -540  360  152  178  594  170 #>  [379]  274 -420  194  -88 -692 -378 -358 -366 -480  118  -74   -6 -168   54 #>  [393]  132  398   80 -230  -84 -710 -358 -242  310  164  414   90  244 -478 #>  [407]  -64 -150  176 -360   72  280  -48 -176 -102  -64   68 -138   64 -224 #>  [421]  154   92  410  510 -114 -696 -206  310  302  172  100   98   84 -186 #>  [435]   36  180 -560    0  488 -104 -122 -238  624  308  184   28   54 -670 #>  [449]  626   14  -50  318   44 -160   34 -174  178 -848  600  -46  244  414 #>  [463] -296 -206  592 -298   86   56   88  530   42 -358 -500  214 -222  -20 #>  [477] -544  312  426  234 -254  316 -440 -366  360  -76 -156 -250   46 -452 #>  [491]   24   80  108  196  382 -470 -400  372 -360   90  576 -278  186 -368 #>  [505] -486 -224   -6  206 -406 -434 -312 -506 -872    8  218  -58 -132  132 #>  [519]  586 -102 -212  444   58    8 -622  344  298 -236  214 -232 -206   94 #>  [533] -148  256  606 -244 -144 -204  260 -174  158   32  538   54 -584 -406 #>  [547]  232   46  -10 -498   84  196 -446 -474  152   44 -290 -304  116 -286 #>  [561] -262 -190  110  340 -616  -50 -838 -416   96  130    8  192  292  312 #>  [575] -380  192   24  216 -490 -120  114  220  362   40  -78 -252    8  180 #>  [589]  194 -308   32  334 -208   52  -62  -12  420  468 -170 -180  144 -516 #>  [603]   14 -156   -6  700  388 -320 -316  552  -24   26  676 -116  -32 -596 #>  [617] -214 -652  644 -196 -276 -358  372 -428   72  -10   82  130    6  -96 #>  [631] -330  -68 -612  614 -310  712  -16 -114 -286 -316 -256 -138   76  506 #>  [645]  412 -328   10    6  100  600 -164  -40  546 -132 -152 -790   24 -254 #>  [659] -306  172  330    8  218   60  234  618  -68 -678  506 -276   18  266 #>  [673] -142  416 -120 -598 -336 -242   66 -292 -578  142 -498 -336 -236 -238 #>  [687]  216 -154 -270  428 -200 -112   82  -82 -384   92  210  194 -216  420 #>  [701]  382  482  -82  -20  100   28  -36 -300   58 -294 -740  282   94  -70 #>  [715]   22  242  -72  530  476  428  222  -54  592   10  242  354 -764  400 #>  [729] -218 -276  198 -142 -702 -204  154  162  364  -28 -334  414 -132 -194 #>  [743] -144   50  534  568  102 -190   10 -140   36 -548 -660  -24  702  148 #>  [757]  328  308  264 -120  -30   36 -324  388 -464  -56  340  236  148 -486 #>  [771]  562  176 -268 -436  622   72 -234 -366 -574   38  196 -558 -304  -66 #>  [785] -312 -948 -232  508 -118 -440 -496 -324 -244 -300  264  348 -180  -78 #>  [799]  -54  214 -242  504 -266  840   56   14  134  126 -170   52  192 -352 #>  [813]  -88 -282 -162  492  166 -258   64  -56 -282 -178  108   66  392  666 #>  [827]  206  204 -160  224 -304  350 -178 -230 -164  286 -366 -698  526 -836 #>  [841]  186  226 -116  306   42 -478  -70  224   44  -10 -428  346   34 -140 #>  [855] -474 -208 -824 -318  -20 -408 -314 -326  -42   74  560 -554   40  782 #>  [869]  120  160 -500  112  358 -100  -56   26 -108  168 -296  416  336 -438 #>  [883] -132 -488  -94  372  128   64 -332  -34   94 -104 -596 -486  442  160 #>  [897]  122  258   72 -660 -294 -366 -206 -492 -324 -648 -228 -468  700  706 #>  [911]  -20  -30  118  274 -140  296  296  680   44  162  -12 -660  434   86 #>  [925] -156 -106  214  320  294  392  410  192   -2   38 -160    0  -62   54 #>  [939]  186  224   50  -78 -346  400  210  322  472 -194 -110 -154  112  212 #>  [953]  254   36  470  482 -200  628 -478  458 -248  -50 -234  124  406  304 #>  [967]  -92   74 -178 -106  402  -30  318  178  552  -70  146 -388 -150 -106 #>  [981]   82  158  484 -404 -584  406  -48 -268   12 -194 -364  626 -430 -416 #>  [995]  478  340 -180 -428  172  -98 #>  #> $p_value #> [1] 0.172 #>  #> $bounds #>    2.5%   97.5%  #> -646.05  626.00  #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"Performs KPSS unit root test annual maximum series data. null hypothesis time series trend-stationary linear deterministic trend constant drift. alternative hypothesis time series unit root (also known stochastic trend).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"","code":"eda_kpss_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: KPSS test statistic. p_value: interpolated p-value. See details information. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"implementation KPSS test based aTSA package, interpolates significance table Hobijn et al. (2004). Therefore, result \\(p = 0.01\\) implies \\(p \\leq 0.01\\) result \\(p = 0.10\\) implies \\(p \\geq 0.10\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"Hobijn, B., Franses, P.H. Ooms, M. (2004), Generalizations KPSS-test stationarity. Statistica Neerlandica, 58: 483-502. Kwiatkowski, D.; Phillips, P. C. B.; Schmidt, P.; Shin, Y. (1992). Testing null hypothesis stationarity alternative unit root. Journal Econometrics, 54 (1-3): 159-178.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_kpss_test(data) #> $data #>   [1]  87.50984 102.95252  90.26103  73.53136 100.23273 111.47362 115.61049 #>   [8]  87.35983  88.33181  91.75555  94.76172  98.89976 121.99260  95.34879 #>  [15] 120.36984 100.39004  87.96905 119.83484  90.29670  85.67438 104.83300 #>  [22] 101.28824  84.71710 104.98693  86.50927  97.41662  83.55172  98.98267 #>  [29]  97.63843 106.02731 109.66670 107.35570 109.18831 102.81522 109.64195 #>  [36]  94.23139  97.94809 107.97812 108.19274 121.59665 104.90342 111.42943 #>  [43] 100.70440  93.71694  99.09350 105.10520  98.99026  81.75223 112.77722 #>  [50]  88.81335 110.26617 106.83853  90.09093  93.36497  98.52802  99.89112 #>  [57] 118.42932 103.24793 102.18773 106.94797  95.30401 100.08250  80.78876 #>  [64] 100.51796  94.84747  95.93285  92.80528  94.86763 105.97930 109.77976 #>  [71]  99.80091 114.75578 101.09780 100.12387  98.95186 107.50888  97.77118 #>  [78]  93.79625 113.14000 116.23621  88.10228 101.15881 116.18140  99.90063 #>  [85]  92.66700 106.42069 108.95565  91.35165 100.35780 107.02140 110.87775 #>  [92] 110.32847 112.30771  90.03516  90.82555  94.35715 103.97653  99.42904 #>  [99]  94.74145 104.28256 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The time series is trend-stationary.\" #>  #> $alternative_hypothesis #> [1] \"The time series has a unit root (stochastic trend).\" #>  #> $statistic #> [1] 0.04758024 #>  #> $p_value #> [1] 0.1 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann–Kendall Trend Test — eda_mk_test","title":"Mann–Kendall Trend Test — eda_mk_test","text":"Performs Mann–Kendall trend test numeric vector detect presence increasing decreasing monotonic trend time. test nonparametric accounts tied observations data. null hypothesis assumes monotonic trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann–Kendall Trend Test — eda_mk_test","text":"","code":"eda_mk_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann–Kendall Trend Test — eda_mk_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann–Kendall Trend Test — eda_mk_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: Mann–Kendall test statistic. variance: variance test statistic null hypothesis. p_value: p-value associated two-sided hypothesis test. reject: Logical. TRUE, null hypothesis rejected alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mann–Kendall Trend Test — eda_mk_test","text":"test statistic \\(S\\) sum pairs \\(< j\\) sign difference \\(x_j - x_i\\). Ties explicitly accounted calculating variance \\(S\\), using grouped frequencies tied observations. test statistic \\(Z\\) computed based sign magnitude \\(S\\), p-value derived standard normal distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mann–Kendall Trend Test — eda_mk_test","text":"Kendall, M. (1975). Rank Correlation Methods. Griffin, London, 202 pp. Mann, H. B. (1945). Nonparametric Tests Trend. Econometrica, 13(3): 245-25","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann–Kendall Trend Test — eda_mk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_mk_test(data) #> $data #>   [1] 116.11412  90.69241 103.37862 105.22782  82.64148 109.39183 105.45024 #>   [8]  84.75166  94.25823 111.23967  86.69933  97.37938  96.58283 111.08042 #>  [15] 114.25324  99.55259  98.79250 106.57130 110.35033  88.61991  93.08293 #>  [22] 100.83571 104.75665 102.37172  92.25124 103.24165 108.40478 116.61977 #>  [29] 111.01600 108.00191 104.89789 108.15966  75.26442  89.19149 105.21227 #>  [36]  86.71029 118.16608 102.27068  87.32682 106.03875  88.81822 103.22338 #>  [43] 102.98355 114.61274 119.20752  89.24305  93.12479 106.15612  99.96043 #>  [50] 100.60333  97.72133  91.09217  99.29099  87.82165  96.03174 116.78254 #>  [57] 119.72330  98.41525  96.38403  92.93475 108.29597  92.21121  96.49941 #>  [64]  94.03990  95.46888  87.32682  93.65167 106.19333 105.58708  99.05894 #>  [71]  99.19472 100.19550  97.85936 107.34841  99.84156  88.23479  97.79369 #>  [78] 115.64516 111.22041 104.63076 106.33357  95.12631  89.60322  75.68793 #>  [85] 102.59373  96.36258 110.89977 107.88251 105.74549  98.24206 100.42963 #>  [92] 101.62222  97.24310  99.82175 102.24486  83.05105  98.18668 108.51155 #>  [99] 105.74684 107.53031 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There is no monotonic trend in the data.\" #>  #> $alternative_hypothesis #> [1] \"There is a monotonic trend in the data.\" #>  #> $statistic #> [1] -60 #>  #> $variance #> [1] 112750 #>  #> $p_value #> [1] 0.8605227 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"Performs Mann–Kendall–Sneyers (MKS) test detect trend change annual maximum series data. test computes normalized progressive regressive Mann–Kendall statistics identifies statistically significant crossing points, indicating potential change points. null hypothesis, trend changes.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"","code":"eda_mks_test(data, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"list containing test results, including: data: data argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. progressive_series: Normalized progressive Mann–Kendall-Sneyers statistics. regressive_series: Normalized regressive Mann–Kendall-Sneyers statistics. bound: Critical confidence bound significance based alpha. change_points: dataframe potential change points. p_value: Two-sided p-value significant crossing point. reject: TRUE, null hypothesis rejected significance alpha. change_points contains years, test statistics, p-values potential change point. change points identified, change_points empty.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"function computes progressive regressive Mann–Kendall-Sneyers statistics, normalized expected values variances null hypothesis. crossing points occur difference progressive regressive statistics switches sign. significance detected crossing points assessed using quantiles normal distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"Sneyers, R. (1990). statistical analysis series observations. Technical note . 143, World Meteorological Organization, Geneva.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_mks_test(data, years) #> $data #>   [1]  85.09204  98.48259  96.75074 111.55520  98.43460 110.63326 102.35489 #>   [8] 120.92595  83.07251  89.94641 116.74478  95.62255 113.27158 114.27544 #>  [15]  84.60421 111.82677 106.54959 113.19297  95.98798  94.25990  81.96696 #>  [22] 100.44151 100.24345 111.49112  97.26690  94.35158 107.04075 105.20372 #>  [29] 107.43372 101.73053 109.10044  93.58330  88.93986  92.14111 105.30740 #>  [36] 112.18120  84.70178 105.51114  94.83542  96.01779 103.24808 107.26851 #>  [43]  96.57706  94.41080  96.02413  99.10775 110.40952 102.40919  96.55350 #>  [50]  91.02249  98.98338  92.13937  90.92910 114.08476 102.50388  94.02291 #>  [57]  94.74065  94.91006  92.55806  91.13979 118.16085  83.30854 111.22617 #>  [64] 107.17357  96.59280  99.14638 103.38835  96.73917 101.31666  98.82788 #>  [71] 108.98828 110.77115 107.69158  85.54915  85.71614  97.22417 101.68775 #>  [78] 109.77722 102.96900  97.91774  96.94300 102.01555  89.55891 110.86274 #>  [85]  85.63202 104.14338  97.27396 109.76791  93.27818 107.34289 103.56664 #>  [92] 101.41236 103.49810 109.90516  95.04841 101.62542 115.25917 102.32179 #>  [99]  94.17772  98.77404 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There are trend changes in the data.\" #>  #> $alternative_hypothesis #> [1] \"There is at least one trend change in the data.\" #>  #> $progressive_series #>   [1]  0.000000000  1.000000000  0.522232968  1.358732441  0.979795897 #>   [6]  1.315071011  1.351690671  1.979486637  0.834057656  0.268328157 #>  [11]  0.856348839  0.411435289  0.854124427  1.259132473  0.544358825 #>  [16]  0.810405304  0.823852555  1.098453328  0.734697000  0.324442842 #>  [21] -0.301969221 -0.253781368 -0.237694107  0.000000000 -0.140129810 #>  [26] -0.418789464 -0.229316010 -0.118539117  0.075032247  0.089205155 #>  [31]  0.288939088 -0.064865813 -0.433843555 -0.726397723 -0.582258714 #>  [36] -0.217934306 -0.601628535 -0.465160477 -0.641134244 -0.745666212 #>  [41] -0.651452411 -0.444332963 -0.554667287 -0.748455410 -0.841279499 #>  [46] -0.823729207 -0.559397660 -0.479954179 -0.586148819 -0.861580350 #>  [51] -0.852832167 -1.104750685 -1.365385099 -0.977312631 -0.863885270 #>  [56] -1.060130239 -1.197789713 -1.308057256 -1.510621544 -1.734796427 #>  [61] -1.331703750 -1.646076163 -1.370081699 -1.170311681 -1.188890886 #>  [66] -1.134491337 -1.001131697 -1.026919897 -0.953031061 -0.937886780 #>  [71] -0.719726334 -0.476402214 -0.285740204 -0.564675074 -0.827946905 #>  [76] -0.852123612 -0.782898632 -0.565199731 -0.469899066 -0.498559490 #>  [81] -0.546506476 -0.476530197 -0.719686431 -0.479022813 -0.736325519 #>  [86] -0.615424633 -0.641562445 -0.439699360 -0.616628533 -0.449597451 #>  [91] -0.346254058 -0.310297708 -0.212404716 -0.009798813 -0.138248896 #>  [96] -0.107617931  0.174532479  0.217920290  0.045347031  0.017868701 #>  #> $regressive_series #>   [1] -0.01786870  0.25092024  0.29158349  0.37399817  0.13927026  0.18326016 #>   [7] -0.02939644 -0.08628942 -0.39799054 -0.09941948  0.14986582 -0.15592905 #>  [13] -0.02883274 -0.31894819 -0.63034402 -0.33400333 -0.62582013 -0.79834069 #>  [19] -1.11724307 -1.01144482 -0.84755113 -0.52916562 -0.54794172 -0.56298329 #>  [25] -0.87903278 -0.83709549 -0.66734327 -0.85722061 -1.03058438 -1.26572562 #>  [31] -1.35359876 -1.62636822 -1.45039202 -1.17430042 -0.94633180 -1.14359980 #>  [37] -1.50634177 -1.18028683 -1.40311289 -1.24458294 -1.10975948 -1.27520000 #>  [43] -1.52271281 -1.43184058 -1.25802122 -1.12522871 -1.14144147 -1.48811634 #>  [49] -1.64134387 -1.53509790 -1.26309352 -1.27573566 -1.01323660 -0.70612492 #>  [55] -1.12671007 -1.27170157 -1.03165475 -0.80583738 -0.57438163 -0.26956651 #>  [61]  0.06990621 -0.39919679  0.06285952 -0.39236644 -0.65380292 -0.38343867 #>  [67] -0.31131331 -0.46483238 -0.19459744 -0.11897492 -0.01784103 -0.33764511 #>  [73] -0.82977382 -1.22996769 -0.72737117 -0.23354968  0.04960881  0.07923137 #>  [79] -0.36657309 -0.54354460 -0.38933141 -0.10495671 -0.11363310  0.49431153 #>  [85] -0.09004503  0.64333316  0.38321423  0.85412443  0.41143529  1.32344821 #>  [91]  0.98386991  0.62554324  0.98974332  0.75093926  0.18786729  0.97979590 #>  [97]  1.35873244  0.52223297 -1.00000000  0.00000000 #>  #> $bound #> [1] 1.959964 #>  #> $change_points #> [1] index     year      value     statistic p_value   #> <0 rows> (or 0-length row.names) #>  #> $p_value #> [1] 0.2340706 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Performs nonparametric Pettitt test detect single abrupt change mean time series. null hypothesis, change point.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"","code":"eda_pettitt_test(data, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"list containing test results, including: data: data argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. u_series: Numeric vector absolute U-statistics years. statistic: test statistic maximum absolute U-statistic. bound: critical value test statistic based alpha. change_points: dataframe containing potential change point. p_value: asymptotic approximation  p-value test. reject: Logical scalar. TRUE, null hypothesis rejected. change_points contains years, test statistics, p-values potential change point. change points identified, change_points empty.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Pettitt, .N., 1979. Non-parametric Approach Change-point Problem. J. Royal Statistics Society 28 (2), 126–135. http://www.jstor.org/stable/2346729","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_pettitt_test(data, years) #> $data #>   [1] 110.10684 109.21671  99.00200  94.00343  89.97952  96.54386  96.87132 #>   [8] 118.40742  81.72863 100.76640 100.55287 103.52433  99.65863 104.98293 #>  [15] 123.86866  86.82425  89.81833  78.07199 109.07017 105.91076  95.54329 #>  [22] 109.39690  79.70020  95.64596  94.12719 107.52656 106.84281  90.71340 #>  [29] 103.15814 101.68861  89.16990  94.98362 107.85188 104.65562 106.01239 #>  [36]  98.39976  97.98901 103.80865 104.51256  96.98454  85.77457  88.90572 #>  [43]  99.96630 121.10423 111.00964  87.02501  87.80226  95.98337 124.83532 #>  [50] 100.11715  88.47333 112.44132 119.73193  89.69074 106.60512 106.76343 #>  [57] 112.06801  90.97239 104.50397 107.26423 112.04740 113.73421  93.75126 #>  [64] 100.81992 112.55942  88.79528  87.33852 100.56045 113.85555  98.87681 #>  [71]  79.61201  93.19376  92.09872  93.18624 103.82141 102.02935 112.10449 #>  [78]  85.42835 107.26397  88.20753 108.59298 100.01181  90.54158 111.24859 #>  [85] 116.50599  99.71808  95.68262 109.62970 101.42725  92.26551  98.38343 #>  [92] 102.72831 111.78279  99.34285  96.73675 106.16976 114.48573 104.01289 #>  [99] 107.36656 106.75189 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There are no abrupt changes in the mean of the data.\" #>  #> $alternative_hypothesis #> [1] \"There is one abrupt change in the mean of the data.\" #>  #> $u_series #>   [1]  65 124 107  60   5  38  67  24  69  68  71  56  69  40  57  30  97 196 #>  [19] 139 108 149  88 183 222 267 216 173 234 221 214 285 328 275 248 215 236 #>  [37] 261 244 219 246 335 408 417 322 255 340 421 456 357 362 439 360 267 336 #>  [55] 299 258 183 242 219 172  99  16  65  62  19  56 139 140  55  74 171 222 #>  [73] 279 332 313 304 227 318 273 352 297 304 367 298 209 220 257 194 189 244 #>  [91] 267 256 185 200 231 196 109  88  39  39 #>  #> $statistic #> [1] 456 #>  #> $bound #> [1] 710.1279 #>  #> $p_value #> [1] 0.291 #>  #> $change_points #> [1] index     year      value     statistic p_value   #> <0 rows> (or 0-length row.names) #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Phillips–Perron Unit Root Test — eda_pp_test","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"Applies Phillips–Perron (PP) test check unit root annual maximum series data. null hypothesis assumes time series contains unit root (also known stochastic trend). alternative hypothesis time series trend-stationary deterministic linear trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"","code":"eda_pp_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: PP test statistic. p_value: Reported p-value test. See details information. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"implementation test based aTSA package, interpolates p-values table critical values presented Fuller W. . (1996). critical values available \\(\\alpha \\geq 0.01\\). Therefore, reported p-value 0.01 indicates \\(p \\leq 0.01\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"Fuller, W. . (1976). Introduction Statistical Time Series. New York: John Wiley Sons Phillips, P. C. B.; Perron, P. (1988). Testing Unit Root Time Series Regression. Biometrika, 75 (2): 335-346","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_pp_test(data) #> $data #>   [1] 105.71910  95.62950 115.22793  90.09813 101.21090 105.45931 108.28352 #>   [8]  94.04016  97.61715 104.73747 103.40918  96.95804 107.33999 103.13770 #>  [15] 111.29980 103.81615 103.68654 108.84609 109.21164 117.78567  92.96911 #>  [22]  75.93637  99.68249  97.04275 106.00636 111.60364 100.56538  95.59872 #>  [29]  98.35395  90.02786  76.48258  97.01634  78.53935  97.08140  93.10026 #>  [36]  94.97523 106.05890  97.37607  96.90605 119.81818  94.51492  92.73484 #>  [43] 101.06323 114.59809  93.10381 114.15768 100.04895 101.07439  98.37847 #>  [50]  89.26774 100.03078 110.44615  98.93937 107.17062  87.33825  69.94219 #>  [57] 108.75675 106.93614 112.83858 109.99143  86.73613  81.15200 101.48586 #>  [64]  99.01536  91.65490 102.34030 104.16639  89.90877  92.40957  81.75752 #>  [71]  98.91953 104.97110 115.84434 105.76548 116.35644 105.87302  91.87373 #>  [78] 100.21493 102.16915 106.43384  90.75542 112.09305 115.66475 106.29210 #>  [85]  93.57340 109.91148 123.90197 111.88599 107.95127 112.67272  96.37174 #>  [92]  90.85030 109.63619 110.11232 103.51880  85.45366  96.87146 101.49090 #>  [99]  85.91269 110.95705 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The time series has a unit root (stochastic trend).\" #>  #> $alternative_hypothesis #> [1] \"The time series is trend-stationary.\" #>  #> $statistic #> [1] -79.64662 #>  #> $p_value #> [1] 0.01 #>  #> $reject #> [1] TRUE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Applies Wald–Wolfowitz runs test numeric vector order assess whether behave random sequence. test statistic p-value computed using number runs (sequences values median). null hypothesis, data random.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"","code":"eda_runs_test(values, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"values numeric vector values check randomness. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"list containing test results, including: values: values argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. n: length input vector removing median. runs: number runs transformed sequence residuals. statistic: runs test statistic, computed using runs n. p_value: p-value derived normally distributed test statistic. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Wald, . Wolfowitz, J. (1940). test whether two samples population. Annals Mathematical Statistics, 11(2), 147–162.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) sens_trend <- eda_sens_trend(data, years) eda_runs_test(sens_trend$residuals, years) #> $values #>   [1]   3.4591070  -0.2548210   4.0780276  -5.7121758  -4.1019963   5.8170220 #>   [7]  18.3759451   7.8448449 -19.3704826   3.1951557  -4.8548835 -14.0041231 #>  [13]  15.8960238   9.7043435   7.7599675  -2.6344192  12.4022537   5.2769517 #>  [19]   5.9751249  -0.3766194  -8.9044044   0.4777749  -2.8826902  -7.0580551 #>  [25]  -6.4190872   4.2534043   0.2057172  14.2050622 -13.0367103  -2.4429078 #>  [31]  -6.3697003 -13.2841977  -5.0320028 -11.9802453  -3.8846573  -5.7262198 #>  [37]   4.5316228   7.6894095  10.4028158  10.9720948  -3.2556775   2.3393429 #>  [43] -10.4254574   8.8172799   1.9941589  -4.5579976  20.0140418   3.7121135 #>  [49]  -2.5697982  -9.5932598  -9.0913520 -16.7248099 -12.6076036   1.1704120 #>  [55]  14.2431448   5.5670667  -2.7751031  -7.6384031   0.4798927  18.3112193 #>  [61] -13.8913171  -5.2786273   9.3185863   7.5079721  -9.9864054   8.2432909 #>  [67]  -0.2057172   3.8273357  14.6473824  -0.8514123   3.0004590   7.0521799 #>  [73]  12.6558942  23.8521577 -11.5999526 -10.6746966 -11.1816573  -3.1532257 #>  [79]  -2.8515510   6.4116198 -14.4396657   3.4544708  -0.4803302  -6.9933186 #>  [85]   5.9791544   6.2065308  -7.1883797  16.3031722  -8.8611832   4.9651717 #>  [91]  13.5735386  23.8327449  18.3549657 -15.3155336  -4.2107676  20.1174146 #>  [97] -11.5633922   2.9811871  -7.6860026  -6.6695637 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The input vector is random.\" #>  #> $alternative_hypothesis #> [1] \"The input vector is not random.\" #>  #> $n #> [1] 100 #>  #> $runs #> [1] 50 #>  #> $statistic #> [1] -0.2010178 #>  #> $p_value #> [1] 0.8406846 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"Sen's Trend Estimator — eda_sens_trend","title":"Sen's Trend Estimator — eda_sens_trend","text":"Computes Sen's linear trend estimator univariate time series. estimated slope y-intercept given terms data covariate, derived years using formula \\((\\text{Years} - 1900) / 100\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sen's Trend Estimator — eda_sens_trend","text":"","code":"eda_sens_trend(data, years)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sen's Trend Estimator — eda_sens_trend","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sen's Trend Estimator — eda_sens_trend","text":"list containing estimated trend: data: data argument. years: years argument. slope: estimated slope. intercept: estimated y-intercept. residuals: Vector differences predicted observed values.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sen's Trend Estimator — eda_sens_trend","text":"Sen's slope estimator robust, nonparametric trend estimator based median pairwise slopes data points. corresponding intercept median \\(y_i - mx_i\\) \\(m\\) estimated slope.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sen's Trend Estimator — eda_sens_trend","text":"Sen, P.K. (1968). Estimates regression coefficient based Kendall's tau. Journal American Statistical Association, 63(324), 1379–1389.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sen's Trend Estimator — eda_sens_trend","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_sens_trend(data, years) #> $data #>   [1] 106.92862 100.25897 102.30677 113.45502  84.21815  98.97677  82.43465 #>   [8] 103.70060 105.35396  91.20770  97.68624  93.26708 104.92886  79.27116 #>  [15]  97.78326 101.73428 106.31450 103.22489  73.27027  95.80033 103.70320 #>  [22] 102.10024  99.97592  83.25465  99.17297  91.39310 105.19352  93.22492 #>  [29]  99.17705  84.72953 118.55731 103.49558  82.49623  96.23500  98.72704 #>  [36] 105.71291  97.50484 108.02381 117.10142  95.18903  86.38487  80.38076 #>  [43] 103.62647  90.84430 112.93500 109.10819  91.70940  97.33396 118.54191 #>  [50] 125.12024  96.60533 101.08595 114.59925  91.33009  91.55568 100.06430 #>  [57] 112.65379  87.15250  79.90941 100.66470  96.72762  97.51682  85.97496 #>  [64] 101.36356  93.11784 102.07516 104.08187 106.84038 108.13680  95.52265 #>  [71] 121.98109 121.29389 110.50041  71.14720 114.04081  85.53392  97.67344 #>  [78]  90.89083 103.29376  99.21390  98.90397  89.27138 103.95860 108.25451 #>  [85] 108.57277  98.29088 101.00560  95.65229  95.56905  89.66521 122.50497 #>  [92]  94.90634 107.83315 106.31107 111.51340 102.09891  98.66040 107.10639 #>  [99] 102.32650  93.56602 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $slope #> [1] 4.073809 #>  #> $intercept #> [1] 98.07508 #>  #> $residuals #>   [1]   8.81280410   2.10240745   4.10947612  15.21698100 -14.06061752 #>   [6]   0.65726046 -15.92560351   5.29961713   6.91223949  -7.27476579 #>  [11]  -0.83696179  -5.29685538   6.32418254 -19.37425178  -0.90289104 #>  [16]   3.00739133   7.54687039   4.41652710 -25.57883673  -3.08950872 #>  [21]   4.77262151   3.12892459   0.96386544 -15.79814328   0.07943578 #>  [26]  -7.74117533   6.01850770  -5.99082596  -0.07943578 -14.56769291 #>  [31]  19.21934370   4.11687477 -16.92320726  -3.22517479  -0.77387587 #>  [36]   6.17125220  -2.07755547   8.40067587  17.43755213  -4.51557266 #>  [41] -13.36047035 -19.40531874   3.79965319  -9.02325725  13.02670623 #>  [46]   9.15915834  -8.28037423  -2.69654990  18.47065789  25.00825173 #>  [51]  -3.54739108   0.89248606  14.36504662  -8.94484585  -8.76000051 #>  [56]  -0.29211471  12.25663939 -13.28538916 -20.56921799   0.14533092 #>  [61]  -3.83248368  -3.08402654 -14.66662587   0.68123669  -7.60521663 #>  [66]   1.31136327   3.27733533   5.99510320   7.25079120  -5.40409794 #>  [71]  21.01360311  20.28566444   9.45144431 -29.94250111  12.91036975 #>  [76] -15.63725540  -3.53847814 -10.36182353   2.00037202  -2.12023325 #>  [81]  -2.47089906 -12.14422362   2.50225456   6.75742932   7.03494788 #>  [86]  -3.28768030  -0.61369798  -6.00774504  -6.13171757 -12.07630191 #>  [91]  20.72271847  -6.91664208   5.96942836   4.40660696   9.56820195 #>  [96]   0.11296797  -3.36627632   5.03897227   0.21835134  -8.58287229 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Spearman Test for Autocorrelation — eda_spearman_test","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"Performs Spearman serial correlation test annual maximum series data check serial correlation various lags. Reports smallest lag serial correlation statistically significant given significance level (least insignificant lag).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"","code":"eda_spearman_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. rho: Numeric vector serial correlation estimates lags \\(1\\) \\(n-3\\). least_lag: smallest lag serial correlation insignificant. significant: Indicates whether serial correlation significant lag. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_spearman_test(data) #> $data #>   [1] 115.53949  97.62048  91.48151 103.99375  78.75553 109.02592 109.87513 #>   [8]  91.57034  75.35796  83.06758 111.02988 110.79918  97.81132 115.99110 #>  [15]  97.49414 114.96522 104.48972 101.82078  93.83436  86.25984  92.93219 #>  [22] 108.05278 101.79365 100.54119  84.71055 104.00399  96.18705 100.58256 #>  [29] 103.80280 101.53855 114.89921 104.92200 103.21021 101.94214 107.42460 #>  [36] 116.84394  92.50584 104.87693 100.38928  91.57844 110.66950 112.50907 #>  [43]  99.43985 111.01152 108.60272  94.35932  79.94742 102.48602 102.09311 #>  [50] 105.64982 104.92798  97.24127 102.44770 101.24951 102.63553  93.00900 #>  [57]  79.43679 102.37812  99.58353 106.73590  90.05232 106.93567 105.46208 #>  [64] 113.96973  95.44503 104.04250 103.99922  76.23319 104.59000 111.99336 #>  [71] 106.43052 102.14418 113.51713  86.05348  86.47162 106.82030  93.79462 #>  [78] 101.08264 111.23510  95.33119 103.83775  77.06348 117.92758  78.22464 #>  [85]  91.43614 109.47363 105.26578  81.73983 112.47440  99.33391 109.85445 #>  [92] 112.67286 100.08714  87.93782  95.52039  88.28031 107.00460 115.12215 #>  [99] 101.99070  93.67655 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The least insignificant lag is 1.\" #>  #> $alternative_hypothesis #> [1] \"The least insignificant lag is greater than 1.\" #>  #> $rho #>  [1] -0.088620903 -0.124393525 -0.013412582 -0.135349973 -0.056187010 #>  [6]  0.128158075 -0.026707648 -0.108564647 -0.045548654  0.208494876 #> [11] -0.144603337 -0.053661372 -0.036104833 -0.091806217 -0.047058824 #> [16]  0.060443454 -0.076445153 -0.039170231  0.236833785  0.088185654 #> [21] -0.068597858  0.107424221 -0.178978916 -0.204812030  0.098890469 #> [26] -0.151958534  0.031685795  0.336356036  0.124346076 -0.154614644 #> [31]  0.077968579 -0.023743177 -0.218173837  0.074793863  0.114597902 #> [36] -0.162042125  0.122503840  0.277731611 -0.141882602 -0.176382328 #> [41]  0.039625950 -0.038973823 -0.132745657  0.055502392 -0.113492063 #> [46] -0.290032399  0.280519271  0.296337403 -0.068506787  0.026458583 #> [51] -0.096632653 -0.169778550  0.094935245 -0.024360160  0.049407115 #> [56]  0.115715292  0.180761099 -0.138157362  0.053832753  0.006754221 #> [61] -0.100000000 -0.049786629  0.079895685 -0.175546976  0.156022409 #> [66]  0.023682200  0.075200535 -0.348240469  0.267741935 -0.155951057 #> [71] -0.171921182  0.200875753 -0.131257631 -0.187008547  0.523076923 #> [76]  0.039130435  0.015810277 -0.169960474  0.183116883  0.037593985 #> [81] -0.108771930 -0.011351909 -0.284313725 -0.150000000  0.496428571 #> [86]  0.221978022 -0.109890110 -0.188811189 -0.463636364  0.127272727 #> [91]  0.850000000  0.142857143 -0.535714286 -0.257142857 -0.400000000 #> [96]  0.000000000  1.000000000 #>  #> $least_lag #> [1] 1 #>  #> $significant #>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE #> [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [73] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [85] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE #> [97]  TRUE #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":null,"dir":"Reference","previous_headings":"","what":"White Test for Heteroskedasticity — eda_white_test","title":"White Test for Heteroskedasticity — eda_white_test","text":"Performs White test heteroskedasticity regressing squared residuals linear model original regressors squared terms. null hypothesis homoskedasticity.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"White Test for Heteroskedasticity — eda_white_test","text":"","code":"eda_white_test(data, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"White Test for Heteroskedasticity — eda_white_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"White Test for Heteroskedasticity — eda_white_test","text":"list containing results White test: data: data argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: White test statistic based sample size r_squared. p_value: p-value derived Chi-squared distribution df = 2. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"White Test for Heteroskedasticity — eda_white_test","text":"White test regresses squared residuals primary linear model lm(data ~ years) original regressor square. test statistic calculated \\(nR^2\\), \\(R^2\\) coefficient determination auxiliary regression \\(n\\) number elements time series. null hypothesis, test statistic \\(\\chi^2\\) distribution 2 degrees freedom.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"White Test for Heteroskedasticity — eda_white_test","text":"White, H. (1980). heteroskedasticity-consistent covariance matrix estimator direct test heteroskedasticity. Econometrica, 48(4), 817–838.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"White Test for Heteroskedasticity — eda_white_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_white_test(data, years) #> $data #>   [1] 106.48141 101.00782  82.42012 109.38275  84.40313  97.26097 107.97217 #>   [8]  96.08833 109.67785  93.54223 100.93528 107.62956  94.67642  97.07130 #>  [15] 102.06642  79.20201 108.58147 107.13222  84.83731 109.16774  89.74668 #>  [22]  91.85919 108.46643  94.93178 107.50644 106.77331 101.41293  85.65508 #>  [29]  86.16541  92.84438 122.92140  90.07804 104.59519  97.62281 108.35991 #>  [36]  93.65053  80.76932  98.64659 108.60061 113.31049  83.67603  97.24631 #>  [43]  97.62521 107.06400  99.04726 127.25076 106.30267  88.88680  96.44126 #>  [50] 110.38200  87.75264  93.26501 118.97439  96.53224  78.59880 124.76428 #>  [57]  95.97234 103.79369  92.51198 105.05991  94.64354 103.41252  92.41732 #>  [64]  95.76410  88.48226 115.30293 101.12761  98.74202  85.32868 109.61289 #>  [71] 109.64497 112.58596  84.62194 107.85550 103.97192 106.98846 104.50714 #>  [78] 106.40800 112.20660 110.78431  96.80989  87.26127  93.49333  92.57200 #>  [85]  87.74771  96.87723 110.71671  98.46020  91.09966  84.26416 105.62013 #>  [92]  94.57179 111.64665 103.88534 108.28514 100.32738  93.51255  98.24003 #>  [99]  91.33492 102.79443 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The data is homoskedastic.\" #>  #> $alternative_hypothesis #> [1] \"The data is heteroskedastic.\" #>  #> $statistic #> [1] 4.015465 #>  #> $p_value #> [1] 0.1342928 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/ffaframework-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Flood Frequency Analysis Framework — ffaframework-package","title":"Flood Frequency Analysis Framework — ffaframework-package","text":"package provides tools stationary (S-FFA) nonstationary (NS-FFA) flood flood frequency analysis annual maximum series data. Methods framework_* prefix orchestrate EDA /FFA modules Vidrio-Sahagún et al. (2024) generate reports. Users wish develop customized workflows may use methods following prefixes: eda_*: Explore annual maximum series data evidence nonstationarity inform approach selection (S-FFA NS-FFA): Detect statistically significant change points. Detect statistically significant temporal trends mean variability. select_*: Select suitable probability distribution using L-moments. fit_*: Fit parameters given distribution approach (S-FFA NS-FFA). uncertainty_*: Compute return level estimates confidence intervals. model_assessment() evaluates model performance using variety metrics. Additional utility functions visualization computation also available: data_* methods load, transform, decompose annual maximum series data. plot_* methods produce diagnostic summary plots. utils_* methods implement distribution-specific computations. Datasets five hydrometric stations Canada provided representative use cases (datasets /inst/extdata testing purposes ): Athabasca River Athabasca (CAN-07BE001): unregulated station statistical evidence trends change points (S-FFA recommended). Kootenai River Porthill (CAN-08NH21): regulated station outside evidence abrupt change mean 1972 (piecewise NS-FFA recommended). Bow River Banff (CAN-05BB001). unregulated station statistical evidence trend mean (NS-FFA recommended). Chilliwack River Chilliwack Lake (CAN-08MH016): unregulated station statistical evidence linear trend variability (NS-FFA recommended). Okanagan River Penticton (CAN-08NM050): regulated station statistical evidence linear trend mean variability (NS-FFA recommended). package assumes familiarity statistical techniques used FFA, including L-moments, maximum likelihood estimation, parametric bootstrap. explanation methods, see FFA Framework wiki. examples, see vignettes exploratory data analysis flood frequency analysis.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/ffaframework-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Flood Frequency Analysis Framework — ffaframework-package","text":"Maintainer: Riley Wheadon rileywheadon@gmail.com Authors: Cuauhtémoc Vidrio-Sahagún ct.vidrio-sahagun@usask.ca Alain Pietroniro alain.pietroniro@ucalgary.ca Jianxun jianhe@ucalgary.ca","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"Estimates parameters generalized extreme value (GEV) distribution maximizing generalized log‐likelihood, incorporates Beta prior shape parameter. Initial parameter estimates obtained using method L‐moments optimization performed via stats::nlminb() repeated perturbations needed. NS-FFA: estimate parameters nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"","code":"fit_gmle(data, prior, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"list containing results parameter estimation: data: data argument. prior: prior argument. ns_years: ns_years argument, given. ns_structure: ns_structure argument, given. method: \"GMLE\". params: Numeric vector estimated parameters. mll: maximum value generalized log‐likelihood.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"Calls fit_lmoments() data obtain initial parameter estimates. Initializes trend parameters zero necessary. Defines objective function using utils_generalized_likelihood(). Runs stats::nlminb() box constraints. Attempts minimization 100 times.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"El Adlouni, S., Ouarda, T.B.M.J., Zhang, X., Roy, R., Bobee, B., 2007. Generalized maximum likelihood estimators nonstationary generalized extreme value model. Water Resources Research 43 (3), 1–13. doi:10.1029/2005WR004545 Martins, E. S., Stedinger, J. R. (2000). Generalized maximum-likelihood generalized extreme-value quantile estimators hydrologic data. Water Resources Research, 36(3), 737–744. doi:10.1029/1999WR900330","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) prior <- c(6, 9) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE) fit_gmle(data, prior, ns_years, ns_structure) #> $data #>   [1] 105.36249 117.23348  98.92870 105.61287  89.23935 100.82991 101.78167 #>   [8]  91.55114 117.67981  82.68244 112.11189 107.36570 111.29951  90.78180 #>  [15] 101.56818  80.14524 110.30039 112.91148 105.00442 110.39921  87.44111 #>  [22]  98.86676 101.12835 111.51733  85.58585 103.89748 107.29353  86.04344 #>  [29]  96.94657 110.95199  88.58207  91.29411 109.85239  91.61905  91.71838 #>  [36] 110.01256 111.97043  95.29367  84.88836 103.47476  95.94925  96.50217 #>  [43]  84.59143  95.90070  89.02645 100.54988  90.44008 109.84374 109.39418 #>  [50]  87.61338  86.89788  92.04935  93.35320 108.44849  94.79207 103.34544 #>  [57]  93.20054  96.88521 113.29437 103.96915  98.51686  92.26959 118.54612 #>  [64] 111.78232 105.47654 106.94876 108.49706 103.51722 104.15862  84.53482 #>  [71]  87.53159 104.64329 108.85733  94.02569 107.12776  93.87376 107.84242 #>  [78]  97.69873 125.24530 103.56465  93.36118 109.48751 103.26694  96.17233 #>  [85] 113.48133  86.81124 108.93587 112.09918  97.40808  85.91189 106.89636 #>  [92]  99.71902  80.10229  92.36063  83.85098 121.10798 108.58506 108.31253 #>  [99]  94.26097 100.53390 #>  #> $distribution #> [1] \"GEV\" #>  #> $ns_years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $ns_structure #> $ns_structure$location #> [1] TRUE #>  #> $ns_structure$scale #> [1] FALSE #>  #>  #> $prior #> [1] 6 9 #>  #> $method #> [1] \"GMLE\" #>  #> $params #> [1] 94.7699741  0.2536479  9.5291896  0.1090253 #>  #> $mll #> [1] -267.2693 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Moments Parameter Estimation — fit_lmoments","title":"L-Moments Parameter Estimation — fit_lmoments","text":"Estimates parameters stationary probability model using L-moments.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Moments Parameter Estimation — fit_lmoments","text":"","code":"fit_lmoments(data, distribution)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Moments Parameter Estimation — fit_lmoments","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Moments Parameter Estimation — fit_lmoments","text":"list containing results parameter estimation: data: data argument. distribution: distribution argument. method: \"L-moments\". params: Numeric vector estimated parameters.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Moments Parameter Estimation — fit_lmoments","text":"First, sample L-moments data computed using utils_sample_lmoments(). , formulas Hosking (1997) used match parameters sample L-moments. distributions \"GNO\", \"PE3\", \"LP3\" use rational approximation parameters since closed-form expression known.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Moments Parameter Estimation — fit_lmoments","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Moments Parameter Estimation — fit_lmoments","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmoments(data, \"GUM\") #> $data #>   [1] 107.26516 109.96803  91.08321 105.39807  99.44333 100.16600 118.61687 #>   [8] 110.21902 114.73549 100.36435  86.31768 109.19317 116.28756 101.60625 #>  [15]  90.94688 102.68745  97.00890  89.48579 117.41882  98.48603  99.31366 #>  [22]  86.91908 101.22587 118.70062  97.80619 109.65154 107.82251  88.81587 #>  [29]  75.86941  85.69462  97.30973  99.80566 112.09757  91.36437  95.86744 #>  [36]  92.77654 104.87393 102.51375 100.99291  95.86417  99.78147 104.83921 #>  [43] 110.42958 109.35107  97.67290 104.29871 109.35454  92.24086 108.62367 #>  [50]  85.20797  90.62383 102.25252 105.23610  94.18402 101.79172 103.95063 #>  [57] 112.68783  95.59487  92.48007  94.78395  94.88289 106.87342 107.67279 #>  [64] 115.10075 114.32144 118.17319 100.70136 102.34274  96.87547 115.08114 #>  [71] 108.78293 105.86041  85.56727 120.00224 103.56648  97.37379  91.94665 #>  [78] 108.82779  82.40831  94.94096  90.56819 102.17673  92.68039  98.05867 #>  [85]  99.08948 100.12524 115.71024  96.13517 111.17732  99.43153  90.23783 #>  [92]  79.33490 104.12935 107.77373 107.74647  90.52324 104.05805 117.28742 #>  [99]  90.72178 100.51341 #>  #> $distribution #> [1] \"GUM\" #>  #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 96.63627  7.83976 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"function estimates parameters four-parameter Kappa distribution using method L-moments. Since closed-form solution parameters terms L-moments known, parameters estimated numerically using Newton-Raphson iteration.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"","code":"fit_lmoments_kappa(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"list containing results parameter estimation: data: data argument. distribution: \"KAP\". method: \"L-moments\". params: numeric vector 4 parameters order location, scale, shape (2).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"First, sample L-moments data computed using utils_sample_lmoments(). , stats::optim() function used determine parameters minimizing euclidian distance sample theoretical L-moment ratios. implementation routine based deprecated homtest package, formerly available https://CRAN.R-project.org/package=homtest.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmoments_kappa(data) #> $data #>   [1]  98.17972 102.58520  96.10162 100.28579 103.75042 102.36861 106.81857 #>   [8]  99.87023  93.63866 103.16125 101.24585 114.56949  98.74122 108.01745 #>  [15]  88.36622  92.08586  94.85833  91.17829  79.81302 106.05510  87.84966 #>  [22]  94.28917 115.41705 104.91905 115.68214  86.67678 102.79631  92.60434 #>  [29] 119.73140 117.24102 108.36749 103.51559  79.13414 101.57273 110.01306 #>  [36]  94.95882  94.36551  98.49159 114.57832  82.77162  88.09108  95.81234 #>  [43]  79.14392  84.59182  98.12339  97.29406  89.23987 112.77777 111.88500 #>  [50] 101.40517 109.86976  97.46669 114.10414  99.06067 119.42181 104.18372 #>  [57] 104.83997  95.58950  98.99218  96.55484 115.53452 106.02357  81.50147 #>  [64]  96.43393  86.41441  94.61247  99.85326 107.39677  97.63858 114.23139 #>  [71]  97.42237  87.23457 102.19430 123.33102 129.98500 103.65176  96.13149 #>  [78] 101.34976 127.82386  93.53035  98.14358 108.50758  92.69139  99.54006 #>  [85] 109.46315  97.90904  95.27777  86.73009  85.38698 102.77775 112.91988 #>  [92]  81.80512  94.74878 104.12961  86.15792  93.61056  90.67634 107.98288 #>  [99]  93.72856  93.11586 #>  #> $distribution #> [1] \"KAP\" #>  #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 97.34746894  7.95482702  0.06210136 -0.33166023 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Parameter Estimation — fit_mle","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"Estimates parameters probability distribution maximizing log‐likelihood. Initial parameter estimates obtained using method L‐moments optimization performed via stats::nlminb() repeated perturbations needed. NS-FFA: estimate parameters nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"","code":"fit_mle(data, distribution, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"list containing results parameter estimation: data: data argument. distribution: distribution argument. ns_years: ns_years argument, given. ns_structure: ns_structure argument, given. method: \"MLE\". params: Numeric vector estimated parameters. mll: maximum value log‐likelihood.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"Calls fit_lmoments() data obtain initial parameter estimates. Initializes trend parameters zero necessary. WEI models, sets location parameter zero ensure support. Defines objective function using utils_log_likelihood(). Runs stats::nlminb() box constraints. Attempts minimization 100 times.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE) fit_mle(data, \"GNO\", ns_years, ns_structure) #> $data #>   [1]  96.89832  85.21415 103.60718 118.07402  92.29831 116.30787  96.94046 #>   [8]  88.75006 110.70093 106.80362 106.80181  78.45343  90.59212 113.49160 #>  [15] 107.58402 105.77168  97.74529  92.92667  87.12961  97.34649 103.17341 #>  [22] 114.52780 114.82291  84.09064  97.41627  80.09692 112.52924  84.14193 #>  [29] 105.79051  92.79212  77.79175  94.06701  91.08944 102.43396 100.58815 #>  [36] 112.30860  93.74515 100.52105 103.26004 107.44203  97.91168 119.01198 #>  [43]  86.81093  95.02666  97.24043  78.01471 105.61307 103.25924 100.08636 #>  [50] 111.09707 127.78743  87.27984 123.72900  97.47131 102.77547  87.47706 #>  [57]  94.13426  96.19866 118.04711 105.96198 114.36962 115.87495 115.10900 #>  [64] 108.80649 109.96885 111.57981  94.25167  87.46057 106.31133 109.05409 #>  [71] 107.89903 114.14477 103.67402 102.26379 108.00647  94.50523  87.72731 #>  [78]  99.77925 108.63950 112.97008  96.02339  84.07061 102.54378  82.27624 #>  [85] 100.78716  86.00637 132.19060  91.81452 100.36118  94.42961  91.78141 #>  [92] 112.85518  87.10887  98.47703  90.29603 115.85079  96.85944  90.73756 #>  [99] 113.84408  89.75266 #>  #> $distribution #> [1] \"GNO\" #>  #> $ns_years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $ns_structure #> $ns_structure$location #> [1] TRUE #>  #> $ns_structure$scale #> [1] FALSE #>  #>  #> $prior #> NULL #>  #> $method #> [1] \"MLE\" #>  #> $params #> [1] 99.45758050  1.59710972 11.41849812 -0.07884203 #>  #> $mll #> [1] -385.4173 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":null,"dir":"Reference","previous_headings":"","what":"Orchestrate Exploratory Data Analysis — framework_eda","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"First, method identifies change points annual maximum series data. , user given option split dataset two subperiods. Finally, method performs collection statistical tests identifying nonstationarity mean variability subperiod.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"","code":"framework_eda(data, years, ns_splits = NULL, automatic = FALSE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. ns_splits integer vector years split data (default NULL). split point first year subperiod. automatic TRUE, data split automatically using results Pettitt MKS tests (default FALSE). argument ignored ns_splits NULL. ... Additional arguments. See \"Optional Arguments\" section complete list.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"recommendations: list recommended split points nonstationary structures: approach: Either \"S-FFA\", \"NS-FFA\", \"Piecewise NS-FFA\". splits: change point(s) identified change point detection test lowest statistically significant p-value, empty vector test exists. structures: list nonstationary structure objects subperiod. structure list boolean items location scale represent linear trend mean variability data respectively. submodules: list lists statistical tests. sublist contains: name: Either \"Change Points\" \"Trend Detection\". start: first year subperiod. end: last year subperiod. Additional items statistical tests within submodule.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"ns_splits argument NULL, used split data. avoid splitting data, use splits = integer(0). Note integer(0) NULL. ns_splits NULL automatic TRUE, data split automatically based change point detection test lowest statistically significant p-value. neither test yielded statistically significant p-value, data split. ns_splits NULL automatic FALSE, user prompted select split points manually. feature requires R running interactive mode. Check R interactive mode using built-interactive() function.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"optional-arguments","dir":"Reference","previous_headings":"","what":"Optional Arguments","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"alpha: numeric significance level statistical tests (default 0.05). bbmk_samples: number samples used Block-Bootstrap Mann-Kendall (BBMK) test (default 10000). Must integer.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":null,"dir":"Reference","previous_headings":"","what":"Orchestrate Flood Frequency Analysis — framework_ffa","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"Performs frequency analysis annual maximum series (AMS) data including distribution selection, parameter estimation, uncertainty quantification, model assessment. Supports stationary frequency analysis (S-FFA) nonstationary frequency analysis (NS-FFA).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"","code":"framework_ffa(data, years, ns_splits = NULL, ns_structures = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. ns_splits integer list years split data. Use splits = integer(0) avoid splitting data. Note integer(0) NULL. ns_structures list structure objects size length(splits) + 1. structure object list boolean items location scale indicating trend mean/variability respectively. ... Additional arguments. See \"Optional Arguments\" section complete list.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"list submodules containing results frequency analysis. list contains name, either \"Distribution Selection\", \"Parameter Estimation\",  \"Uncertainty  Quantification\", \"Model Assessment\". , submodule contain sublist results subperiod.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"optional-arguments","dir":"Reference","previous_headings":"","what":"Optional Arguments","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"selection: Distribution selection method (default \"L-distance\"). Must one \"L-distance\", \"L-kurtosis\" \"Z-statistic\". Alternatively, set selection three-letter distribution code (eg. \"GUM\") use specific distribution. s_estimation: Parameter estimation method S-FFA (default \"L-moments\"). Must \"L-moments\", \"MLE\", \"GMLE\". Method \"GMLE\" requires selection = \"GEV\". ns_estimation: Parameter estimation method NS-FFA (default \"MLE\"). Must \"MLE\" \"GMLE\". Method \"GMLE\" requires selection = \"GEV\". s_uncertainty: Uncertainty quantification method S-FFA (default \"Bootstrap\"). Must one \"Bootstrap\", \"RFPL\", RFGPL\". Using method \"RFPL\" requires s_estimation = \"MLE\" method \"RFGPL\" requires s_estimation = \"GMLE\". ns_uncertainty: Uncertainty quantification method NS-FFA (default \"RFPL\"). Must one \"Bootstrap\", \"RFPL\", RFGPL\". Using method \"RFPL\" requires ns_estimation = \"MLE\" method \"RFGPL\" requires ns_estimation = \"GMLE\". z_samples: Integer number bootstrap samples selection method \"Z-statistic\" (default 10000). gev_prior: Parameters prior distribution shape parameter GEV distribution (default 6, 9). Used estimation method \"GMLE\". return_periods: Integer list return periods (years) estimating return levels. Uses 2, 5, 10, 20, 50, 100 year return periods default. slices: Integer vector years estimate return levels nonstationary models. Slices outside period ignored (default 1900, 1950, 2000). sb_samples: Integer number samples uncertainty quantification method \"Bootstrap\" (default 10000). rfpl_tolerance: Log-likelihood tolerance uncertainty quantification method \"RFPL\" (default 0.01). pp_formula: Plotting position formula model assessment. Must one : \"Weibull\" (default): \\(/ (n + 1)\\) \"Blom\": \\((- 0.375) / (n + 0.25)\\) \"Cunnane\": \\((- 0.4) / (n + 0.2)\\) \"Gringorten\": \\((- 0.44) / (n + 0.12)\\) \"Hazen\": \\((- 0.5) / n\\)","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Orchestrate the Full FFA Framework — framework_full","title":"Orchestrate the Full FFA Framework — framework_full","text":"Runs entire flood frequency analysis framework using exploratory data analysis (framework_eda()) flood frequency analysis (framework_ffa()) modules. Returns comprehensive reproducible summary results.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orchestrate the Full FFA Framework — framework_full","text":"","code":"framework_full(   data,   years,   ns_splits = NULL,   ns_structures = NULL,   automatic = FALSE )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orchestrate the Full FFA Framework — framework_full","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. ns_splits integer vector years split data (default NULL). split point first year subperiod. ns_structures list structure objects size length(ns_splits) + 1 (default NULL). structure object list boolean items location scale indicating trend mean/variability respectively. automatic TRUE, split points nonstationary ns_structures chosen automatically using results EDA (default FALSE). argument ignored ns_splits ns_structures NULL. ... Additional arguments passed statistical tests frequency analysis functions. See details module_eda() module_ffa() complete list.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orchestrate the Full FFA Framework — framework_full","text":"summary: list containing nonstationary splits structures used analysis. ns_splits /ns_structures arguments provided, included . Otherwise, list contain split points model structures selected manually user. submodules: list results submodule. submodules name, one \"Change Points\", \"Trend Detection\", \"Distribution Selection\", \"Parameter Estimation\", \"Uncertainty Quantification\", \"Model Assessment\". information, see framework_eda() framework_ffa().","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Orchestrate the Full FFA Framework — framework_full","text":"behaviour function automatic = FALSE can confusing. either ns_splits ns_structures NULL, user prompted select . However, R running non-interactive mode, possible, function return results current block along error message. avoid issue, user three options: Set ns_splits ns_structures manually. Run R interactive mode (using RStudio, example). Set automatic = TRUE.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Assessment — model_assessment","title":"Model Assessment — model_assessment","text":"Computes various metrics assessing quality fitted flood frequency model. Metrics include accuracy (residual statistics), fitting efficiency (information criteria), uncertainty (coverage based metrics using confidence intervals).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Assessment — model_assessment","text":"","code":"model_assessment(   data,   distribution,   params,   ns_years = NULL,   ns_structure = NULL,   alpha = 0.05,   pp_formula = \"Weibull\",   ci = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Assessment — model_assessment","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. pp_formula Character string specifying plotting position formula. Must \"Weibull\" (default), \"Blom\", \"Cunnane\", \"Gringorten\", \"Hazen\". ci Dataframe containing return periods (column periods) confidence intervals (columns ci_lower ci_upper). Dataframes format can generated uncertainty_bootstrap(), uncertainty_rfpl(), uncertainty_rfgpl().","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Assessment — model_assessment","text":"List containing results model assessment: data: data argument. estimates: Return level estimates based plotting positions (S-FFA ). metrics: list model assessment metrics (see details).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Assessment — model_assessment","text":"metrics computed stationary nonstationary models: AIC_MLL: Akaike Information Criterion, computed using maximum log-likelihood. BIC_MLL: Bayesian Information Criterion, computed using maximum log-likelihood. metrics always computed stationary models: R2: Coefficient determination linear regression estimates vs. data. RMSE: Root mean squared error quantile estimates. bias: Mean bias quantile estimates. AIC_RMSE: Akaike Information Criterion, computed using RMSE. BIC_RMSE: Bayesian Information Criterion, computed using RMSE. metrics computed stationary models ci argument provided: AW: Average width confidence interval(s). POC: Percent observations covered confidence interval(s). CWI: Confidence width index, metric combines AW POC.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Assessment — model_assessment","text":"","code":"# Initialize example data and params data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 10)  # Perform uncertainty analysis ci <- uncertainty_bootstrap(data, \"NOR\", \"L-moments\")$results  # Evaluate model diagnostics model_assessment(data, \"NOR\", params, ci = ci) #> $data #>   [1] 103.32694  83.67615 110.88718 105.92150  88.93916  97.37292 105.86291 #>   [8]  91.23258 108.51698  99.39284  95.83097 107.19835  85.08089 100.34346 #>  [15]  97.53211 119.54145 100.09658 113.11216  88.64854  95.31387 103.40441 #>  [22]  98.21043 116.15922  99.69659 110.39512 102.20352 109.53315 111.88895 #>  [29]  95.33576 116.22845  92.46341 108.04747  93.51511  94.71189  76.80314 #>  [36] 111.49970  97.32005 113.35798 103.04911 110.48993  92.94706 100.24797 #>  [43] 100.81656 105.06131  94.48316 107.03604 101.50665  81.50408  96.53061 #>  [50]  99.56023  98.79920  92.41629 110.41362 100.44308 108.27265  98.96216 #>  [57]  92.11579 108.29480 116.68956 102.13646 111.57535  89.21120 113.15584 #>  [64]  93.25724  93.56120 100.40112 108.21379 114.65366 104.47294 103.40752 #>  [71] 120.89891 103.25784 105.00181 108.11776  98.44905  91.99071  75.23320 #>  [78]  86.10714 108.21163  99.17586  93.73108  89.23005  93.14664 103.55095 #>  [85] 109.96582 109.94133  89.48270 100.77882 105.86229  96.05944 105.74290 #>  [92] 101.84364  88.81079  88.19487 104.83221 107.28678  90.25614  85.70304 #>  [99]  87.53543  75.85501 #>  #> $estimates #>   [1] 123.30079 120.57856 118.85177 117.55301 116.49673 115.59780 114.80973 #>   [8] 114.10420 113.46263 112.87214 112.32341 111.80947 111.32497 110.86568 #>  [15] 110.42824 110.00990 109.60838 109.22178 108.84850 108.48716 108.13657 #>  [22] 107.79571 107.46367 107.13967 106.82300 106.51302 106.20918 105.91097 #>  [29] 105.61792 105.32963 105.04569 104.76577 104.48953 104.21668 103.94693 #>  [36] 103.68003 103.41572 103.15377 102.89397 102.63612 102.38000 102.12543 #>  [43] 101.87224 101.62024 101.36926 101.11915 100.86973 100.62085 100.37236 #>  [50] 100.12409  99.87591  99.62764  99.37915  99.13027  98.88085  98.63074 #>  [57]  98.37976  98.12776  97.87457  97.62000  97.36388  97.10603  96.84623 #>  [64]  96.58428  96.31997  96.05307  95.78332  95.51047  95.23423  94.95431 #>  [71]  94.67037  94.38208  94.08903  93.79082  93.48698  93.17700  92.86033 #>  [78]  92.53633  92.20429  91.86343  91.51284  91.15150  90.77822  90.39162 #>  [85]  89.99010  89.57176  89.13432  88.67503  88.19053  87.67659  87.12786 #>  [92]  86.53737  85.89580  85.19027  84.40220  83.50327  82.44699  81.14823 #>  [99]  79.42144  76.69921 #>  #> $metrics #> $metrics$AIC_MLL #> [1] 740.7242 #>  #> $metrics$BIC_MLL #> [1] 745.9345 #>  #> $metrics$R2 #> [1] 0.9898225 #>  #> $metrics$RMSE #> [1] 1.007288 #>  #> $metrics$bias #> [1] -0.2654189 #>  #> $metrics$AIC_RMSE #> [1] 4.726128 #>  #> $metrics$BIC_RMSE #> [1] 9.936468 #>  #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/mu_sigma.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Location and Scale of Kappa Distribution — mu_sigma","title":"Compute Location and Scale of Kappa Distribution — mu_sigma","text":"Compute Location Scale Kappa Distribution","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/mu_sigma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Location and Scale of Kappa Distribution — mu_sigma","text":"","code":"mu_sigma(l1, l2, k, h)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'alpha' — param-alpha","title":"Parameter 'alpha' — param-alpha","text":"Parameter 'alpha'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'alpha' — param-alpha","text":"alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-data.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'data' — param-data","title":"Parameter 'data' — param-data","text":"Parameter 'data'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'data' — param-data","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'distribution' — param-distribution","title":"Parameter 'distribution' — param-distribution","text":"Parameter 'distribution'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'distribution' — param-distribution","text":"distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'method' — param-method","title":"Parameter 'method' — param-method","text":"Parameter 'method'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'method' — param-method","text":"method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_slice' — param-ns-slice","title":"Parameter 'ns_slice' — param-ns-slice","text":"Parameter 'ns_slice'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_slice' — param-ns-slice","text":"ns_slice NS-FFA . Numeric scalar specifying year evaluate quantiles nonstationary probability distribution. ns_slice element ns_years argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slices.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_slices' — param-ns-slices","title":"Parameter 'ns_slices' — param-ns-slices","text":"Parameter 'ns_slices'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_slices' — param-ns-slices","text":"ns_slices NS-FFA . Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-structure.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_structure' — param-ns-structure","title":"Parameter 'ns_structure' — param-ns-structure","text":"Parameter 'ns_structure'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-structure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_structure' — param-ns-structure","text":"ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-years.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_years' — param-ns-years","title":"Parameter 'ns_years' — param-ns-years","text":"Parameter 'ns_years'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-years.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_years' — param-ns-years","text":"ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-p.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'p' — param-p","title":"Parameter 'p' — param-p","text":"Parameter 'p'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'p' — param-p","text":"p Numeric vector probabilities 0 1 missing values.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-params.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'params' — param-params","title":"Parameter 'params' — param-params","text":"Parameter 'params'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'params' — param-params","text":"params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-periods.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'periods' — param-periods","title":"Parameter 'periods' — param-periods","text":"Parameter 'periods'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-periods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'periods' — param-periods","text":"periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'prior' — param-prior","title":"Parameter 'prior' — param-prior","text":"Parameter 'prior'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'prior' — param-prior","text":"prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'samples' — param-samples","title":"Parameter 'samples' — param-samples","text":"Parameter 'samples'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'samples' — param-samples","text":"samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-tolerance.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'tolerance' — param-tolerance","title":"Parameter 'tolerance' — param-tolerance","text":"Parameter 'tolerance'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-tolerance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'tolerance' — param-tolerance","text":"tolerance log-likelihood tolerance Regula-Falsi convergence (default 0.01).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-years.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'years' — param-years","title":"Parameter 'years' — param-years","text":"Parameter 'years'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-years.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'years' — param-years","text":"years Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Annual Maximum Series Data — plot_ams_data","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"Produces scatterplot annual maximum series data time, optionally overlaid sample mean/variability Sen's trend estimator mean/variability.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"","code":"plot_ams_data(   data,   years,   plot_mean = \"None\",   plot_variability = \"None\",   show_line = TRUE,   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. plot_mean \"None\" (default), mean plotted. \"Constant\", black line plotted sample mean. \"Trend\", trend mean estimated using eda_sens_trend() plotted blue line. plot_variability \"None\" (default), variability plotted. \"Constant\", dashed black lines plotted one standard deviation /sample mean. \"Trend\", trend variability estimated data_mw_variability() eda_sens_trend() plotted dashed blue line. show_line TRUE (default), fitted line drawn data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"ggplot; plot containing: Gray points year’s annual maximum series value. gray line connecting data show_line = TRUE. solid black line representing constant mean, plot_mean == \"Constant\". solid blue line representing trend mean, plot_mean == \"Trend\". dashed black line representing constant variability, plot_variability == \"Constant\". dashed blue line representing trend variability, plot_variability == \"Trend\".","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) plot_ams_data(data, years, plot_mean = \"Trend\", plot_variability = \"Constant\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"Generates histogram bootstrapped Mann–Kendall S‐statistics vertical lines indicating observed S‐statistic confidence bounds.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"","code":"plot_bbmk_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"results List BB‐MK test results generated eda_bbmk_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"ggplot; plot containing: gray histogram distribution bootstrapped S‐statistics. red vertical line lower upper confidence bounds. black vertical line observed S‐statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- eda_bbmk_test(data, samples = 1000L) plot_bbmk_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"Generates plot L-moment ratios L-skewness x-axis L-kurtosis y-axis. Plots sample log-sample L-moment ratios alongside theoretical L-moment ratios set candidate distributions. Also includes small inset around L-moment ratios recommended distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"","code":"plot_lmom_diagram(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"results List distribution selection results generated select_ldistance(), select_lkurtosis(), select_zstatistic(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"ggplot; plot object containing L-moment ratio diagram, : L-moment ratio curves 3-parameter distribution. Points L-moment ratios 2-parameter distribution. Sample log-sample L-moment ratio \\((t_3, t_4)\\) points.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- select_ldistance(data) plot_lmom_diagram(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"Constructs two‐panel visualization MKS test. upper panel plots normalized progressive regressive Mann–Kendall S‐statistics time, dashed confidence bounds potential trend‐change points. lower panel contains annual maximum series data change points highlighted.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"","code":"plot_mks_test(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"results list generated eda_mks_test(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'top_xlabel', 'top_ylabel', 'bottom_xlabel' 'bottom_ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"patchwork object two ggplot2 panels stacked vertically.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- eda_mks_test(data, years) plot_mks_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Model Assessment Results — plot_model_assessment","title":"Plot Model Assessment Results — plot_model_assessment","text":"Creates quantile–quantile plot comparing observed annual maximum series data quantile estimates fitted parametric model. 1:1 line drawn black parametric model estimates plotted semi‐transparent red points.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Model Assessment Results — plot_model_assessment","text":"","code":"plot_model_assessment(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Model Assessment Results — plot_model_assessment","text":"results List; model assessment results generated model_assessment(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Model Assessment Results — plot_model_assessment","text":"ggplot; plot containing: black line representing model deviation empirical quantiles. Red points denoting estimated quantiles empirical quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_assessment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Model Assessment Results — plot_model_assessment","text":"","code":"# Initialize example data and params data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 10)  # Perform uncertainty analysis uncertainty <- uncertainty_bootstrap(data, \"NOR\", \"L-moments\")  # Evaluate model diagnostics results <- model_assessment(data, \"NOR\", params, ci = uncertainty$ci)  # Generate a model assessment plot plot_model_assessment(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"Generates plot effective return periods x-axis effective return levels (annual maxima magnitudes) y-axis. slice displayed distinct color. Confidence bounds shown semi-transparent  ribbons, point estimates  overlaid solid lines. Return periods logarithmic scale.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"","code":"plot_nsffa_estimates(   results,   ci_list = NULL,   slices = c(1900, 1940, 1980, 2020),   periods = c(2, 5, 10, 20, 50, 100),   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"results list estimated return levels confidence intervals generated uncertainty_bootstrap() uncertainty_rfpl(). ci_list optional list dataframes containing return periods confidence intervals generated uncertainty_bootstrap(), uncertainty_rfpl(), uncertainty_rfgpl(). slices Default time slices plotting return levels ci_list NULL. periods Numeric vector used set return periods FFA. entries must greater equal 1. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"ggplot; plot one line ribbon per slice.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"","code":"# Fit a nonstationary model   data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  results <- fit_mle(      data,       \"GEV\",       ns_years = years,       ns_structure = ns_structure )  # Run bootstrap uncertainty quantification at slices 1920, 1960, 2000 uncertainty <- uncertainty_bootstrap(      data,    \"GEV\",    \"MLE\",    ns_years = years,    ns_structure = ns_structure,    ns_slices = c(1920, 1960, 2000),      samples = 1000L )  # Generate the plot plot_nsffa_estimates(results, ci_list = uncertainty$ci_list)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"Generates plot slices nonstationary probability model plotted vertically left panel data right panel.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"","code":"plot_nsffa_fit(   results,   slices = c(1925, 1950, 1975, 2000),   show_line = TRUE,   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle(). slices Years plot nonstationary probability model. show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"ggplot; plot showing: likelihood function distribution plotted vertically left panel. data, connected line show_line == TRUE, right panel.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  results <- fit_mle(      data,       \"GEV\",       ns_years = years,       ns_structure = ns_structure )  plot_nsffa_fit(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"Creates two‐panel visualization Mann–Whitney–Pettitt test. upper panel plots Pettitt \\(U_t\\) statistic time along significance threshold potential change point. lower panel displays annual maximum series data optional trend line, period mean(s), potential change point(s).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"","code":"plot_pettitt_test(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"results list generated eda_pettitt_test(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'top_xlabel', 'top_ylabel', 'bottom_xlabel' 'bottom_ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"patchwork object two ggplot2 panels stacked vertically.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- eda_pettitt_test(data, years) plot_pettitt_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Runs Test Results — plot_runs_test","title":"Plot Runs Test Results — plot_runs_test","text":"Generates residual plot Sen's estimator applied annual maximum series data (variability data) horizontal dashed line zero annotation indicating p-value Runs test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Runs Test Results — plot_runs_test","text":"","code":"plot_runs_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Runs Test Results — plot_runs_test","text":"results list runs test results generated eda_runs_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Runs Test Results — plot_runs_test","text":"ggplot; plot containing: Black points residual year. red dashed horizontal line \\(y = 0\\). text annotation “Runs p-value: X.XXX” plot area.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Runs Test Results — plot_runs_test","text":"","code":"# Initialize data and years data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000)  # Generate the runs test plot  sens_trend <- eda_sens_trend(data, years) results <- eda_runs_test(sens_trend$residuals, years) plot_runs_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"Generates plot return periods x-axis return levels (annual maxima magnitudes) y-axis S-FFA. confidence bound shown semi-transparent ribbon, point estimates overlaid solid line. Return periods shown logarithmic scale.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"","code":"plot_sffa_estimates(   results,   ci = NULL,   periods = c(2, 5, 10, 20, 50, 100),   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle(). ci optional dataframe return periods confidence intervals generated uncertainty_bootstrap(), uncertainty_rfpl(), uncertainty_rfgpl(). periods Numeric vector used set return periods FFA. entries must greater equal 1. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"ggplot; plot showing: solid black line point estimates produced model. semi-transparent gray ribbon indicating confidence interval, given.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- fit_lmoments(data, \"WEI\") uncertainty <- uncertainty_bootstrap(data, \"WEI\", \"L-moments\") plot_sffa_estimates(results, ci = uncertainty$ci)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"Generates plot stationary probability distribution plotted vertically left panel data right panel.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"","code":"plot_sffa_fit(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"ggplot; plot showing: likelihood function distribution plotted vertically left panel. data, connected line show_line == TRUE, right panel.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- fit_lmoments(data, \"WEI\") plot_sffa_fit(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"Visualizes Spearman’s rho serial correlation coefficients shaded points indicating statistical significance.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"","code":"plot_spearman_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"results list generated eda_spearman_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"ggplot; plot showing: Vertical segments \\(y=0\\) \\(\\rho\\) value lag. Filled circles lag, filled black serial correlation detected.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- eda_spearman_test(data) plot_spearman_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Distance Method for Distribution Selection — select_ldistance","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"Selects distribution set candidate distributions minimizing Euclidean distance theoretical L-moment ratios \\((\\tau_3, \\tau_4)\\) sample L-moment ratios \\((t_3, t_4)\\). NS-FFA: select distribution nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure). , method detrend data internally using data_decomposition() function prior distribution selection.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"","code":"select_ldistance(data, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"list results distribution selection: method: \"L-distance\". data: data argument (S-FFA) detrended dataset (NS-FFA). metrics: list L-distance metrics candidate distribution. recommendation: name distribution smallest L-distance.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"candidate distribution, method computes Euclidean distance sample L-moment ratios (\\(\\tau_3\\), \\(\\tau_4\\)) closest point theoretical distribution's L-moment curve. two-parameter distributions (Gumbel, Normal, Log-Normal), theoretical L-moment ratios compared directly sample L-moment ratios. distribution minimum distance selected. distribution fit log-transformed data (Log-Normal Log-Pearson Type III), L-moment ratios log-transformed sample used instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_ldistance(data) #> $method #> [1] \"L-distance\" #>  #> $data #>   [1] 112.36210  90.96671  88.81809 105.49874 101.44455  91.36199 108.24594 #>   [8] 101.76501  92.67487 100.88402  94.50747 110.45014  87.42728 112.88892 #>  [15] 105.50069 113.28995 103.00665 118.53577 102.97076  98.57930 112.89908 #>  [22]  97.18895 111.13498 109.83232 109.55026  96.96021  97.91620  87.01459 #>  [29]  99.28443  93.81179  97.34613  93.89084 103.55019 109.96499  79.31277 #>  [36]  93.83550  91.45473 109.03163 115.78444 105.72620  92.92973 107.96002 #>  [43]  93.29243  94.34594  99.73184  90.12823  92.97532 109.12187  85.51126 #>  [50]  97.94028 100.59896  91.66640 106.53450  99.54317 109.12172  99.03369 #>  [57] 122.21154 109.30758  98.84861 109.11931  89.31727 107.16006  87.92649 #>  [64]  97.34781  94.12382 102.02802  95.21949 107.10338 108.55868 111.70885 #>  [71]  88.50561 113.18589  92.41219 115.19096  91.95496 115.27030  86.47308 #>  [78]  95.39673 117.46465  98.83503  91.59992 113.50751  90.05050  92.04249 #>  [85]  99.44339 110.29035 100.57330 103.17333  93.53476  82.46938  83.48580 #>  [92] 102.76144  93.08456  99.57173 109.96268 104.46125 102.70581 117.61106 #>  [99]  86.70633  92.06702 #>  #> $metrics #> $metrics$GUM #> [1] 0.1743756 #>  #> $metrics$NOR #> [1] 0.08134432 #>  #> $metrics$LNO #> [1] 0.07437066 #>  #> $metrics$GEV #> [1] 0.0636822 #>  #> $metrics$GLO #> [1] 0.1204359 #>  #> $metrics$GNO #> [1] 0.07637753 #>  #> $metrics$PE3 #> [1] 0.07601018 #>  #> $metrics$LP3 #> [1] 0.07391115 #>  #> $metrics$WEI #> [1] 0.05763824 #>  #>  #> $recommendation #> [1] \"WEI\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"Selects probability distribution minimizing absolute distance theoretical L-kurtosis (\\(\\tau_4\\)) sample L-kurtosis (\\(t_4\\)). supports 3-parameter distributions. NS-FFA: select distribution nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure). , method detrend data internally using data_decomposition() function prior distribution selection.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"","code":"select_lkurtosis(data, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"list results distribution selection: method: \"L-kurtosis\". data: data argument (S-FFA) detrended dataset (NS-FFA). metrics: list L-kurtosis metrics distribution. recommendation: Name distribution smallest L-kurtosis metric.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"method computes distance sample theoretical L-kurtosis values fixed L-skewness. three parameter distributions, shape parameter best replicates sample L-skewness determined using stats::optim().","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_lkurtosis(data) #> $method #> [1] \"L-kurtosis\" #>  #> $data #>   [1]  95.18049  96.29055  91.52380 116.75304  93.63964  98.91239  99.26363 #>   [8]  99.44687 103.81568  95.84018  97.27735  97.03057 100.44135  95.40703 #>  [15] 106.52077  89.09580 101.38783 110.83395 100.02482  96.39266  94.80582 #>  [22] 102.89364 113.80124 109.10813  94.03932  96.41940  91.96727  96.95295 #>  [29] 120.58976  87.20401 107.05555  97.25663  98.01527  91.38964  95.79279 #>  [36]  99.98806  87.83996 101.28904 105.78956 102.67137  83.47458  91.94682 #>  [43]  81.61950  99.79259  79.54261 100.15682  93.37544  93.62910  98.02516 #>  [50] 111.46625  85.41590  99.33952 106.29672  88.00825 109.01071 108.62575 #>  [57] 120.74578  93.95437  95.53630  85.72929 109.39748  98.87250 109.97638 #>  [64]  91.37333 108.50989  89.28955  98.41831  78.86985  85.57707  98.92098 #>  [71]  88.35421  93.65519  99.68154  95.85789 118.71775  95.59222 100.94584 #>  [78] 100.27913  89.24481 102.17445 104.32430  98.04964  90.57925 105.59244 #>  [85] 115.97841 106.58272 120.48920  94.44608 102.02191  93.10472 101.73187 #>  [92]  98.61486 104.51093  90.85825 109.25733 103.02943  90.21234  81.61561 #>  [99] 106.38030  92.06038 #>  #> $metrics #> $metrics$GEV #> [1] 0.04347321 #>  #> $metrics$GLO #> [1] 0.009128035 #>  #> $metrics$GNO #> [1] 0.0351111 #>  #> $metrics$PE3 #> [1] 0.03690165 #>  #> $metrics$LP3 #> [1] 0.03651435 #>  #> $metrics$WEI #> [1] 0.05714841 #>  #>  #> $recommendation #> [1] \"GLO\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":null,"dir":"Reference","previous_headings":"","what":"Z-Statistic Method for Distribution Selection — select_zstatistic","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"Selects best-fit distribution comparing bias-corrected Z-statistic sample L-kurtosis (\\(\\tau_4\\)) theoretical L-moments set candidate distributions. distribution smallest absolute Z-statistic selected. NS-FFA: select distribution nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure). , method detrend data internally using data_decomposition() function prior distribution selection.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"","code":"select_zstatistic(data, ns_years = NULL, ns_structure = NULL, samples = 10000L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"list results distribution selection: method: \"Z-selection\". data: data argument (S-FFA) detrended dataset (NS-FFA). metrics: List computed Z-statistics candidate distribution. recommendation: Name distribution smallest Z-statistic. reg_params: Kappa distribution parameters data. reg_bias_t4: Bias L-kurtosis bootstrap. reg_std_t4: Standard deviation L-kurtosis bootstrap. log_params: Kappa distribution parameters log-transformed data. log_bias_t4: Bias L-kurtosis bootstrap using log_params. log_std_t4: Standard deviation L-kurtosis bootstrap using log_params.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"First, method fits four-parameter Kappa distribution original log-transformed data. , bootstrapping used estimate bias variance L-kurtosis. values, along difference sample theoretical L-kurtosis, used compute Z-statistic distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_zstatistic(data) #> $method #> [1] \"Z-statistic\" #>  #> $data #>   [1]  93.66981  90.95956  99.19026  98.71915 101.79338 101.32694 102.04820 #>   [8] 110.98209  99.65298  89.94651  96.69792 108.31218  85.88962 100.37866 #>  [15]  92.39855 102.35374  87.37552  98.86392 107.48181 105.12639 104.11626 #>  [22] 107.28600  91.54723 118.06782 106.62263  99.94238 105.10995  89.14286 #>  [29] 108.08411 104.66837  87.61050 104.62507 112.93330  92.95327  89.89847 #>  [36] 123.78929 102.61699  85.61433 105.39715 116.24928  91.03303  95.75079 #>  [43] 108.26474  94.86348  87.87594  94.51921  83.97493  99.74286  85.59272 #>  [50]  94.79051 112.23648  94.56373 105.61505  99.81454 101.83150  97.17795 #>  [57] 103.62006  91.39505  94.13403 113.16686 103.50459 115.87438 108.12959 #>  [64]  97.86323 107.14469  82.71510  98.38532  94.02230 103.65213  88.34442 #>  [71] 101.53695  83.04860  89.29452 104.70286 100.49462  96.85461  91.09270 #>  [78]  95.05623 108.05659 100.52742 107.24436  82.70252 101.30351 103.20557 #>  [85] 106.39076 109.81046 105.96192  92.45432 102.68295  83.69302 102.26561 #>  [92] 101.81147 104.23127  93.39594  87.95513  83.76912 104.15148 102.00870 #>  [99] 110.92091  93.29045 #>  #> $metrics #> $metrics$GEV #> [1] 0.3596903 #>  #> $metrics$GLO #> [1] 2.511239 #>  #> $metrics$GNO #> [1] 0.9741756 #>  #> $metrics$PE3 #> [1] 0.9674902 #>  #> $metrics$LP3 #> [1] 1.065967 #>  #> $metrics$WEI #> [1] 0.5156712 #>  #>  #> $recommendation #> [1] \"GEV\" #>  #> $reg_params #> [1] 95.82679505  9.75557803  0.36785260  0.09312144 #>  #> $reg_bias_t4 #> [1] 0.0004975979 #>  #> $reg_std_t4 #> [1] 0.02868038 #>  #> $log_params #> [1] 4.56228252 0.10236845 0.44564137 0.08956027 #>  #> $log_bias_t4 #> [1] 0.001001428 #>  #> $log_std_t4 #> [1] 0.02914515 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/sumquad_tau3tau4.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","title":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","text":"Compute L-moment Distance Kappa Distribution","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/sumquad_tau3tau4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","text":"","code":"sumquad_tau3tau4(k.h, t3.t4)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"Computes return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using parametric bootstrap. function supports variety probability models parameter estimation methods. NS-FFA: perform uncertainty quantification nonstationary model, include observation years (ns_years), nonstationary model structure (ns_structure), list years compute return level estimates confidence intervals (ns_slices).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"","code":"uncertainty_bootstrap(   data,   distribution,   method,   prior = NULL,   ns_years = NULL,   ns_structure = NULL,   ns_slices = NULL,   alpha = 0.05,   samples = 10000L,   periods = c(2, 5, 10, 20, 50, 100) )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. ns_slices NS-FFA . Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. samples Integer scalar. number bootstrap samples. Default 10000. periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"list containing following four items: method: \"Bootstrap\" ns_structure: ns_structure argument, given. ns_slices: ns_slices argument, given. ci: dataframe containing confidence intervals (S-FFA ) ci_list: list dataframes containing confidence intervals (NS-FFA ). dataframe(s) ci ci_list four columns: estimates: Estimated quantiles return period. lower: Lower bound confidence interval return period. upper: Upper bound confidence interval return period. periods: periods argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"Bootstrap samples obtained fitted distribution via inverse transform sampling. bootstrapped sample, parameters re-estimated based method argument. , bootstrapped parameters used compute new set bootstrapped quantiles. Confidence intervals obtained empirical nonexceedance probabilities bootstrapped quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"parametric bootstrap known give unreasonably wide confidence intervals small datasets. method yields confidence interval least 5 times greater magnitude return levels, return error recommend uncertainty_rfpl() uncertainty_rfgpl() alternatives.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_bootstrap(data, \"WEI\", \"L-moments\") #> $method #> [1] \"Bootstrap\" #>  #> $ns_structure #> NULL #>  #> $ns_slices #> NULL #>  #> $ci #>   periods estimates     lower    upper #> 1       2  99.38382  97.19376 101.4899 #> 2       5 107.32605 105.24336 109.3161 #> 3      10 111.04519 108.75148 113.3067 #> 4      20 113.91876 111.28210 116.6264 #> 5      50 116.96068 113.81608 120.3403 #> 6     100 118.88590 115.36404 122.8719 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"Calculates return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using regula-falsi generalized profile likelihood root‐finding method GEV distribution. NS-FFA: perform uncertainty quantification nonstationary model, include observation years (ns_years), nonstationary model structure (ns_structure), list years compute return level estimates confidence intervals (ns_slices).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"","code":"uncertainty_rfgpl(   data,   prior,   ns_years = NULL,   ns_structure = NULL,   ns_slices = NULL,   alpha = 0.05,   periods = c(2, 5, 10, 20, 50, 100),   tolerance = 0.01 )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. ns_slices NS-FFA . Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. periods Numeric vector used set return periods FFA. entries must greater equal 1. tolerance log-likelihood tolerance Regula-Falsi convergence (default 0.01).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"list containing following four items: method: \"RFGPL\" ns_structure: ns_structure argument, given. ns_slices: ns_slices argument, given. ci: dataframe containing confidence intervals (S-FFA ) ci_list: list dataframes containing confidence intervals (NS-FFA ). dataframe(s) ci ci_list four columns: estimates: Estimated quantiles return period. lower: Lower bound confidence interval return period. upper: Upper bound confidence interval return period. periods: periods argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"Uses fit_gmle() obtain maximum generalized log‐likelihood. Defines objective function \\(f(y_p, p)\\) reparameterizing generalized log-likelihood. Iteratively brackets root rescaling initial guesses 0.05 \\(f(y_p, p)\\) changes sign. Uses regula-falsi method solve \\(f(y_p, p) = 0\\) return period probability. Returns lower upper confidence bounds significance level alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"RFGPL uncertainty quantification can numerically unstable datasets. function encounters issue, return error recommend uncertainty_bootstrap() instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151 Vidrio-Sahagún, C.T., , J. & Pietroniro, . Multi-distribution regula-falsi profile likelihood method nonstationary hydrological frequency analysis. Stochastic Environmental Research Risk Assessment 38, 843–867 (2024). doi:10.1007/s00477-023-02603-0","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_rfgpl(data, c(6, 9)) #> $method #> [1] \"RFGPL\" #>  #> $ns_structure #> NULL #>  #> $ns_slices #> NULL #>  #> $ci #>   periods estimates     lower     upper #> 1       2  97.38167  95.29788  99.66764 #> 2       5 108.70545 105.46690 112.50746 #> 3      10 116.98965 112.71372 122.12315 #> 4      20 125.58186 120.13719 132.20006 #> 5      50 137.72617 130.47343 146.64420 #> 6     100 147.64854 138.80465 158.58547 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"Calculates return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using regula-falsi profile likelihood root‐finding method. NS-FFA: perform uncertainty quantification nonstationary model, include observation years (ns_years), nonstationary model structure (ns_structure), list years compute return level estimates confidence intervals (ns_slices).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"","code":"uncertainty_rfpl(   data,   distribution,   ns_years = NULL,   ns_structure = NULL,   ns_slices = NULL,   alpha = 0.05,   periods = c(2, 5, 10, 20, 50, 100),   tolerance = 0.01 )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. ns_slices NS-FFA . Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. periods Numeric vector used set return periods FFA. entries must greater equal 1. tolerance log-likelihood tolerance Regula-Falsi convergence (default 0.01).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"list containing following four items: method: \"RFPL\" ns_structure: ns_structure argument, given. ns_slices: ns_slices argument, given. ci: dataframe containing confidence intervals (S-FFA ) ci_list: list dataframes containing confidence intervals (NS-FFA ). dataframe(s) ci ci_list four columns: estimates: Estimated quantiles return period. lower: Lower bound confidence interval return period. upper: Upper bound confidence interval return period. periods: periods argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"Uses fit_mle() obtain maximum log‐likelihood. Defines objective function \\(f(y_p, p)\\) reparameterizing log-likelihood. Iteratively brackets root rescaling initial guesses 0.05 \\(f(y_p, p)\\) changes sign. Uses regula-falsi method solve \\(f(y_p, p) = 0\\) return period probability. Returns lower upper confidence bounds significance level alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"RFPL uncertainty quantification can numerically unstable datasets. function encounters issue, return error recommend using parametric bootstrap method uncertainty_bootstrap() instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151 Vidrio-Sahagún, C.T., , J. & Pietroniro, . Multi-distribution regula-falsi profile likelihood method nonstationary hydrological frequency analysis. Stochastic Environmental Research Risk Assessment 38, 843–867 (2024). doi:10.1007/s00477-023-02603-0","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_rfpl(data, \"GLO\") #> $method #> [1] \"RFPL\" #>  #> $ns_structure #> NULL #>  #> $ns_slices #> NULL #>  #> $ci #>   periods estimates     lower    upper #> 1       2  101.2751  99.19611 103.4211 #> 2       5  109.7932 107.32076 112.7611 #> 3      10  115.1027 111.97286 119.5162 #> 4      20  120.2208 116.04191 126.7392 #> 5      50  127.0368 120.79309 137.3857 #> 6     100  132.3444 124.04251 146.5332 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"Computes generalized log-likelihood stationary nonstationary variants Generalized Extreme Value (GEV) distribution geophysical (Beta) prior distribution shape parameter (Martins Stedinger, 2000). NS-FFA: compute generalized log-likelihood nonstationary probability model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"","code":"utils_generalized_likelihood(   data,   params,   prior,   ns_years = NULL,   ns_structure = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"Numeric scalar. generalized log-likelihood value.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"generalized log-likelihood defined sum (1) log-likelihood (2) log-density Beta prior parameters \\((p, q)\\). contribution prior : $$\\log \\pi(\\kappa) = (p-1) \\log(0.5-\\kappa) + (q-1) \\log(0.5+\\kappa) - \\log (\\beta(p, q))$$","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"El Adlouni, S., Ouarda, T.B.M.J., Zhang, X., Roy, R., Bobee, B., 2007. Generalized maximum likelihood estimators nonstationary generalized extreme value model. Water Resources Research 43 (3), 1–13. doi:10.1029/2005WR004545 Martins, E. S., Stedinger, J. R. (2000). Generalized maximum-likelihood generalized extreme-value quantile estimators hydrologic data. Water Resources Research, 36(3), 737–744. doi:10.1029/1999WR900330","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(1, 1, 1, 1) prior <- c(5, 10) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  # Compute the generalized log-likelihood utils_generalized_likelihood(data, params, prior, ns_years, ns_structure) #> Warning: NaNs produced #> [1] NaN"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"Compute log-likelihood stationary nonstationary probability models. NS-FFA: compute log-likelihood nonstationary probability model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"","code":"utils_log_likelihood(   data,   distribution,   params,   ns_years = NULL,   ns_structure = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. ns_years NS-FFA . Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"Numeric scalar. log-likelihood value.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(1, 1, 1, 1) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  # Compute the log-likelihood utils_log_likelihood(data, \"GNO\", params, ns_years, ns_structure) #> [1] -Inf"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Functions for Probability Models — utils_quantiles","title":"Quantile Functions for Probability Models — utils_quantiles","text":"Compute quantiles stationary nonstationary probability models. NS-FFA: compute quantiles nonstationary probability model, specify time slice (ns_slice) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Functions for Probability Models — utils_quantiles","text":"","code":"utils_quantiles(p, distribution, params, ns_slice = 0, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Functions for Probability Models — utils_quantiles","text":"p Numeric vector probabilities 0 1 missing values. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. ns_slice NS-FFA . Numeric scalar specifying year evaluate quantiles nonstationary probability distribution. ns_slice element ns_years argument. ns_structure NS-FFA . Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Functions for Probability Models — utils_quantiles","text":"numeric vector quantiles length p.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Functions for Probability Models — utils_quantiles","text":"","code":"p <- runif(n = 100) params <- c(1, 1, 1) utils_quantiles(p, \"GEV\", params) #>   [1]  2.4666847  3.4950121 26.1556802  3.2345470  2.6931867  0.2435830 #>   [7]  0.6269835  2.8402128 10.2380081  3.6969446  1.1312619  1.9922922 #>  [13]  1.4325774  0.8195452  1.0835757  1.2036872  2.8097046  0.6565409 #>  [19]  0.4012199  0.3121710  1.5241493 21.6154858  0.7465035  1.9976075 #>  [25]  1.2301924  6.3474841  1.3096856  5.6510131  4.8775172  1.5102954 #>  [31]  3.3410673  2.0313215  0.1723445  3.2281077  2.9360130  0.7143273 #>  [37]  1.3371532  0.8591236  0.6466655  0.3833000  0.6599588  0.9787352 #>  [43]  0.2989051  0.5866714  1.5104043  1.6610655 11.0243983  1.3211304 #>  [49]  0.2959296  1.3172886  7.4973113  1.9440010  0.8659400  0.6121291 #>  [55] 47.2800933  2.2525122  0.9202294  2.1745096  4.1532640  1.4217814 #>  [61]  0.6584235  0.8220539  0.6115734  0.4342235  1.3889402  1.2784336 #>  [67] 18.9807630  0.4587727  1.2858622  1.1816469 39.8984444  0.8202021 #>  [73]  0.9376804  1.1062952  5.9285384  0.9373009  1.9164821  0.6941272 #>  [79]  1.1921584  0.6312081  1.3851441  0.5346806  2.6501865  0.9666124 #>  [85]  1.3264494  6.5310088 12.6796871  1.9229663 28.1915678  1.4339464 #>  [91]  0.6017530  0.6988725  0.7521211  1.6447825  1.1599285  0.9013736 #>  [97]  0.7129161 12.1867549  0.6787519  0.9381461"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample L-moments — utils_sample_lmoments","title":"Sample L-moments — utils_sample_lmoments","text":"Computes first four sample L-moments L-moment ratios numeric vector data. L-moments linear combinations order statistics provide robust alternatives conventional moments, advantages parameter estimation heavy-tailed skewed distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample L-moments — utils_sample_lmoments","text":"","code":"utils_sample_lmoments(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample L-moments — utils_sample_lmoments","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample L-moments — utils_sample_lmoments","text":"numeric vector containing first four sample L-moments L-moment ratios: \\(l_1\\): L-mean \\(l_2\\): L-variance \\(t_3\\): L-skewness \\(t_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample L-moments — utils_sample_lmoments","text":"Given probability weighted moments \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\), first four sample L-moments : \\(l_1 = \\beta_0\\) \\(l_2 = 2\\beta_1 - \\beta_0\\) \\(l_3 = 6\\beta_2 - 6\\beta_1 + \\beta_0\\) \\(l_4 = 20\\beta_3 - 30\\beta_2 + 12\\beta_1 - \\beta_0\\) , sample L-skewness \\(t_3 = l_3 / l_2\\) sample L-kurtosis \\(t_4 = l_4 / l_2\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample L-moments — utils_sample_lmoments","text":"Hosking, J. R. M. (1990). L-moments: Analysis estimation distributions using linear combinations order statistics. Journal Royal Statistical Society: Series B (Methodological), 52(1), 105–124.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample L-moments — utils_sample_lmoments","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) utils_sample_lmoments(data) #> [1] 99.38291615  6.04961940  0.03415494  0.09602903"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":null,"dir":"Reference","previous_headings":"","what":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"Computes first four L-moments L-moment ratios stationary probability models.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"","code":"utils_theoretical_lmoments(distribution, params)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"numeric vector four elements: \\(\\lambda_1\\): L-mean \\(\\lambda_2\\): L-variance \\(\\tau_3\\): L-skewness \\(\\tau_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"distributions \"GUM\", \"\", \"GEV\", \"GLO\", \"WEI\" closed-form solutions L-moments L-moment ratios terms parameters. distributions \"GNO\" \"PE3\" use rational approximations L-moment ratios Hosking (1997). L-moments ratios \"LNO\" \"LP3\" distributions compared log-transformed data thus identical \"\" \"PE3\" distributions respectively.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"","code":"utils_theoretical_lmoments(\"GEV\", c(1, 1, 1)) #> [1]  1.0000000  0.5000000 -0.3333333  0.1666667"}]
