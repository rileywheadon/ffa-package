[{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU Affero General Public License","title":"GNU Affero General Public License","text":"Version 3, 19 November 2007 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU Affero General Public License","text":"GNU Affero General Public License free, copyleft license software kinds works, specifically designed ensure cooperation community case network server software. licenses software practical works designed take away freedom share change works. contrast, General Public Licenses intended guarantee freedom share change versions program–make sure remains free software users. speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. Developers use General Public Licenses protect rights two steps: (1) assert copyright software, (2) offer License gives legal permission copy, distribute /modify software. secondary benefit defending users’ freedom improvements made alternate versions program, receive widespread use, become available developers incorporate. Many developers free software heartened encouraged resulting cooperation. However, case software used network servers, result may fail come . GNU General Public License permits making modified version letting public access server without ever releasing source code public. GNU Affero General Public License designed specifically ensure , cases, modified source code becomes available community. requires operator network server provide source code modified version running users server. Therefore, public use modified version, publicly accessible server, gives public access source code modified version. older license, called Affero General Public License published Affero, designed accomplish similar goals. different license, version Affero GPL, Affero released new version Affero GPL permits relicensing license. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU Affero General Public License","text":"“License” refers version 3 GNU Affero General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU Affero General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU Affero General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU Affero General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU Affero General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU Affero General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU Affero General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU Affero General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU Affero General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU Affero General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU Affero General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU Affero General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU Affero General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_13-remote-network-interaction-use-with-the-gnu-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Remote Network Interaction; Use with the GNU General Public License.","title":"GNU Affero General Public License","text":"Notwithstanding provision License, modify Program, modified version must prominently offer users interacting remotely computer network (version supports interaction) opportunity receive Corresponding Source version providing access Corresponding Source network server charge, standard customary means facilitating copying software. Corresponding Source shall include Corresponding Source work covered version 3 GNU General Public License incorporated pursuant following paragraph. Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU General Public License single combined work, convey resulting work. terms License continue apply part covered work, work combined remain governed version 3 GNU General Public License.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU Affero General Public License","text":"Free Software Foundation may publish revised /new versions GNU Affero General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU Affero General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU Affero General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU Affero General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU Affero General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU Affero General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU Affero General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU Affero General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. software can interact users remotely computer network, also make sure provides way users get source. example, program web application, interface display “Source” link leads users archive code. many ways offer source, different solutions better different programs; see section 13 specific requirements. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU AGPL, see https://www.gnu.org/licenses/.","code":"<one line to give the program's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>      This program is free software: you can redistribute it and/or modify     it under the terms of the GNU Affero General Public License as     published by the Free Software Foundation, either version 3 of the     License, or (at your option) any later version.      This program is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the     GNU Affero General Public License for more details.      You should have received a copy of the GNU Affero General Public License     along with this program.  If not, see <https://www.gnu.org/licenses/>."},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Change Point Detection","text":"vignette explore Kootenai River Porthill (08NH021) station, located border British Columbia Idaho. station located downstream Libby Dam, finished construction 1972. Data station provided CAN-08NH021.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-08NH021.csv\") head(df) #>   year  max #> 1 1928 2350 #> 2 1929 1680 #> 3 1930 1730 #> 4 1931 1470 #> 5 1932 2190 #> 6 1933 2640  plot_ams_data(df$max, df$year, title = \"Kootenai River at Porthill (08NH021)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"the-pettitt-test","dir":"Articles","previous_headings":"","what":"The Pettitt Test","title":"Change Point Detection","text":"rank-based test detects single abrupt change median time series. null hypothesis assumes change point. Use eda_pettitt_test function perform test. requires two arguments: data: annual maximum series (AMS) years: corresponding numeric vector years  Conclusion: p-value <0.001 provides strong evidence change point year 1972.","code":"pettitt_test <- eda_pettitt_test(df$max, df$year)  print(pettitt_test$p_value) #> [1] 0  print(pettitt_test$change_year) #> [1] 1972  plot_pettitt_test(pettitt_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"the-mks-test","dir":"Articles","previous_headings":"","what":"The MKS Test","title":"Change Point Detection","text":"Mann-Kendall-Sneyers (MKS) test identifies trend changes data. Use eda_mks_test arguments .  Conclusion: p-value 0.015, evidence trend changes 1960 1985. Note: Since MKS test can identify multiple change points, reported p-value determined using significant change point.","code":"mks_test <- eda_mks_test(df$max, df$year)  print(mks_test$p_value) #> [1] 0.01495225  print(mks_test$change_df$year) #> [1] 1960 1985  plot_mks_test(mks_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"interpreting-and-selecting-change-points","dir":"Articles","previous_headings":"","what":"Interpreting and Selecting Change Points","title":"Change Point Detection","text":"example, Pettitt MKS tests suggest structural changes time series. Consider following guidelines choosing split data: Incorporate domain knowledge case-specific understanding. example, know water regulation structure built 1972 (Libby dam). supports results Pettitt test. Avoid overpartitioning. Pettitt MKS tests operate independently may detect multiple change points. minimize sample size issues reduce uncertainty, retain significant change points physical justification. Prioritize based p-value. Lower p-values indicate stronger evidence given weight.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"change-point-detection","dir":"Articles","previous_headings":"","what":"Change Point Detection","title":"Change Point Detection","text":"EDA module FFA Framework includes two statistical tests detecting change points annual maximum series data: Mann-Kendall-Sneyers (MKS) test Pettitt test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"mann-kendall-sneyers-test","dir":"Articles","previous_headings":"Change Point Detection","what":"Mann-Kendall-Sneyers Test","title":"Change Point Detection","text":"Mann-Kendall-Sneyers (MKS) test detects trend change time series: Null hypothesis: change points. Alternative hypothesis: one change points. Define \\(\\mathbb{}(y_{} > y_{j})\\) \\(1\\) \\(y_{} > y_{j}\\) \\(0\\) otherwise. Given time series \\(y_{1}, \\dots, y_{n}\\), compute progressive series \\(S^{F}_{t}\\): \\[ S^{F}_{t} = \\sum_{=}^{t} \\sum_{j=1}^{-1} \\mathbb{}(y_{} > y_{j}) \\] Next, reverse time series \\(y\\). gives us new time series \\(y'\\) \\(y_{}' = y_{n+1-}\\). compute regressive series \\(S^{B}_{t}\\), \\(\\text{rev}()\\) indicates vector reversed: \\[ S^{B}_{t} = \\text{rev}\\left( \\sum_{=}^{t} \\sum_{j=1}^{-1} \\mathbb{}(y'_{} > y'_{j})\\right) \\] , compute normalized progressive series \\(UF_{t}\\) normalized regressive series \\(UB_{t}\\): \\[ UF_{t} = \\frac{S^{F}_{t} - \\mathbb{E}[S^{F}_{t}]}{\\sqrt{\\text{Var}\\,(S^{F}_{t})}}, \\quad UB_{t} = \\frac{S^{B}_{t} - \\mathbb{E}[S^{B}_{t}]}{\\sqrt{\\text{Var}\\,(S^{B}_{t})}} \\] progressive regressive series, expectation variance follows: \\[ \\mathbb{E}[S^{F}_{t}] = \\mathbb{E}[S^{B}_{t}] = \\frac{t(t-1)}{4}, \\quad \\text{Var}(S^{F}_{t}) = \\text{Var}(S^{B}_{t}) = \\frac{t(t-1)(2t+5)}{72} \\] Finally, plot \\(UF_{t}\\) \\(UB_{t}\\) confidence bounds \\(\\alpha/2\\) \\(1 - (\\alpha /2)\\) quantiles standard normal distribution, \\(\\alpha\\) chosen significance level. crossing point \\(UF_{t}\\) \\(UB_{t}\\) lies outside confidence bounds potential change point.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"pettitt-test","dir":"Articles","previous_headings":"Change Point Detection","what":"Pettitt Test","title":"Change Point Detection","text":"Pettitt test detects abrupt changes mean time series. Null hypothesis: abrupt changes. Alternative hypothesis: one abrupt change. Define \\(\\text{sign}(x)\\) \\(1\\) \\(x > 0\\), \\(0\\) \\(x = 0\\), \\(-1\\) otherwise. Given time series \\(y_{1}, \\dots, y_{n}\\), compute following test statistic: \\[ U_{t} = \\sum_{=1}^{t} \\sum_{j=t+1}^{n} \\text{sign} (y_{j} - y_{}), \\quad K = \\max_{t}|U_{t}| \\] value \\(t\\) \\(U_{t} = K\\) potential change point. p-value potential change point can approximated using following formula one-sided test: \\[ p \\approx \\exp \\left(-\\frac{6K^2}{n^3 + n^2}\\right) \\] p-value less significance level \\(\\alpha\\), reject null hypothesis conclude evidence abrupt change mean potential change point.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"introduction-to-exploratory-data-analysis-eda","dir":"Articles","previous_headings":"","what":"Introduction to Exploratory Data Analysis (EDA)","title":"","text":"EDA module FFA Framework used evaluate whether available evidence supports assumption stationarity. , EDA module applies structured sequence statistical tests data detect statistically significant nonstationary signatures. statistical tests serve three purposes: Detect change points (.e., abrupt shifts trend changes). Detect trends mean identify deterministic/stochastic, linear/non-linear. Detect trends variability (.e., heteroskedasticity trends standard deviation). primary goal EDA inform choice stationary nonstationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"stationary-and-nonstationary-ffa","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA)","what":"Stationary and Nonstationary FFA","title":"","text":"Prior performing FFA, necessary choose stationary (S-FFA) nonstationary (NS-FFA) approach. using S-FFA, assumed time series independent identically distributed. Evidence change point(s) /time dependence violates assumptions stationarity indicates NS-FFA may necessary.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"identifying-change-points","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA) > The EDA Workflow","what":"Identifying Change Points","title":"","text":"change point abrupt shift (jump) temporal pattern switch (trend change) time series. Change points indicate inhomogeneous periods (nonstationarity), meaning single model may represent entire record adequately. Instead, piecewise analysis applied homogeneous subperiod. Pettitt test MKS test used identify abrupt shifts temporal pattern switches respectively. However, statistically significant result one tests conclusively identify change point. Type 1 errors issues data quality can cause Pettitt MKS tests identify spurious change points, type 2 errors can cause true change points go unnoticed. Therefore, always important use station-specific knowledge addition results tests.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"identifying-time-dependence","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA) > The EDA Workflow","what":"Identifying Time Dependence","title":"","text":"many types time dependence, FFA framework focuses identifying linear trends mean /variability using two groups statistical tests. Identifying trends mean: First, Mann-Kendall test used identify evidence linear trend mean. trend identified, Spearman test used check evidence autocorrelation, known cause issues Mann-Kendall test. autocorrelation identified, BB-MK test used place Mann-Kendall test identify linear trend mean. Finally, trend identified, PP KPSS tests used check trend deterministic stochastic. Identifying trends variability: variability time series can estimated computing sample standard deviation sequential subsets data (moving window). MW-MK test applies Mann-Kendall test variability time series identify linear trend. White test also used identify general time-dependence (e.g. nonlinear trends) variability. Trend estimation: Sen’s trend estimator robust, nonparametric estimator used estimate linear trend. can applied trends mean variability. linear trend estimated, fit can assessed using runs test, checks randomness residuals. residuals non-random, linear trend may suitable data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"detecting-and-characterizing-trends-in-the-mean","dir":"Articles","previous_headings":"","what":"Detecting and Characterizing Trends in the Mean","title":"","text":"section describes statistical tests (listed alphabetical order) used detect characterizesignificant trends mean annual maximum series. tests help identify trend, identify autocorrelation, determine whether trend deterministic/stochastic linear/non-linear.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"bb-mk-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"BB-MK Test","title":"","text":"Block Bootstrap Mann-Kendall (BB-MK) Test assesses presence statistically significant monotonic trend time series. BB-MK test insensitive autocorrelation, known produce false positives MK test. Null hypothesis: monotonic trend. Alternative hypothesis: monotonic upward downward trend exists. conduct BB-MK test, rely results MK test Spearman autocorrelation test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > BB-MK Test","what":"Steps","title":"","text":"Compute MK test statistic (see ). Use Spearman test (see ) identify least insignificant lag \\(k\\). Resample time series blocks size \\(k+1\\) without replacement. Compute MK test statistic bootstrapped sample. Derive empirical distribution MK test statistic bootstrapped statistics. Estimate significance observed test statistic using empirical distribution.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"kpss-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"KPSS Test","title":"","text":"KPSS Test determines whether autoregressive time series unit root. test helps assess time series deterministic linear trend. Null hypothesis: time series deterministic linear trend. Alternative hypothesis: time series unit root (stochastic trend). autoregressive time series shown unit root \\(\\sigma_{v}^2 > 0\\): \\[ \\begin{align} y_{t} &= \\mu_{t} + \\beta t +  \\epsilon_{t} \\\\[5pt] \\mu_{t} &= \\mu_{t-1} + v_{t} \\\\[5pt] v_{t} &\\sim \\mathcal{N}(0, \\sigma_{v}^2) \\end{align} \\] : \\(\\mu_{t}\\) drift, deviation \\(y_{t}\\) \\(0\\). null hypothesis, \\(\\mu_{t}\\) constant (since \\(v_{t}\\) constant). alternative hypothesis, \\(\\mu_t\\) stochastic process unit root. \\(\\beta t\\) linear trend, represents deterministic nonstationarity (e.g., climate change). \\(\\epsilon_{t}\\) stationary noise, corresponding reversible fluctuations \\(y_{t}\\). hydrology, \\(\\epsilon_{t}\\) represents fluctuations streamflow due natural variability. \\(v_{t}\\) random walk innovation, irreversible fluctuations \\(\\mu_{t}\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-1","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > KPSS Test","what":"Steps","title":"","text":"Fit linear model \\(y_{t}\\) get residuals \\(\\hat{r}_{t}\\). Compute cumulative partial-sum statistics \\(S_{k}\\) using following formula: \\[ S_{k} = \\sum_{t=1}^{k} \\hat{r}_{t} \\] null hypothesis, \\(S_{k}\\) behave like random walk finite variance. \\(y_{t}\\) unit root, sums “drift” much. Estimate long-run variance time series using Newey-West estimator: \\[ \\hat{\\lambda}^2 = \\hat{\\gamma}_0 + 2 \\sum_{j=1}^{q} \\left(1 - \\frac{j}{q+1} \\right) \\hat{\\gamma}_j \\] \\(q = \\left\\lfloor \\frac{3\\sqrt{n}}{13} \\right\\rfloor\\) autocovariance \\(\\hat{\\gamma}_j\\) : \\[ \\hat{\\gamma}_j = \\frac{1}{n} \\sum_{t = j+1}^{n} \\hat{r}_t \\hat{r}_{t-j} \\] Compute test statistic \\(z_{K}\\): \\[ z_{K} = \\frac{1}{n^2\\hat{\\lambda }^2}\\sum_{k=1}^{n}  S_{k}^2 \\] Since test statistic \\(z_{K}\\) non-normally distributed, compute p-value interpolating table quantiles Hobjin et al. (2004) shown . Warning: interpolation works \\(0.01 < p < 0.10\\) (p-values \\(0.01\\) \\(0.10\\) truncated) significance levels \\(\\alpha\\) \\(0.01\\) \\(0.10\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"mann-kendall-mk-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Mann-Kendall (MK) Test","title":"","text":"Mann-Kendall (MK) Test detects statistically significant monotonic trends time series assumption independence (.e. autocorrelation). Null hypothesis: monotonic trend. Alternative hypothesis: (upward downward) monotonic trend exists. Define \\(\\text{sign} (x)\\) \\(1\\) \\(x > 0\\), \\(0\\) \\(x = 0\\), \\(-1\\) otherwise. test statistic \\(S\\) defined follows: \\[ S = \\sum_{k-1}^{n-1}  \\sum_{j - k + 1}^{n} \\text{sign} (y_{j} - y_{k}) \\] Next, need compute \\(\\text{Var}(S)\\), depends number tied groups data. Let \\(g\\) number tied groups \\(t_{p}\\) number observations \\(p\\)-th group. \\[\\text{Var}(S) = \\frac{1}{18} \\left[n(n-1)(2n + 1) - \\sum_{p-1}^{g} t_{p}(t_{p} - 1)(2t_{p} + 5) \\right]\\] , compute normally distributed test statistic \\(Z_{MK}\\) follows: \\[ Z_{MK} = \\begin{cases} \\frac{S-1}{\\sqrt{\\text{Var}(S)}} &\\text{} S > 0 \\\\ 0 &\\text{}  S = 0 \\\\ \\frac{S+1}{\\sqrt{\\text{Var}(S)}} &\\text{} S < 0 \\end{cases} \\] two-sided test, reject null hypothesis \\(|Z_{MK}| \\geq Z_{1 - (\\alpha/2) }\\) conclude statistically significant monotonic trend data. information, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"phillips-perron-pp-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Phillips-Perron (PP) Test","title":"","text":"PP Test identifies autoregressive time series unit root. Null hypothesis: time series unit root (stochastic trend). Alternative hypothesis: time series deterministic linear trend. Precisely, let \\(x_{t}\\) AR(1) model. Let \\(y_{t}\\) function \\(x_{t}\\) drift \\(\\beta_{0}\\) trend \\(\\beta_{1} t\\). \\[ \\begin{align} y_{t} &= \\beta_{0} + \\beta_{1} t + x_{t} \\\\[5pt] x_{t} &= \\rho x_{t-1} + \\epsilon_{t} \\end{align} \\] \\(\\rho = 1\\), \\(x_t\\) hence \\(y_t\\) unit root (null hypothesis). \\(\\rho < 1\\), \\(y_t\\) trend stationary (alternative hypothesis).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-2","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Phillips-Perron (PP) Test","what":"Steps","title":"","text":"Fit linear autoregressive model time series \\(y_{t}\\). Let \\(\\hat{r}_{t}\\) residuals model. model, can determine \\(\\hat{\\rho}\\) (estimated coefficient \\(y_{t-1}\\)) \\(\\text{SE}(\\hat{\\rho})\\). Estimate variance residuals \\(\\hat{\\sigma}^2\\): \\[ \\hat{\\sigma^2} = \\frac{1}{n - 3} \\sum_{t=1}^{n} \\hat{r}_{t}^2 \\] \\(n\\) number data points sample. \\(n-3\\) degrees freedom since three parameters autoregressive model (\\(\\beta_{0}\\), \\(\\beta_{1}\\), \\(\\rho\\)). Estimate long-run variance \\(\\hat{\\lambda}^2\\) using Newey-West style estimator. estimator corrects additional variability \\(\\epsilon_{t}\\) caused autocorrelation heteroskedasticity. \\[ \\hat{\\lambda}^2 = \\hat{\\gamma}_{0} + 2\\sum_{j=1}^{q} \\left(1 - \\frac{j}{q + 1} \\right)  \\gamma_{j} \\] sample autocovariances \\(\\gamma_{j}\\) computed \\(q = \\left\\lfloor \\sqrt[4]{\\frac{n}{25}}\\right\\rfloor\\) lags: \\[ \\hat{\\gamma}_{j} = \\frac{1}{n} \\sum_{t = j + 1}^{n} \\hat{r}_{t}\\hat{r}_{t-j} \\] Compute test statistic \\(z_{\\rho}\\) using following formula: \\[ z_{\\rho } = n(\\hat{\\rho} - 1) - \\frac{n^2 \\text{SE}(\\hat{\\rho})^2}{2 \\hat{\\sigma}^2}(\\hat{\\lambda }^2 - \\hat{\\gamma}_{0}) \\] test statistic \\(z_{\\rho}\\) normally distributed. Instead, compute p-value interpolating table Fuller, W. . (1996). table shown sample sizes \\(n\\) probabilities \\(p\\): Warning: interpolation works p-values \\(p > 0.01\\) (p-values \\(0.01\\) truncated) confidence levels \\(\\alpha > 0.01\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"runs-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Runs Test","title":"","text":"Runs Test checks whether residuals regression (e.g., trend approximation Sen’s estimator) randomly distributed. Runs test identifies non-randomness residuals, strong indication nonstationarity data non-linear. Null hypothesis: Residuals distributed randomly. Alternative hypothesis: Residuals distributed randomly (e.g., due nonlinearity).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-3","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Runs Test","what":"Steps","title":"","text":"Classify data based whether (\\(+\\)) \\((-)\\) median. data points equal median removed. Compute number contiguous blocks \\(+\\) \\(-\\) (known runs) data. example, sequence \\(+++--+++-+-\\) six runs length \\((3, 2, 3, 1, 1, 1)\\). Let \\(R\\) number runs \\(N\\) data points (category counts \\(N_{+}\\) \\(N_{-}\\)). , null hypothesis, \\(R\\) asymptotically normal : \\[ \\mathbb{E}[R] = \\frac{2N_{+}N_{-}}{N} + 1, \\quad \\text{Var}(R) = \\frac{2N_{+}N_{-}(2N_{+}N_{-} - N)}{N^2(N - 1)} \\] Compute p-value normalizing \\(R\\) using expectation variance given .","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Sen’s Trend Estimator","title":"","text":"Sen’s Trend Estimator approximates slope regression line. Unlike Least Squares, Sen’s trend estimator uses non-parametric approach makes robust outliers.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-4","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Sen’s Trend Estimator","what":"Steps","title":"","text":"pairs \\((x_i, y_i)\\) \\((x_j, y_j)\\) \\(x_i \\neq x_j\\), compute slopes: \\[ m_{ij} = \\frac{y_j - y_i}{x_j - x_i} \\] Take median slopes: \\(\\hat{m}\\). Estimate \\(y\\)-intercept \\(\\hat{b}\\) median \\(y_{} - \\hat{m}x_{}\\) \\(\\).","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"spearman-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Spearman Test","title":"","text":"Spearman test identifies autocorrelation time series \\(y_{t}\\). significant lag number \\(\\) correlation \\(y_{t}\\) \\(y_{t-}\\) statistically significant. least insignificant lag smallest \\(\\) significant lag. Null hypothesis: least insignificant lag \\(1\\). Alternative hypothesis: least insignificant lag greater \\(1\\). carry Spearman test, use following procedure: Compute Spearman’s correlation coefficient \\(\\rho_{}\\) \\(y_{t}\\) \\(y_{t-}\\) \\(0 \\leq  <  n\\). Compute \\(p\\)-value \\(p_{}\\) correlation coefficient \\(\\rho _{}\\) using formula: \\[ t_{}= \\rho_{} \\sqrt{\\frac{n-2}{1 - \\rho _{}^2}} \\] test statistic \\(t_{}\\) \\(t\\)-distribution \\(n-2\\) degrees freedom. Find smallest \\(\\) \\(p_{} > \\alpha\\). \\(\\) least insignificant lag confidence level \\(\\alpha\\). information, see Wikipedia pages Autocorrelation Spearman’s Rho.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"detecting-trends-in-the-variability","dir":"Articles","previous_headings":"","what":"Detecting Trends in the Variability","title":"","text":"section describes methods used detect trends changes variability (e.g., variance standard deviation) annual maximum series data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"moving-window-mann-kendall-mw-mk-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Moving Window Mann-Kendall (MW-MK) Test","title":"","text":"MW-MK test detects statistically significant monotonic trends standard deviation data. Null hypothesis: significant trend standard deviation. Alternative hypothesis: Significant monotonic trend standard deviation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"steps","dir":"Articles","previous_headings":"Detecting Trends in the Variability > Moving Window Mann-Kendall (MW-MK) Test","what":"Steps","title":"","text":"compute standard deviations data, use moving window algorithm. Let \\(w\\) length moving window \\(s\\) step size. , Initialize moving window indices \\([1, w]\\). Compute sample standard deviation within window. Move window forward \\(s\\) steps. Repeat steps 2 3 window reaches end data. produces time series moving-window standard deviations. , Mann-Kendall Test used test monotonic trend standard deviation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Sen’s Trend Estimator","title":"","text":"Used estimate slope trend standard deviations (see ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"runs-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Runs Test","title":"","text":"Used check residuals trend fitted standard deviations randomness (see ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"white-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"White Test","title":"","text":"White Test detects changes variability (heteroskedasticity) time series. Null hypothesis: Constant variability (homoskedasticity). Alternative hypothesis: Time-dependent variability (heteroskedasticity).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"steps-1","dir":"Articles","previous_headings":"Detecting Trends in the Variability > White Test","what":"Steps","title":"","text":"Fit simple linear regression model using ordinary least squares: \\[y_{} = \\beta_{0} + \\beta_{1} x_{} + \\epsilon_{}\\] Compute squared residuals: \\[ \\hat{r}_i^2 = \\left(y_i - \\hat{y}_i\\right)^2 \\] Fit auxiliary regression model squared residuals. model includes regressor, square regressor, cross products regressors. Since \\(x\\) regressor, regression model simply: \\[ \\hat{r}_i^2 = \\alpha_0 + \\alpha_1 x_i + \\alpha_2 x_i^2 + u_i \\] Compute coefficient determination \\(R^2\\) auxillary model. Compute test statistic \\(nR^2 \\sim \\chi_{d}^2\\) \\(n\\) number observations \\(d = 2\\) number regressors, excluding intercept. \\(nR^2 > \\chi^2_{1-\\alpha, d}\\), reject null hypothesis conclude time series exhibits heteroskedasticity.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"overview","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA)","what":"Overview","title":"","text":"Flood Frequency Analysis (FFA) uses probability distribution fitted extreme streamflow observations (e.g., annual maxima) estimate recurrence likelihood floods. perform FFA, require probability model corresponding parameter estimates based data. FFA relates flood peak magnitudes \\(Q\\) expected frequency occurrence, expressed return period. example, flood 10-year return period—commonly referred 10-year flood—1--10 chance equalled exceeded given year. corresponds annual exceedance probability \\(p_e = 0.1\\). Since FFA Framework uses annual maxima data, equates 90th percentile (.e., \\(0.90\\) quantile) fitted probability distribution. summary return periods, exceedance probabilities, associated quantiles used default FFA framework: Let \\(F(q)\\) cumulative distribution function (CDF) fitted model. function maps flood magnitudes exceedance probabilities: \\(p_e = 1 - F(q)\\). estimate flood magnitudes given exceedance probability, use inverse CDF, better known quantile function: \\(\\hat{q} = F^{-1}(p_e)\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"example-plot","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA) > Overview","what":"Example Plot","title":"","text":"FFA results typically visualized return period \\(x\\)-axis flood magnitude \\(y\\)-axis. plots can interpreted two directions: Estimate flood magnitude given return period. example, 50-year flood estimated \\(85\\ \\text{m}^3/\\text{s}\\). Estimate return period given flood magnitude. example, streamflow \\(50\\ \\text{m}^3/\\text{s}\\) expected occur roughly every 4 years. Note: explanation confidence bounds plot, see Uncertainty Quantification.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA)","what":"Handling Nonstationarity","title":"","text":"probability model considered nonstationary statistical properties (e.g., location scale) change time. cases, quantile function becomes time-dependent: \\(F^{-1}(p_e, t)\\). result, return levels exceedance probabilities vary time, static return period curve longer valid. address , FFA framework computes effective return periods, yield flood estimates specific year based time-varying distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"example-plot-1","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA) > Handling Nonstationarity","what":"Example Plot","title":"","text":"plot illustrates effective return levels years 1920, 1960, 2000. Remember, 100-year effective return level imply flood expected occur next 100 years. Instead, means given year, probability exceeding effective return level 1 100.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"nonparametric-models","dir":"Articles","previous_headings":"Model Assessment","what":"Nonparametric Models","title":"","text":"Plotting Position non-parametric estimator used derive empirical exceedance probabilities. using plotting position, can evaluate quality parametric model (assuming model stationary). compute plotting position, arrange sample observations descending order magnitude: \\(x_{n:n} \\geq  \\dots  \\geq  x_{1:n}\\). , empirical exceedance probabilities given following formula: \\[ p_{:n} = \\frac{-}{n+1 - 2a}, \\quad \\\\{1, \\dots , n\\} \\] coefficient \\(\\) depends plotting position formula: default, FFA framework uses Weibull formula, unbiased.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"r2---coefficient-of-determination","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"\\(R^2\\) - Coefficient of Determination","title":"","text":"compute \\(R^2\\) statistic, perform linear regression annual maximum series data predictions parametric model plotting positions. \\(R^2\\) statistic describes well parametric model captures variance data. Higher better. plot shows deviation estimated quantiles (red dots), data (black line).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"rmse---root-mean-squared-error","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"RMSE - Root-Mean Squared Error","title":"","text":"RMSE statistic describes average squared difference data predictions parametric model. Lower better.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"bias","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"Bias","title":"","text":"Bias statistic describes average difference data predictions parametric model. positive bias indicates model tends overestimate data negative bias indicates model tends underestimate data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"information-criterion","dir":"Articles","previous_headings":"Model Assessment","what":"Information Criterion","title":"","text":"Akaike Information Criterion (AIC) Bayesian Information Criterion (BIC) describe quality model based error (RMSE) number parameters (n_theta). Better models lower AIC/BIC, indicates less parameters lower error. Akaike/Bayesian information criterion can also computed using maximum log-likelihood maximum likelihood estimation. statistics reported AIC_MLL BIC_MLL.","code":"AIC <- (n * log(RMSE)) + (2 * n_theta) BIC <- (n * log(RMSE)) + (log(n) * n_theta) AIC_MLL <- (n * log(MLL)) + (2 * n_theta) BIC_MLL <- (n * log(MLL)) + (log(n) * n_theta)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"uncertainty-statistics","dir":"Articles","previous_headings":"Model Assessment","what":"Uncertainty Statistics","title":"","text":"FFA framework uses three statistics assess uncertainty flood quantile estimates: AW captures precision (narrower confidence intervals better). POC captures reliability (higher coverage observations better). CWI composite measure balancing precision reliability (lower better). use metrics together evaluate robustness flood frequency analysis.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"aw-average-width","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"AW – Average Width","title":"","text":"AW average width interpolated confidence intervals across return periods interest. smaller AW indicates precise quantile estimates. compute AW, use log-linear interpolation estimate confidence intervals empirical exceedance probabilities confidence intervals computed uncertainty quantification.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"poc-percent-of-coverage","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"POC – Percent of Coverage","title":"","text":"POC percentage observed quantiles fall within corresponding confidence intervals. higher POC indicates greater reliability confidence intervals.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"cwi-confidence-width-indicator","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"CWI – Confidence Width Indicator","title":"","text":"CWI composite metric penalizes wide /poorly calibrated confidence intervals. lower CWI better. Wide intervals low coverage increase penalty. Ideal confidence intervals narrow well-calibrated, resulting low CWI. CWI computed using following formula, alpha significance level.","code":"CWI <- AW * exp((1 - alpha) - POC / 100)^2;"},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"model-selection","dir":"Articles","previous_headings":"","what":"Model Selection","title":"","text":"module selects statistical model S-FFA NS-FFA based annual maximum series. S-FFA: time-invariant probability distribution selected candidate distributions. NS-FFA: distribution chosen along nonstationary structure capture evolution time. piecewise NS-FFA, series segmented subperiods, modelled either time-invariant time-varying distributions. framework uses L-moment ratio method identify best-fit distribution family comparing sample L-moments L-moments various distribution families. NS-FFA, series decomposed isolate stationary component following Vidrio-Sahagún (2022). decomposed sample used distribution selection, S-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"an-introduction-to-l-moments","dir":"Articles","previous_headings":"Model Selection","what":"An Introduction to L-Moments","title":"","text":"Definition 1: \\(k\\)-th Order Statistic statistical sample \\(k\\)-th smallest value. Definition 2: \\(r\\)-th Population L-moment \\(\\lambda_{r}\\) linear combination expectation order statistics. Let \\(X_{k:n}\\) \\(k\\)-th order statistic sample size \\(n\\). , \\[ \\lambda_{r} = \\frac{1}{r} \\sum_{k=0}^{r-1} (-1)^{k} \\binom{r-1}{k} \\mathbb{E}[X_{r-k:r}] \\] Definition 3: Probability Weighted Moment (PWM) encodes information value’s position cumulative distribution function. \\(r\\)-th PWM, denoted \\(\\beta_{r}\\), : \\[ \\beta_{r} = \\mathbb{E}[X \\cdot  F(X)^{r}] \\] ordered sample \\(x_{1:n} \\leq  \\dots  \\leq  x_{n:n}\\), sample PWM often estimated : \\[ b_{r} = \\frac{1}{n} \\sum_{=1}^{r} x_{:n} \\left(\\frac{-1}{n-1}\\right) ^{r} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"sample-l-moments-from-pwms-and-l-moment-ratios","dir":"Articles","previous_headings":"Model Selection > An Introduction to L-Moments","what":"Sample L-Moments (from PWMs) and L-Moment Ratios","title":"","text":"first four sample L-moments can computed linear combinations PWMs: \\[ \\begin{aligned} l_{1} &= b_{0} \\\\ l_{2} &= 2b_{1} - b_{0} \\\\ l_{3} &= 6b_{2} - 6b_{1} + b_{0} \\\\ l_{4} &= 20b_{3} - 30b_{2} + 12b_{1} - b_{0} \\end{aligned} \\] L-moments used compute Sample L-variance \\(t_{2}\\), Sample L-skewness \\(t_{3}\\) Sample L-kurtosis \\(t_{4}\\) using following formulas: \\[ \\begin{aligned} t_{2} &= l_{2} / l_{1} \\\\ t_{3} &= l_{3} / l_{2} \\\\ t_{4} &= l_{4} / l_{2} \\end{aligned} \\] , compare statistics, specifically L-skewness L-kurtosis theoretical values (given ) using one three different metrics select distribution. Note: Probability distributions two parameters constant L-skewness \\(\\tau_{3}\\) L-kurtosis \\(\\tau_{4}\\) regardless parameters. L-skewness L-kurtosis probability distributions three parameters function shape parameter \\(\\kappa\\). notation \\(\\tau_{3}(\\kappa)\\) \\(\\tau_{4}(\\kappa)\\) refers L-skewness L-kurtosis curves three parameter distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"example-plot","dir":"Articles","previous_headings":"Model Selection > An Introduction to L-Moments","what":"Example Plot","title":"","text":"Shown L-moment curves GEV, GLO, GNO, PE3/LP3, WEI distributions well L-moment ratios two parameter distributions GUM /LNO. L-moment diagram depicts “L-distance” selection metric, compares euclidian distance sample theoretical L-moment ratios. inset shows GEV distribution (yellow line) closest L-moments data.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"l-distance","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"1. L-Distance","title":"","text":"Euclidean distance sample \\((t_3, t_4)\\) theoretical \\((\\tau_3, \\tau_4)\\) candidate distribution. 3-parameter distributions, minimum distance along L-moment ratio curve.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"l-kurtosis","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"2. L-Kurtosis","title":"","text":"L-kurtosis method used three-parameter probability distributions. First, shape parameter \\(\\kappa^{*}\\) \\(t_{3} = \\tau _{3}(\\kappa ^{*})\\) identified. , difference sample L-kurtosis theoretical L-kurtosis computed using metric \\(|\\tau_{4}(\\kappa ^{*}) - t_{4} |\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"z-statistic","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"3. Z-statistic","title":"","text":"Z-statistic selection metric calculated follows (three-parameter distributions): Fit four-parameter Kappa (K4D) distribution sample. Generate \\(N_{\\text{sim}}\\) bootstrap samples fitted K4D distribution. Calculate sample L-kurtosis \\(t_{4}^{[]}\\) synthetic dataset. Calculate bias standard deviation bootstrap distribution: \\[ B_{4} = N_{\\text{sim} }^{-1} \\sum_{= 1}^{N_{\\text{sim} }} \\left(t_{4}^{[]} - t_{4}^{s}\\right) \\] \\[ \\sigma _{4} = \\left[(N_{\\text{sim} } - 1)^{-1} \\left\\{\\sum_{- 1}^{N_{\\text{sim} }} \\left(t_{4}^{[]} - t_{4}^{s}\\right)^2 - N_{\\text{sim} } B_{4}^2\\right\\} \\right] ^{\\frac{1}{2}} \\] Identify shape parameter \\(\\kappa^{*}\\) \\(t_{3} = \\tau _{3}(\\kappa ^{*})\\). Use bootstrap distribution compute Z-statistic distribution: \\[ z = \\frac{\\tau_{4} (\\kappa ^{*}) - t_{4} + B_{4} }{ \\sigma _{4}} \\] Choose distribution smallest Z-statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Model Selection","what":"Handling Nonstationarity","title":"","text":"nonstationarity detected, annual maximum series decomposed model selection. consider three nonstationary scenarios can identified EDA: Trend mean . Trend standard deviation . Trend mean standard deviation.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-1-trend-in-mean","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 1: Trend in mean","title":"","text":"Use Sen’s Trend Estimator approximate slope \\(b_1\\) intercept \\(b_0\\). Detrend: subtract linear function \\((b_{1} \\cdot \\text{Covariate})\\) time series, covariate time index calculated using formula \\((\\text{Years} - 1900) / 100\\). Ensure positivity: necessary, shift series adding constant \\(\\min(\\text{data}) = 1\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-2-trend-in-standard-deviation","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 2: Trend in standard deviation","title":"","text":"Generate time series standard deviations using moving windows method. Use Sen’s Trend Estimator identify slope \\(c_{1}\\) intercept \\(c_{0}\\) trend standard deviations. Normalize data mean \\(0\\), divide scale factor \\(g_{t}\\). \\[ g_{t} = \\frac{(c_{1} \\cdot  \\text{Covariate} ) + c_{0}}{c_{0}} \\] Add back long-term mean \\(\\mu\\), ensure positivity Scenario 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-3-trend-in-both-mean-and-standard-deviation","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 3: Trend in both mean and standard deviation","title":"","text":"Remove linear trend mean exactly Scenario 1. detrended series, generate rolling‐window STD series fit trend. Divide detrended data time-varying scale factor \\(g_{t}\\) (Scenario 2). Shift preserve series mean ensure positivity.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"","text":"module estimates parameters S-FFA NS-FFA. NS-FFA, parameter estimation also involves estimating regression coefficients time-varying parameters. framework supports three estimation methods: L-moments Maximum Likelihood (MLE) Generalized Maximum Likelihood (GMLE) Note: adopt GEV distribution convention Coles (2001)1, positive shape parameter \\(\\kappa\\) indicates heavy tail. differs convention used sources.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"l-moments","dir":"Articles","previous_headings":"Parameter Estimation","what":"L-Moments","title":"","text":"L-moments parameter estimation method implemented distributions S-FFA. method uses sample L-moments (\\(l_1\\), \\(l_2\\)) L-moment ratios (\\(t_3\\), \\(t_4\\)) estimate parameters. information L-moments, see . Warning: L-moment-based estimates can yield distributions support small values. However, typically issue quantile estimation mid- high-return periods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"maximum-likelihood-mle","dir":"Articles","previous_headings":"Parameter Estimation","what":"Maximum Likelihood (MLE)","title":"","text":"MLE implemented distributions across S-FFA NS-FFA. Maximum likelihood estimation aims maximize log-likelihood function \\(\\ell(x : \\theta)\\) data \\(x = x_{1}, \\dots , x_{n}\\) given parameters \\(\\theta\\). log-likelihood functions distribution defined . find optimal parameters, use nlminb function stats library. function implements “L-BFGS-B” algorithm box-constrained optimization.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"generalized-maximum-likelihood-gmle","dir":"Articles","previous_headings":"Parameter Estimation","what":"Generalized Maximum Likelihood (GMLE)","title":"","text":"GMLE used GEV models incorporating prior knowledge2 shape parameter \\(\\kappa\\) using Bayesian reasoning via maximum posteriori estimation, maximizes product likelihood prior distribution. Suppose \\(\\kappa\\) drawn \\(K \\sim \\text{Beta}(p, q)\\) \\(p\\) \\(q\\) determined using prior knowledge. prior PDF \\(f_{K}(\\kappa)\\) shown , \\(B(p, q)\\) Beta function. \\[ f_{K}(\\kappa) = \\frac{\\kappa ^{p - 1}(1 - \\kappa)^{q-1}}{B(p, q)} \\] case regular maximum likelihood estimation, likelihood function : \\[ f_{X}(x : \\mu, \\sigma, \\kappa) =\\prod_{=1}^{n} \\frac{1}{\\sigma}t_{}^{-1 - (1/\\kappa)} \\exp (-t_{}^{-1/\\kappa}), \\quad t_{} = 1 + \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma } \\right) \\] mentioned previously, want maximize product \\(\\mathcal{L} = f_{K}(\\kappa)f_{X}(x:\\mu ,\\sigma ,\\kappa)\\). ensure numerical stability, maximize \\(\\ln  (\\mathcal{L})\\) instead, following form: \\[ \\begin{aligned} \\ln(\\mathcal{L}) &= \\ln(f_{K}(\\kappa)) + \\ln(f_{X}(x:\\mu ,\\sigma ,\\kappa )) \\\\[10pt] \\ln(f_{K}(\\kappa)) &= (p - 1)\\ln \\kappa + (q-1) \\ln (1 - \\kappa)  - \\ln (B(p, q)) \\\\[5pt] \\ln(f_{X}(x:\\mu ,\\sigma ,\\kappa )) &= \\sum_{=1}^{n} \\left[-\\ln \\sigma - \\left(1 + \\frac{1}{\\kappa }\\right) \\ln t_{} - t_{}^{-1/\\kappa}\\right] \\end{aligned} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"candidate-probability-distributions","dir":"Articles","previous_headings":"","what":"Candidate Probability Distributions","title":"","text":"FFA framework considers nine candidate probability distributions: distribution also three nonstationary variants: trend location parameter \\(\\mu\\) (+1 parameter). trend scale parameter \\(\\sigma\\) (+1 parameter). trend location \\(\\mu\\) scale \\(\\sigma\\) (+2 parameters). FFA framework also uses four-parameter Kappa distribution (KAP) Z-statistic selection metric. Kappa distribution generalizes nine distributions listed .","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"gumbel-gum-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Gumbel (GUM) Distribution","title":"","text":"Support \\(-\\infty < x < \\infty\\) Quantiles \\(x(F) = \\mu - \\sigma \\log (-\\log F)\\) Likelihood Function probability density function (PDF) : \\[ f(x_{} : \\mu, \\sigma) = \\frac{1}{\\sigma} \\exp \\left(-z_{} - e^{-z_{}}\\right) , \\quad z_{} = \\frac{x_{} - \\mu}{\\sigma } \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma) = \\sum_{=1}^{n} \\left[-\\ln \\sigma - z_{} - e^{-z_{}} \\right] \\] L-Moments equations , \\(\\gamma \\approx 0.5772\\) Euler’s constant. \\(\\lambda_{1} = \\mu + \\sigma \\gamma\\) \\(\\lambda_{2} = \\sigma \\log 2\\) \\(\\tau_{3} = \\log(9/8)/\\log 2 \\approx 0.1699\\) \\(\\tau_{4} = (16 \\log 2 - 10\\log 3) / \\log 2 \\approx 0.1504\\) can also express parameters terms L-moments: \\(\\sigma = \\lambda_{2} / \\log 2\\) \\(\\mu = \\lambda_{1} - \\sigma \\gamma\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"normal-nor-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Normal (NOR) Distribution","title":"","text":"Support \\(-\\infty < x < \\infty\\) Quantiles \\(x(F) = \\mu  + \\sigma \\Phi^{-1}(F)\\) Likelihood Function probability density function (PDF) : \\[ f(x_{} : \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi }}e^{-z_{}^2/2} , \\quad z_{} = \\frac{x_{} - \\mu}{\\sigma } \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma) = \\sum_{=1}^{n} \\left[-\\ln (\\sigma \\sqrt{2\\pi }) - \\frac{z_{}^2}{2} \\right] \\] L-Moments \\(\\lambda_{1} = \\mu\\) \\(\\lambda_{2} = \\pi^{-1/2}\\sigma \\approx 0.5642\\sigma\\) \\(\\tau_{3} = 0\\) \\(\\tau_{4} = 30\\pi^{-1}\\arctan \\sqrt{2} - 9 \\approx 0.1226\\) can also express parameters terms L-moments: \\(\\mu = \\lambda_{1}\\) \\(\\sigma = \\pi^{1/2}\\lambda_{2}\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"log-normal-lno-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Log-Normal (LNO) Distribution","title":"","text":"Support \\(0 < x < \\infty\\) Quantiles \\(x(F) = \\exp(\\mu + \\sigma \\Phi^{-1}(F))\\) Likelihood Function derive likelihood, use fact : \\[ \\text{Data} \\sim \\text{LNO} \\Leftrightarrow \\ln (\\text{Data}) \\sim \\text{} \\] Precisely, require change variables formula, states : \\[ \\ell_{\\text{LNO}}(x ; \\mu, \\sigma) = \\ell_{\\text{}}(\\ln x ; \\mu , \\sigma) \\left|\\frac{d}{dx} \\ln  x\\right| = \\frac{\\ell_{\\text{}}(\\ln x ; \\mu , \\sigma)}{x} \\] L-Moments See Normal Distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-extreme-value-gev-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Extreme Value (GEV) Distribution","title":"","text":"Support \\[ \\begin{cases} \\mu + (\\sigma /\\kappa) \\leq x < \\infty & \\kappa > 0 \\\\[5pt] -\\infty < x < \\infty & \\kappa  = 0 \\\\[5pt] -\\infty < x \\leq \\mu + (\\sigma/\\kappa ) &\\kappa < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{dcases} \\mu + \\sigma (1 - (-\\log F)^{\\kappa })/\\kappa  &\\kappa \\neq 0\\\\[5pt] \\mu - \\sigma \\log (-\\log F) &\\kappa = 0 \\end{dcases} \\] Likelihood Function probability density function (PDF) (assume \\(t_{} > 0)\\): \\[ f(x_{} : \\mu, \\sigma, \\kappa) = \\frac{1}{\\sigma}t_{}^{-1 - (1/\\kappa)} \\exp (-t_{}^{-1/\\kappa}), \\quad t_{} = 1 + \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma } \\right) \\] Therefore, Log-likelihood : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[-\\ln \\sigma - \\left(1 + \\frac{1}{\\kappa }\\right) \\ln t_{} - t_{}^{-1/\\kappa}\\right] \\] L-Moments L-moments defined \\(\\kappa > -1\\): \\(\\lambda_{1} = \\mu + \\sigma (1 - \\Gamma (1 + \\kappa)) / \\kappa\\) \\(\\lambda_{2} = \\sigma (1 - 2^{-\\kappa })\\Gamma (1 + \\kappa) / \\kappa\\) \\(\\tau_{3} = 2(1 - 3^{-\\kappa})/(1 - 2^{-\\kappa}) - 3\\) \\(\\tau_{4} = [5(1 - 4^{-\\kappa })-10(1-3^{-\\kappa}) + 6(1-2^{-\\kappa })]/(1 - 2^{-\\kappa })\\) compute parameters L-moments, first compute \\(c\\): \\[ c = \\frac{2}{3 + \\tau_{3}} - \\frac{\\log 2}{\\log 3} \\] , use following approximation2: \\[ \\begin{cases} \\kappa \\approx 7.8590c + 2.9554c^2 \\\\[5pt] \\sigma \\approx \\lambda_{2}\\kappa / (1 - 2^{-\\kappa })\\Gamma (1 + \\kappa) \\\\[5pt] \\mu \\approx \\lambda_{1} - \\sigma (1 - \\Gamma (1 + \\kappa )) / \\kappa \\end{cases} \\] Note: sources often use different notation GEV distribution sign shape parameter \\(\\kappa\\) flipped.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-logistic-glo-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Logistic (GLO) Distribution","title":"","text":"Support \\[ \\begin{cases} -\\infty < x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa  > 0 \\\\[5pt] -\\infty  < x < \\infty  & \\kappa  = 0 \\\\[5pt] \\mu  + (\\sigma /\\kappa ) \\leq  x < \\infty  & \\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu +\\sigma [1 - ((1 - F) / F)^{\\kappa}] / \\kappa &\\kappa \\neq 0 \\\\[5pt] \\mu - \\sigma \\log ((1 - F) / F) & k = 0 \\end{cases} \\] Likelihood Function probability density function (PDF) (assume \\(t_{} > 0)\\): \\[ f(x_{} : \\mu , \\sigma , \\kappa ) = \\frac{1}{\\sigma }t_{}^{(1/\\kappa) - 1} \\left[1 + t_{}^{1/\\kappa}\\right]^{-2}, \\quad t_{} = 1 - \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma }\\right) \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[-\\ln \\sigma + \\left(\\frac{1}{\\kappa }-1\\right) \\ln t_{} - 2 \\ln \\left(1 + t_{}^{1/\\kappa }\\right) \\right] \\] L-Moments L-moments defined \\(-1 < \\kappa < 1\\): \\(\\lambda_{1} = \\mu +\\sigma [(1 / \\kappa) - (\\pi / \\sin (\\kappa\\pi))]\\) \\(\\lambda_{2} = \\sigma \\kappa \\pi / \\sin (\\kappa \\pi)\\) \\(\\tau_{3} = -\\kappa\\) \\(\\tau_{4} = (1 + 5\\kappa ^2) / 6\\) can also express parameters terms L-moments: \\(\\kappa = -\\tau_{3}\\) \\(\\sigma = \\lambda_{2}\\sin (\\kappa \\pi ) / \\kappa \\pi\\) \\(\\mu = \\lambda_{1} - \\sigma [(1 / \\kappa) - (\\pi / \\sin (\\kappa\\pi))]\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-normal-gno-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Normal (GNO) Distribution","title":"","text":"Support \\[ \\begin{cases} -\\infty < x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa  > 0 \\\\[5pt] -\\infty  < x < \\infty  & \\kappa  = 0 \\\\[5pt] \\mu  + (\\sigma /\\kappa ) \\leq  x < \\infty  & \\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu + \\sigma [1 - \\exp(-\\kappa \\Phi^{-1}(F))] / \\kappa &\\kappa \\neq 0 \\\\[5pt] \\mu + \\sigma \\Phi^{-1}(F) &\\kappa  = 0 \\end{cases} \\] Likelihood Function L-Moments L-moments defined values \\(\\kappa\\). \\(\\lambda_{1} = \\mu + \\sigma (1 - e^{\\kappa ^2/2}) / \\kappa\\) \\(\\lambda_{2} = \\sigma e^{-\\kappa ^2/ 2}[1 - 2\\Phi (-\\kappa  / \\sqrt{2})] / \\kappa\\) compute \\(\\tau_{3}\\) \\(\\tau_{4}\\) use following approximation: \\[ \\begin{aligned} \\tau_{3} &\\approx -\\kappa \\left(\\frac{A_{0} + A_{1}\\kappa ^2 + A_{2}\\kappa ^{4} + A_{3}\\kappa ^{6}}{1 + B_{1}\\kappa ^2 + B_{2}\\kappa ^{4} + B_{3}\\kappa ^{6}}\\right)  \\\\[5pt] \\tau_{4} &\\approx \\tau_{4}^{0} + \\kappa ^2 \\left(\\frac{C_{0} + C_{1}\\kappa ^2 + C_{2}\\kappa ^{4} + C_{3}\\kappa ^{6}}{1 + D_{1}\\kappa ^2 + D_{2}\\kappa ^{4} + D_{3}\\kappa ^{6}}\\right) \\end{aligned} \\] determine parameters L-moments also use rational approximation: \\[ \\kappa \\approx -\\tau_{3} \\left(\\frac{E_{0} + E_{1}\\tau_{3}^2 + E_{2}\\tau_{3}^{4} + E_{3}\\tau _{3}^{6}}{1 + F_{1}\\tau _{3}^2 + F_{2}\\tau _{3}^{4} + F_{3}\\tau _{3}^{6}}\\right) \\] , can find \\(\\mu\\) \\(\\sigma\\) function \\(\\kappa\\): \\[ \\sigma \\approx  \\frac{\\lambda_{2}\\kappa e^{-\\kappa ^2 / 2}}{1 - 2\\Phi (-\\kappa  / \\sqrt{2})}, \\quad \\mu  \\approx  \\lambda_{1} - \\frac{\\sigma }{\\kappa }\\left(1 - e^{-\\kappa ^2 / 2 }\\right) \\] coefficients (\\(A_{}\\), \\(B_{}\\), \\(C_{}\\), \\(D_{}\\), \\(E_{}\\), \\(F_{}\\), \\(\\tau_{4}^{0}\\)) defined Appendix .8 Hosking, 19973. Although appendix covers 3-parameter log-normal distribution, L-moments generalized normal distribution .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"pearson-type-iii-pe3-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Pearson Type III (PE3) Distribution","title":"","text":"Pearson Type III distribution typically reparameterized follows \\(\\kappa \\neq 0\\): \\[ \\begin{aligned} \\alpha &= 4 / \\kappa^2 \\\\[5pt] \\beta  &= \\sigma |\\kappa | / 2 \\\\[5pt] \\xi &= \\mu  - 2\\sigma /\\kappa \\end{aligned} \\] Support \\[ \\begin{cases} \\xi \\leq  x < \\infty &\\kappa > 0 \\\\[5pt] -\\infty < x < \\infty  &\\kappa =0 \\\\[5pt] -\\infty  < x \\leq \\xi &\\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu - \\alpha \\beta + q(F, \\alpha, \\beta) &\\kappa > 0\\\\[5pt] \\mu + \\sigma \\Phi^{-1}(F) &\\kappa  = 0\\\\[5pt] \\mu  + \\alpha \\beta  - q(1 - F, \\alpha, \\beta) &\\kappa < 0 \\end{cases} \\] equations , \\(q\\) quantile function Gamma distribution shape \\(\\alpha\\) scale \\(\\beta\\). \\(q\\) defined , \\(\\gamma\\) lower incomplete Gamma function. \\[q(F, \\alpha, \\beta) = \\beta \\gamma ^{-1}(\\alpha, p \\Gamma (\\alpha))\\] Likelihood Function probability density function (PDF) PE3 distribution given : \\[ f(x_{} : \\mu , \\sigma , \\kappa ) = \\frac{(x_{} - \\xi)^{\\alpha  - 1}e^{-(x_{} - \\xi )/\\beta }}{\\beta ^{\\alpha } \\Gamma (\\alpha )} \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[(\\alpha  - 1) \\ln |x_{} - \\xi | - \\frac{|x_{} - \\xi  |}{\\beta } - \\alpha \\ln\\beta  - \\ln \\Gamma (\\alpha )\\right] \\] L-Moments subsequent definitions assume \\(\\kappa > 0\\). \\(\\kappa < 0\\), L-moments can obtained changing signs \\(\\lambda_{1}\\), \\(\\tau_{3}\\), \\(\\xi\\) whenever appear. \\(\\kappa = 0\\), L-moments Normal Distribution. first two L-moments defined follows: \\(\\lambda_{1} = \\xi + \\alpha \\beta\\) \\(\\lambda_{2} = \\pi ^{-1/2} \\beta \\Gamma (\\alpha  + 0.5) / \\Gamma (\\alpha )\\) Rational approximation necessary determine \\(\\tau_{3}\\) \\(\\tau_{4}\\). \\(\\alpha \\geq 1\\): \\[ \\begin{aligned} \\tau_{3} &\\approx \\alpha^{-1/2} \\left(\\frac{A_{0} + A_{1}\\alpha^{-1} + A_{2}\\alpha^{-2} + A_{3}\\alpha^{-3}}{1 + B_{1}\\alpha^{-1} + B_{2}\\alpha ^{-2}}\\right)  \\\\[5pt] \\tau_{4} &\\approx \\frac{C_{0} + C_{1}\\alpha^{-1} + C_{2}\\alpha ^{-2} +C_{3}\\alpha ^{-3}}{1 + D_{1}\\alpha ^{-1} + D_{2}\\alpha ^{-2}} \\end{aligned} \\] \\(\\alpha < 1\\), use different set coefficients: \\[ \\begin{aligned} \\tau_{3} &\\approx \\frac{1 + E_{1}\\alpha  + E_{2}\\alpha ^2 + E_{3}\\alpha ^3}{1 + F_{1}\\alpha  + F_{2}\\alpha ^2 + F_{3}\\alpha ^3} \\\\[5pt] \\tau_{4} &\\approx \\frac{1 + G_{1}\\alpha + G_{2}\\alpha ^2 + G_{3}\\alpha ^3}{1 + H_{1}\\alpha + H_{2}\\alpha ^2 + H_{3}\\alpha ^3} \\end{aligned} \\] Coefficients given Appendix .9 Hosking, 19974. estimate parameters L-moments, use one two approximations \\(\\alpha\\) depending value \\(\\tau_{3}\\): \\[ \\alpha \\approx \\begin{dcases} \\frac{1 + 0.2906z}{z + 0.1882z^2 + 0.0442z^3}, &z = 3\\pi \\tau_{3}^2, &0 < |\\tau_{3}| < \\frac{1}{3} \\\\[5pt] \\frac{0.36067z - 0.59567z^2 + 0.25361z^3}{1 - 2.78861z + 2.56096z^2 - 0.77045z^3}, &z = 1 - |\\tau_{3}|, &\\frac{1}{3} \\leq |\\tau_{3}| < 1 \\end{dcases} \\] , can determine parameters approximated \\(\\alpha\\): \\[ \\begin{aligned} \\kappa &= 2\\alpha ^{-1/2} \\text{sign} (\\tau_{3}) \\\\[5pt] \\sigma &= \\lambda_{2} \\pi^{1/2}\\alpha ^{1/2} \\Gamma (\\alpha )/\\Gamma (\\alpha + 0.5)\\\\[5pt] \\mu &= \\lambda_{1 } \\end{aligned} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"log-pearson-type-iii-lp3-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Log-Pearson Type III (LP3) Distribution","title":"","text":"LP3 distribution uses reparameterization PE3 distribution. Support \\[ \\begin{cases} \\max(0, \\xi) \\leq  x < \\infty &\\kappa > 0 \\\\[5pt] 0 < x < \\infty  &\\kappa =0 \\\\[5pt] 0  < x \\leq \\max(0, \\xi) &\\kappa  < 0 \\end{cases} \\] Quantiles \\(x(F) = \\exp(x_{\\text{PE3}}(F ))\\), \\(x_{\\text{PE3}}(F)\\) quantile function PE3 distribution. Likelihood Function derive likelihood LP3 distribution, use fact : \\[ \\text{Data} \\sim \\text{LP3}  \\Leftrightarrow \\ln (\\text{Data}) \\sim \\text{PE3} \\] Precisely, require change variables formula, states : \\[ \\ell_{\\text{LP3}}(x ; \\mu, \\sigma, \\kappa) = \\ell_{\\text{PE3}}(\\ln x ; \\mu , \\sigma, \\kappa ) \\left|\\frac{d}{dx} \\ln  x\\right| = \\frac{\\ell_{\\text{PE3}}(\\ln x ; \\mu , \\sigma, \\kappa )}{x} \\] L-Moments PE3 distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"weibull-wei-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Weibull (WEI) Distribution","title":"","text":"Weibull distribution implemented reparameterized version generalized extreme value distribution: \\[ \\begin{aligned} \\kappa &= 1 / \\kappa_{\\text{GEV}} \\\\[5pt] \\sigma &= \\kappa \\sigma_{\\text{GEV} } \\\\[5pt] \\mu &= \\sigma + \\mu_{\\text{GEV} } \\end{aligned} \\] reparameterization, required \\(\\sigma > 0\\) \\(\\kappa > 0\\). Support \\(\\mu \\leq x < \\infty\\) Quantiles \\(x(F) = \\mu + \\sigma (-\\log (1 - F))^{1/\\kappa}\\) Likelihood Function probability density function (PDF) given \\(x_{} > \\mu\\): \\[ f(x_{} : \\mu, \\sigma, \\kappa) = \\frac{\\kappa}{\\sigma }\\left(\\frac{x_{} - \\mu}{\\sigma }\\right)^{\\kappa -1} \\exp \\left( - \\left(\\frac{x_{} - \\mu}{\\sigma }\\right)^{\\kappa } \\right) \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[\\ln \\kappa - \\kappa \\ln \\sigma +(\\kappa -1)\\ln (x_{}-\\mu ) - \\left(\\frac{x_{} - \\mu }{\\sigma }\\right) ^{\\kappa } \\right] \\] L-Moments First, reparameterize Weibull distribution recover GEV parameters: \\[ \\begin{aligned} \\kappa_{\\text{GEV}} &= 1 / \\kappa \\\\[5pt] \\sigma_{\\text{GEV}} &= \\sigma / \\kappa \\\\[5pt] \\end{aligned} \\] Next, compute L-moments GEV distribution \\(\\mu_{\\text{GEV}} = 0\\). , \\(\\lambda_{1} = \\mu + \\sigma - \\lambda_{1, \\text{GEV}}\\) \\(\\lambda_{2} = \\lambda_{2, \\text{GEV}}\\) \\(\\tau_{3} = -\\tau_{3, \\text{GEV}}\\) \\(\\tau_{4} = \\tau_{4, \\text{GEV} }\\) compute parameters L-moments, first flip sign \\(\\lambda_{1}\\) \\(\\tau_{3}\\). , estimate parameters GEV distribution get \\(\\hat{\\mu}_{\\text{GEV}}\\), \\(\\hat{\\sigma}_{\\text{GEV}}\\), \\(\\hat{\\kappa}_{\\text{GEV}}\\). Finally, reparameterize GEV parameters shown flip sign \\(\\mu\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"kappa-kap-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Kappa (KAP) Distribution","title":"","text":"Kappa distribution location \\(\\mu\\), scale \\(\\sigma\\), two shape parameters \\(\\kappa\\) \\(h\\). Support \\[ \\begin{cases} \\mu + \\sigma (1 - h^{-\\kappa}) \\leq x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa > 0, h > 0 \\\\[5pt] -\\infty < x \\leq \\mu + (\\sigma /\\kappa) & \\kappa > 0, h \\leq 0 \\\\[5pt] \\mu + \\sigma (1 - h^{-\\kappa}) \\leq x < \\infty &\\kappa \\leq 0, h > 0 \\\\[5pt] \\mu + (\\sigma / \\kappa ) \\leq x <\\infty &\\kappa  \\leq 0, h \\leq 0 \\end{cases} \\] Quantiles \\[ x(F) = \\mu + \\frac{\\sigma }{\\kappa }\\left[1 - \\left(\\frac{1 - F^{h}}{h}\\right)^{\\kappa }\\right] \\] L-Moments L-moments defined \\(h \\geq 0\\) \\(k > -1\\) \\(h < 0\\) \\(-1 < k < -1/h\\). \\(\\lambda_{1} = \\mu  + \\sigma (1 - g_{1})/\\kappa\\) \\(\\lambda_{2} = \\sigma(g_{1} - g_{2})/\\kappa\\) \\(\\tau_{3} = (-g_{1} + 3g_{2} - 2g_{3}) / (g_{1} - g_{2})\\) \\(\\tau_{4} = (-g_{1} + 6g_{2} - 10g_{3} + 5g_{4}) / (g_{1} - g_{2})\\) expression , \\(g_{r}\\) defined follows: \\[ g_{r} = \\begin{dcases} \\frac{r\\Gamma (1 + \\kappa )\\Gamma (r / h)}{h^{1 + \\kappa }\\Gamma (1 + \\kappa + r/h)} &h > 0 \\\\[5pt] \\frac{r\\Gamma (1 + \\kappa ) \\Gamma (-\\kappa  - r/h)}{(-h)^{1 + \\kappa }\\Gamma (1 - r/h)} &h < 0 \\end{dcases} \\] closed-form solution parameters terms L-moments. However, \\(\\tau_{3}\\) \\(\\tau_{4}\\) can computed terms \\(\\kappa\\) \\(h\\) using Newton-Raphson iteration.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"","text":"FFA framework implements three methods uncertainty quantification: Parametric bootstrap Regula-falsi profile likelihood (RFPL) Regula-falsi generalized profile likelihood (RFGPL)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"parametric-bootstrap","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Parametric Bootstrap","title":"","text":"parametric bootstrap flexible method uncertainty quantification works probability models parameter estimation methods. Let \\(n\\) size original dataset. Draw \\(N_{\\text{sim}}\\) bootstrap samples size \\(n\\) selected probability distribution. Fit probability distribution bootstrap sample using model selection method parameter estimation method used generate original distribution. Compute quantiles bootstrapped distributions. Generate confidence intervals using mean variance bootstrapped quantiles. Warning: parametric bootstrap known give unreasonably wide confidence intervals small datasets. FFA framework detects confidence interval 5+ times wider return levels , return error recommend RFPL uncertainty quantification1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"regula-falsi-profile-likelihood-rfpl","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Regula-Falsi Profile Likelihood (RFPL)","title":"","text":"Consider statistical model parameters \\((\\theta, \\psi_{1}, \\dots, \\psi_{n})\\). Profile Likelihood scalar parameter \\(\\theta\\) vector nuisance parameters \\(\\psi\\) defined : \\[ \\ell_{p}(\\theta) = \\max_{\\psi } \\ell(\\theta , \\psi) \\] Let \\(\\hat{\\theta}\\) MLE \\(\\theta\\). find confidence interval significance \\(1-\\alpha\\), find two solutions following equation (\\(\\chi_{1;1-\\alpha}^2\\) \\(1-\\alpha\\) quantile Chi-squared distribution): \\[ 2[\\ell_{p}(\\hat{\\theta }) - \\ell_{p}(\\theta )] = \\chi_{1;1-\\alpha }^2 \\] equivalent finding two points \\(\\theta_{L} < \\hat{\\theta} < \\theta_{U}\\) profile log-likelihood dropped \\(\\chi _{1;1-\\alpha }^2 / 2\\). find \\(\\theta_{L}\\) \\(\\theta_{U}\\) find roots \\(f(\\theta)\\) using secant-based algorithm. \\[ f(\\theta) = \\ell_{p}(\\theta) - \\left[\\ell_{p}(\\hat{\\theta}) - \\frac{\\chi_{1;1-\\alpha }^2}{2}\\right] \\] FFA framework, compute profile likelihood quantile \\(y\\) reparameterizing location parameter \\(\\mu\\). Let \\(q(p, \\mu, \\psi)\\) function takes exceedance probability \\(p\\), location parameter \\(\\mu\\) nuisance parameters \\(\\psi\\) returns quantile \\(y\\). quantile functions satisfy: \\[ y = q(p, \\mu, \\psi) = \\mu + q(p, 0, \\psi) \\] Therefore, can define \\(\\mu\\) function \\((p, y, \\psi)\\) shown : \\[ \\mu = y - q(p, 0, \\psi) \\] use relationship find profile likelihood \\(\\ell_{p}(y)\\) evaluating \\(\\mu(p, y, \\psi)\\) substituting log-likelihood functions listed . Warning: RFPL uncertainty quantification can numerically unstable datasets. FFA framework encounters issue, return error recommend parametric bootstrap2.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"handling-the-weibull-distribution","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Handling the Weibull Distribution","title":"","text":"Due support issues, use different reparameterization Weibull distribution: \\[ \\begin{aligned} &y = (\\mu_{0} + \\mu_{1}t) + (\\sigma_{0} + \\sigma_{1}t)(-\\log (1 - p))^{1/\\kappa}  \\\\[5pt] \\Rightarrow\\,&(\\sigma_{0} + \\sigma_{1}t) = \\frac{y - (\\mu_{0} + \\mu_{1}t)}{(-\\log (1 - p))^{1/\\kappa}} \\\\[5pt] \\Rightarrow\\,&\\sigma_{0} = \\frac{y - (\\mu_{0} + \\mu_{1}t)}{(-\\log (1 - p))^{1 / \\kappa }} - \\sigma_{1}t \\end{aligned} \\] derivation uses Weibull distribution trend mean variability. However, reparameterizations nonstationary structures can obtained easily setting \\(\\sigma_{1} = 0\\) /\\(\\mu_{1} = 0\\). solving \\(\\sigma_{0}\\) terms parameters, can use standard log-likelihood function.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"initialization-algorithm","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Initialization Algorithm","title":"","text":"can find roots \\(f\\), need identify initial values regula-falsi algorithm: Let \\(a_{0}\\) number \\(a_{0} < y\\) \\(f(a_{0}) < 0\\). Let \\(b_{0}\\) number \\(b_{0} > y\\) \\(f(b_{0}) < 0\\). find \\(a_{0}\\), start computing \\(f(^{*})\\) \\(^{*} = 0.95y\\). \\(f(^{*}) < 0\\), assign \\(a_{0} = ^{*}\\). Otherwise, update \\(^{*}\\) \\(0.95a^{*}\\) \\(f(^{*}) < 0\\). find \\(b_{0}\\), use similar process. However, instead iteratively revising \\(b^{*}\\) , revise \\(1.05b^{*}\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"iteration-algorithm","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Iteration Algorithm","title":"","text":"iteration \\(\\), compute following: \\[ c_{} = \\frac{a_{-1}f(b_{-1}) - b_{-1}f(a_{-1})}{f(b_{-1}) - f(a_{-1})} \\] Evaluate \\(\\ell_{p}(c_{})\\) maximizing nuisance parameters \\(\\psi\\), find \\(f(c_{})\\). \\(|f(c_{})| < \\epsilon\\) (\\(\\epsilon\\) small), stop. \\(c_{}\\) confidence interval bound. Otherwise, assign \\(a_{} = c_{}\\) \\(f(c_{}) < 0\\) \\(b_{} = c_{}\\) \\(f(c_{}) > 0\\) continue iteration \\(+ 1\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"regula-falsi-generalized-profile-likelihood-rfgpl","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Regula-Falsi Generalized Profile Likelihood (RFGPL)","title":"","text":"regula-falsi generalized profile likelihood (RFGPL) method performs regula-falsi algorithm shown GEV distributions \\(\\text{Beta}(p, q)\\) prior shape parameter \\(\\kappa\\). information generalized parameter estimation, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Handling Nonstationarity","title":"","text":"selected probability distribution nonstationary, quantiles (hence confidence intervals) bootstrapped distributions change time. See detailed discussion idea. default, FFA framework anchors uncertainty analysis last year dataset. However, model assessment requires confidence intervals every year dataset. Note: parametric bootstrap algorithm fastest algorithm computing confidence intervals years dataset probabilities used generate bootstrapped samples can reused. RFPL RFGPL algorithms far slower, since must run separately timestamp.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"changes-from-matlab-version","dir":"Articles","previous_headings":"","what":"Changes from MATLAB Version","title":"MATLAB Version","text":"page documents changes original MATLAB code.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"bug-fixes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Exploratory Data Analysis (EDA)","what":"Bug Fixes","title":"MATLAB Version","text":"show statistically significant change points Pettitt MKS plots. Fix bug causing MKS test identify one change point, even multiple change points found threshold statistical significance. Fix major bug causing MKS test identify change points based progressive series instead z-statistics crossing points. Remove unnecessary rounding moving window algorithm estimating variability. Re-implement Phillips-Perron KPSS tests account drift trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"framework-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Exploratory Data Analysis (EDA)","what":"Framework Changes","title":"MATLAB Version","text":"serial correlation identified, run Phillips-Perron KPSS tests. Add Runs test detect nonlinearity fitting Sen’s trend estimator. Run change point detection multiple stages prevent overpartitioning.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"distribution-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Distribution Changes","title":"MATLAB Version","text":"generalized Pareto (GPA) distribution removed, since likelihood function amenable maximum likelihood estimation. Issues occur GPA distribution intended peaks threshold modelling, use. R version uses three parameter Weibull distribution (location, scale, shape) parameters instead two parameter Weibull distribution (scale shape parameters). ensures consistency distributions, location parameters.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"model-selection-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Model Selection Changes","title":"MATLAB Version","text":"L-distance L-kurtosis selection methods improved using optimization algorithm find parameters closest L-moments data instead using brute force approach. computationally efficient gives precise results. procedure computing Z-statistic selection metric changed. L-moments dataset satisfy \\(\\tau_{4} \\leq (1 + 5\\tau _{3}^2)/6\\), Kappa distribution fitted candidate distributions use dataset omitted.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"parameter-estimation-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Parameter Estimation Changes","title":"MATLAB Version","text":"Parameterization PE3/LP3 distributions fails datasets MATLAB unable handle large numbers created gamma function. manage issue, MATLAB version used conventional moments (.e. sample mean/variance/skewness) occurred. avoid problem R version using lgamma (log-gamma) function. R implementation uses L-BFGS-B MLE/GMLE parameter estimation instead Nelder-Mead, since gradient well defined likelihood functions working . Additionally, L-BFGS-B method makes possible assign bounds variables. modification produced slight improvements MLL/GMLL datasets.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Uncertainty Quantification","title":"MATLAB Version","text":"Implement RFPL uncertainty quantification Weibull distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"model-assessment-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Model Assessment Changes","title":"MATLAB Version","text":"Use built-R function approx() perform log-linear interpolation return periods. MATLAB implementation uses hard-coded algorithm behaves unpredictably original interpolated \\(x\\)-values equal.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Nonstationary FFA","text":"vignette explore data Bow River Banff (05BB001), station Reference Hydrometric Basin Network. station unregulated, suggests trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"the-structure-list","dir":"Articles","previous_headings":"Case Study","what":"The structure List","title":"Nonstationary FFA","text":"vignette assumes scenario trend mean identified. specify trend distribution parameter, create structure list containing boolean items location scale. Setting items TRUE specifies trend location/scale parameter respectively. Note: guidance trend detection, refer Trend Identification vignette.","code":"structure <- list(location = TRUE, scale = FALSE)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"distribution-selection","dir":"Articles","previous_headings":"","what":"Distribution Selection","title":"Nonstationary FFA","text":"L-moment-based distribution selection remains applicable nonstationarity, requires dataset decomposition (detrending) prior analysis. accomplished using data_decomposition function, takes annual maximum series (AMS), corresponding vector years, structure object. decomposed vector data passed selection function (select_ldistance case).  Conclusion: generalized normal (GNO) distribution best-fit distribution sample.","code":"data_decomposed <- data_decomposition(df$max, df$year, structure)  selection <- select_ldistance(data_decomposed)  print(selection$recommendation) #> [1] \"GNO\"  plot_lmom_diagram(selection)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"Nonstationary FFA","text":"L-moments parameter estimation requires stationarity, use maximum likelihood estimation nonstationary model. fit_maximum_likelihood function implements maximum likelihood estimation stationary nonstationary distributions. two required arguments: data: annual maximum series observations. model: three-letter code corresponding probability distribution (ex. \"GNO\"). Since nonstationary model used, two additional arguments required: years: corresponding vector years observations data. structure: nonstationary structure object described . Note: fitted parameters : \\((\\mu_0, \\mu_1, \\sigma, \\kappa)\\), time-dependent location modeled \\(\\mu(t) = \\mu_0 + \\mu_1 t\\). covariate \\(t\\) linear function years: \\((\\text{years} - 1900) / 100\\).","code":"fit <- fit_maximum_likelihood(     df$max,     \"GNO\",     years = df$year,     structure = structure )  print(fit$params) #> [1] 224.0496619 -35.5153685  54.6324886  -0.3689085  print(fit$mll) #> [1] -590.7329"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"Nonstationary FFA","text":"Uncertainty quantification also essential nonstationary probability distributions. addition parametric bootstrap, framework implements regula-falsi profile likelihood (RFPL) method MLE. uncertainty_rfpl method two required arguments: data: annual maximum series observations. model: three-letter code corresponding probability distribution (ex. \"GNO\"). Since model nonstationary structure, three additional arguments required: years: corresponding vector years observations data. structure: nonstationary structure object described . slices: years return levels computed.  Example Conclusion: 2025, \\(1/20\\) exceedance probability flood approximately \\(300\\text{m}^3/\\text{s}\\) greater. estimated return levels decreased approximately \\(50\\text{m}^3/\\text{s}\\) 1925 2025. Note: nonstationarity, return period reflects probability distribution fixed year rather long-run average. clarify difference stationary FFA, phrase “effective return period” used.","code":"uncertainty <- uncertainty_rfpl(     df$max,     \"GNO\",     years = df$year,     structure = structure,     slices = c(1925, 2025) )  plot_nsffa(uncertainty)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Stationary FFA","text":"vignette explore data Athabasca River Athabasca (07BE001), unregulated hydrological monitoring station. statistical analysis data station reveal evidence trends mean variability data. Data station provided CAN-07BE001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-07BE001.csv\") head(df) #>   year  max #> 1 1913 1670 #> 2 1914 3090 #> 3 1915 2760 #> 4 1916 2080 #> 5 1917 2490 #> 6 1918 1470  plot_ams_data(df$max, df$year, title = \"Athabasca River at Athabasca (07BE001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"distribution-selection","dir":"Articles","previous_headings":"","what":"Distribution Selection","title":"Stationary FFA","text":"First, suitable probability distribution data selected using L-moments. select_ldistance chooses distribution theoretical L-skewness (\\(\\tau_3\\)) L-kurtosis (\\(\\tau_4\\)) closest sample, based Euclidean distance. select_lkurtosis selects distribution smallest difference sample theoretical L-kurtosis (three-parameter distributions ). select_zstatistic uses fitted 4-parameter Kappa distribution estimate sampling distribution L-kurtosis selects distribution smallest z-statistic.  Recommendation: Use generalized extreme value (GEV) distribution. Note: information distributions, see selection$metrics item. can find information probability distributions supported framework .","code":"selection <- select_ldistance(df$max)  print(selection$recommendation) #> [1] \"GEV\"  plot_lmom_diagram(selection)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"Stationary FFA","text":"ffaframework package provides three methods parameter estimation. See information. fit_lmom_*: L-moments parameter estimation distribution. fit_maximum_likelihood: Maximum likelihood generalized maximum likelihood. Conclusion: GEV distribution location = 1600, scale = 616, shape = 0.12 used.","code":"params <- fit_lmom_gev(df$max)$params  print(params) #> [1] 1600.219872  616.666030    0.120747"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"Stationary FFA","text":"probability distribution fitted, return levels (design events) can readily estimated. However, point estimates alone can misleading –informative report confidence intervals reflect estimation uncertainty. uncertainty_bootstrap function performs uncertainty quantification using parametric bootstrap method. requires three arguments: data: vector annual maximum series data. model: three-letter code probability distribution (ex. \"GEV\"). method: parameter estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". default, return levels computed 2-, 5-, 10-, 20-, 50-, 100- year return periods.  Example Conclusion: Every 10 years, can expect flood roughly \\(3{\\small,}200\\text{m}^3/\\text{s}\\) greater.","code":"uncertainty <- uncertainty_bootstrap(df$max, \"GEV\", \"L-moments\")  plot_sffa(uncertainty)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"model-assessment","dir":"Articles","previous_headings":"","what":"Model Assessment","title":"Stationary FFA","text":"Model performance assessed using model_diagnostics, reports collection assessment statistics flood frequency analysis. plot_model_diagnostics compares empirical plotting positions (“Observed Quantiles”) predictions parametric model (“Model Quantiles”). black line represents perfect 1:1 correspondence model data.  Conclusion: parametric model generally matches plotting positions. small positive bias \\(3{\\small,}500\\text{m}^3/\\text{s}\\) \\(5{\\small,}000\\text{m}^3/\\text{s}\\).","code":"diagnostics <- model_diagnostics(df$max, \"GEV\", params, uncertainty)  plot_model_diagnostics(diagnostics)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"list-of-tests","dir":"Articles","previous_headings":"","what":"List of Tests","title":"Trend Identification (Mean)","text":"Mean Trend Tests Stationarity Tests Variability Trend Tests Trend Estimation (Mean & Variability)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Trend Identification (Mean)","text":"vignette explore data Bow River Banff (05BB001) hydrological monitoring station. remoteness station means trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"mann-kendall-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Mann-Kendall Test","title":"Trend Identification (Mean)","text":"Mann-Kendall test non-parametric test used detect monotonic trends time series. null hypothesis, trend. Pass vector annual maximum series (AMS) data eda_mk_test() perform Mann-Kendall test. Conclusion: p-value \\(0.0067\\), reject null hypothesis. statistical evidence trend mean.","code":"mk_test <- eda_mk_test(df$max)  print(mk_test$p_value) #> [1] 0.006773098"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"spearman-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Spearman Test","title":"Trend Identification (Mean)","text":"Spearman test used check serial correlation, can cause Mann-Kendall test identify spurious trend. smallest lag serial correlation statistically significant known “least lag”.  Conclusion: least lag 1 provides evidence serial correlation.","code":"spearman_test <- eda_spearman_test(df$max)  print(spearman_test$least_lag) #> [1] 1  plot_spearman_test(spearman_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"further-tests","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Further Tests","title":"Trend Identification (Mean)","text":"Spearman test identified serial correlation, use BBMK test (eda_bbmk_test) check monotonic trend serial correlation. BBMK test uses reshuffling procedure remove serial correlation data. Phillips-Perron (eda_pp_test) KPSS (eda_kpss_test) tests used check unit root (stochastic trend) data. unit root extreme type serial correlation creates unpredictable variation data. Since find evidence serial correlation Spearman test, necessary apply tests. Phillips-Perron KPSS tests opposite hypotheses: Phillips-Perron assumes presence unit root null hypothesis, KPSS test .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Sen’s Trend Estimator","title":"Trend Identification (Mean)","text":"Mann-Kendall identified significant monotonic trend, estimate slope intercept. can estimate monotonic trend using Sen’s trend estimator, uses non-parametric approach robust outliers. eda_sens_trend() takes two arguments: annual maximum series corresponding vector years. , plot_sens_trend() can used generate plot results. requires AMS data corresponding vector years. also takes optional trend mean (mean_trend), trend variability (variability_trend).  Note: covariate computed using formula \\((\\text{years} - 1900) / 100\\).","code":"mean_trend <- eda_sens_trend(df$max, df$year)  plot_sens_trend(df$max, df$year, mean_trend = mean_trend)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"runs-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Runs Test","title":"Trend Identification (Mean)","text":"previous statistical tests assumed nonstationarity linear. runs test assess feasibility linearity assumption checking residuals randomness. residuals random (null hypothesis), evidence underlying trend linear. eda_runs_test() function takes output eda_sens_trend() argument.  Conclusion: p-value \\(0.682\\), evidence linear trend suitable data.","code":"runs_test <- eda_runs_test(mean_trend)  print(runs_test$p_value) #> [1] 0.4392721  plot_runs_test(runs_test, \"Runs Test (AMS Mean)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Trend Identification (Mean)","text":"Mann-Kendall test identified evidence nonstationarity mean AMS. Spearman test find evidence serial correlation, validating results Mann-Kendall test. runs test found linear model suitable nonstationarity. Flood frequency analysis dataset requires time-dependent probability model. Recommendation: Use NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"list-of-tests","dir":"Articles","previous_headings":"","what":"List of Tests","title":"Trend Identification (Variability)","text":"Mean Trend Tests Stationarity Tests Variability Trend Tests Trend Estimation (Mean & Variability)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Trend Identification (Variability)","text":"vignette explore data Mission Creek near East Kelowna (08NM116) hydrological monitoring station. remoteness station means trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-08NM116.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-08NM116.csv\") head(df) #>   year  max #> 1 1949 49.3 #> 2 1950 52.1 #> 3 1951 49.3 #> 4 1952 50.7 #> 5 1953 62.3 #> 6 1954 36.2  plot_ams_data(df$max, df$year, title = \"Mission Creek near East Kelowna (08NM116)\")"},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"mwmk-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"MWMK Test","title":"Trend Identification (Variability)","text":"MWMK test used detect trends variability time series. First, moving-window algorithm used estimate variability AMS data. , Mann-Kendall test applied series standard deviations check trend. data_mw_variability estimates moving-window standard deviations eda_mk_test function performs Mann-Kendall test. Conclusion: p-value 0.016, reject null hypothesis. evidence linear trend variability data.","code":"mw <- data_mw_variability(df$max, df$year) mwmk_test <- eda_mk_test(mw$std) print(mwmk_test$p_value) #> [1] 0.01600616"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"white-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"White Test","title":"Trend Identification (Variability)","text":"White test checks heteroskedasticity, general time-dependence variability. null hypothesis homoskedasticity, constant variability data. Conclusion: p-value 0.0012, reject null hypothesis. statistical evidence heteroskedasticity.","code":"white_test <- eda_white_test(df$max, df$year) print(white_test$p_value) #> [1] 0.00125362"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"Sen’s Trend Estimator","title":"Trend Identification (Variability)","text":"previous tests provide evidence monotonic trend variability, estimate slope intercept trend. can estimate monotonic trend using Sen’s trend estimator, uses nonparametric approach robust outliers. eda_sens_trend() takes two arguments: data (either annual maximum series vector standard deviations) corresponding vector years. , plot_sens_trend() can used generate plot results. requires AMS data corresponding vector years. also takes optional trend mean (mean_trend), trend variability (variability_trend).  Note: covariate computed using formula \\((\\text{years} - 1900) / 100\\).","code":"variability_trend <- eda_sens_trend(mw$std, mw$year)  plot_sens_trend(df$max, df$year, variability_trend = variability_trend)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"runs-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"Runs Test","title":"Trend Identification (Variability)","text":"Sen’s trend estimator assumed nonstationarity linear. runs test assess feasibility linearity assumption checking residuals randomness. residuals random (null hypothesis), evidence underlying trend linear. eda_runs_test() function takes output eda_sens_trend() argument.  Conclusion: p-value \\(0.266\\), fail reject null hypothesis. evidence residuals random linear trend suitable data.","code":"runs_test <- eda_runs_test(variability_trend)  print(runs_test$p_value) #> [1] 0.2658385  plot_runs_test(runs_test, title = \"Runs Test (AMS Variability)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Trend Identification (Variability)","text":"MWMK White tests find evidence nonstationarity variability AMS. runs test confirms linear model suitable nonstationarity. Flood frequency analysis dataset requires time-dependent probability model. Recommendation: Use NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Riley Wheadon. Author, maintainer. Cuauhtémoc Vidrio-Sahagún. Author. Alain Pietroniro. Author. Jianxun . Author.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Vidrio-Sahagún C, Ruschkowski J, J, Pietroniro (2024). “practice-oriented framework stationary nonstationary flood frequency analysis.” Environmental Modelling Software, 173(105940). doi:10.1016/j.envsoft.2024.105940.","code":"@Article{,   title = {A practice-oriented framework for stationary and nonstationary flood frequency analysis},   author = {Cuauhtémoc Vidrio-Sahagún and Jake Ruschkowski and Jianxun He and Alain Pietroniro},   journal = {Environmental Modelling and Software},   year = {2024},   volume = {173},   number = {105940},   doi = {10.1016/j.envsoft.2024.105940}, }"},{"path":"https://rileywheadon.github.io/ffa-package/index.html","id":"ffa-framework-wiki","dir":"","previous_headings":"","what":"Flood Frequency Analysis Framework","title":"Flood Frequency Analysis Framework","text":"FFA Framework open-source tool flood frequency analysis (FFA) designed support systematic repeatable workflows stationary nonstationary analysis. Development ongoing University Calgary University Saskatchewan Canada. recent version framework freely available R package. original version released stand-alone GUI MATLAB source code published Vidrio-Sahagún et al. (2024). list changes MATLAB version, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-05BB001 — CAN_05BB001","title":"CAN-05BB001 — CAN_05BB001","text":"dataframe annual maximum series observations station 05BB001, BOW RIVER BANFF Alberta, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-05BB001 — CAN_05BB001","text":"","code":"CAN_05BB001"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-05BB001 — CAN_05BB001","text":"dateframe 110 rows 2 columns spanning period 1909-2018.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-05BB001 — CAN_05BB001","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-05BB001 — CAN_05BB001","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-05BB001 — CAN_05BB001","text":"unregulated station RHBN. Whitfield & Pomeroy (2016) found floods may caused rain, snow, combination . Therefore, practitioners careful interpreting results FFA station. Minimal human intervention basin means little justification change points. Trend detection finds evidence decreasing trend mean. dataset used test case comparison MATLAB implementation FFA framework. also excellent introductory example nonstationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CAN-05BB001 — CAN_05BB001","text":"Whitfield P. H., Pomeroy J. W. (2016) Changes flood peaks mountain river: implications analysis 2013 flood Upper Bow River, Canada, Hydrol. Process., 30: 4657–4673. doi:10.1002/hyp.10957 .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-07BE001 — CAN_07BE001","title":"CAN-07BE001 — CAN_07BE001","text":"dataframe annual maximum series observations station 07BE001, ATHABASCA RIVER ATHABASCA Alberta, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-07BE001 — CAN_07BE001","text":"","code":"CAN_07BE001"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-07BE001 — CAN_07BE001","text":"dateframe 108 rows 2 columns spanning period 1913-2020.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-07BE001 — CAN_07BE001","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-07BE001 — CAN_07BE001","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-07BE001 — CAN_07BE001","text":"unregulated station RHBN. notable features include: MKS/Pettitt tests find evidence change points 0.05 significance level. Trend detection finds evidence trends mean variability. dataset used test case comparison MATLAB implementation FFA framework. also excellent introductory example stationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08MH016 — CAN_08MH016","title":"CAN-08MH016 — CAN_08MH016","text":"dataframe annual maximum series observations station 08MH016, CHILLIWACK RIVER CHILLIWACK LAKE British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08MH016 — CAN_08MH016","text":"","code":"CAN_08MH016"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08MH016 — CAN_08MH016","text":"dateframe 95 rows 2 columns spanning period 1922-2016.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08MH016 — CAN_08MH016","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08MH016 — CAN_08MH016","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08MH016 — CAN_08MH016","text":"unregulated station RHBN. notable features include: MKS/Pettitt tests find evidence change points 0.05 significance level. Trend detection finds evidence increasing trend variability. dataset used test case comparison MATLAB implementation FFA framework. also useful demonstrating framework detects handles nonstationarity variability time series.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08NH021 — CAN_08NH021","title":"CAN-08NH021 — CAN_08NH021","text":"dataframe annual maximum series observations station 08NH021, KOOTENAI RIVER PORTHILL British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08NH021 — CAN_08NH021","text":"","code":"CAN_08NH021"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08NH021 — CAN_08NH021","text":"dateframe 91 rows 2 columns spanning period 1928-2018.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08NH021 — CAN_08NH021","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08NH021 — CAN_08NH021","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08NH021 — CAN_08NH021","text":"regulated station RHBN. notable features include: Libby dam constructed upstream station 1972. Pettitt test found evidence change point 1972 0.05 significance level. MKS test found evidence change points 1960 & 1985 0.05 significance level. splitting data 1972, trend detection finds evidence increasing, deterministic, linear trend mean subperiods. dataset used test case comparison MATLAB implementation FFA framework. also useful demonstrating framework detects handles change points time series.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08NM050 — CAN_08NM050","title":"CAN-08NM050 — CAN_08NM050","text":"dataframe annual maximum series observations station 08NM050, OKANAGAN RIVER PENTICTON British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08NM050 — CAN_08NM050","text":"","code":"CAN_08NM050"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08NM050 — CAN_08NM050","text":"dateframe 97 rows 2 columns spanning period 1921-2017.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08NM050 — CAN_08NM050","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08NM050 — CAN_08NM050","text":"Variables: max: Numeric; annual maximum series observation, m\\(^3\\)/s. year: Integer; corresponding year.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08NM050 — CAN_08NM050","text":"regulated station part RHBN. notable features include: Okanagan River upstream station regulated since 1914 due construction first dam, followed second dam 1920, regulation system early 1950s, consisting four dams 38 km engineered channel. Rapid human settlement, development, agricultural activity occurred watershed. dataset used test case comparison MATLAB implementation FFA framework. also useful demonstrating framework detects handles serial correlation, trends mean, trends variability. noted , dataset heavily influenced reservoir operations intended teaching purposes—design flood estimation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":null,"dir":"Reference","previous_headings":"","what":"Decompose Annual Maximum Series — data_decomposition","title":"Decompose Annual Maximum Series — data_decomposition","text":"Decomposes annual maxima series derive stationary stochastic component, can used identify best-fit distribution using conventional stationary methods. decomposition procedure follows proposed Vidrio-Sahagún (2022), relies statistical representation nonstationary stochastic processes.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decompose Annual Maximum Series — data_decomposition","text":"","code":"data_decomposition(data, years, structure)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decompose Annual Maximum Series — data_decomposition","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decompose Annual Maximum Series — data_decomposition","text":"Numeric vector decomposed data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decompose Annual Maximum Series — data_decomposition","text":"Four scenarios supported: trend (data returned unmodified). Linear trend mean . Linear trend standard deviation . Linear trends mean standard deviation. Internally, function following: Compute covariate = (years - 1900) / 100. trend location, fit Sen’s trend estimator data covariate. , remove fitted linear trend. trend scale, compute variability using data_mw_variability(), fit Sen’s trend estimator vector standard deviations, rescale series remove trends scale. necessary, shift data minimum least 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decompose Annual Maximum Series — data_decomposition","text":"Vidrio-Sahagún, C. T., , J. (2022). decomposition-based nonstationary flood frequency analysis. Journal Hydrology, 612 (September 2022), 128186. doi:10.1016/j.jhydrol.2022.128186","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decompose Annual Maximum Series — data_decomposition","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) structure <- list(location = TRUE, scale = FALSE) data_decomposition(data, years, structure) #>   [1] 102.48618  75.49338  99.74332 105.94756 111.14916  81.37988  97.05781 #>   [8]  97.02208  96.57003  93.79310 105.55292 119.84636  82.81923 104.18640 #>  [15]  80.36503  93.70802  98.33514 104.22413  89.58643 103.34173 102.22271 #>  [22]  85.48077 105.83698 117.27727  97.35078  88.89977  98.03175  89.85637 #>  [29]  82.93328 107.34391  99.68818 100.29315 114.02480  98.84270  96.31536 #>  [36]  78.48746  94.72897  94.31990 108.06044  98.02072  90.86215  96.68674 #>  [43]  94.60457 101.50038 124.53960  97.38374 102.62853  97.96640  77.60025 #>  [50] 105.27133  94.15111  94.45562  96.64127  96.67811 101.81379  73.50738 #>  [57] 123.00711  92.50233  98.18111 106.72402  89.26269 106.98611  93.32063 #>  [64]  83.93697  85.88710 106.22919  96.82833 100.33093  78.38314  80.60329 #>  [71]  98.08517 108.54988  97.47665 108.22563 100.21480 100.97619  93.74237 #>  [78]  96.49655  93.80447 113.88418 107.55769 101.99468 100.00202  88.89021 #>  [85] 105.41115  68.11546  92.61488  98.44372  90.21832  98.21272 104.53487 #>  [92] 104.32399  93.38884  98.56437 110.36472  90.02529 102.96539 106.60318 #>  [99]  90.40153  89.42880"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Data from MSC GeoMet API — data_geomet","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"Gets annual maximum series data hydrological monitoring station MSC GeoMet API.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"","code":"data_geomet(station_id)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"station_id character scalar containing ID hydrological monitoring station. can search station IDs name, province, drainage basin, location .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"dataframe two columns: max: float, annual maximum series observation, m\\(^3\\)/s. year: integer, corresponding year.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"","code":"# Get data for the BOW RIVER AT BANFF (05BB001) df <- data_geomet(\"05BB001\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Local Package Data — data_local","title":"Fetch Local Package Data — data_local","text":"Fetch annual maximum series data hydrological monitoring station package data directory.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Local Package Data — data_local","text":"","code":"data_local(csv_file)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Local Package Data — data_local","text":"csv_file character scalar containing file name local dataset /inst/extdata. Must one : \"CAN-05BA001.csv\": BOW RIVER LAKE LOUISE \"CAN-05BB001.csv\": BOW RIVER BANFF \"CAN-07BE001.csv\": ATHABASCA RIVER ATHABASCA \"CAN-08MH016.csv\": CHILLIWACK RIVER CHILLIWACK LAKE \"CAN-08NH021.csv\": KOOTENAI RIVER PORTHILL \"CAN-08NM050.csv\": OKANAGAN RIVER PENTICTON \"CAN-08NM116.csv\": MISSION CREEK NEAR EAST KELOWNA","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Local Package Data — data_local","text":"dataframe two columns: max: float, annual maximum series observation, m\\(^3\\)/s. year: integer, corresponding year.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch Local Package Data — data_local","text":"","code":"# Get data for the BOW RIVER AT BANFF (05BB001) df <- data_local(\"CAN-05BB001.csv\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"Generates time series standard deviations using moving window algorithm, can used explore potential evidence nonstationarity variability dataset. returns list pairs window’s mean year window standard deviation. hyperparameters size step control behaviour moving window. Following simulation findings Vidrio-Sahagún (2022), default window size step set 10 5 years respectively. However, can changed user.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"","code":"data_mw_variability(data, years, size = 10L, step = 5L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. size Integer scalar. number years moving window. Must positive number less equal length(data) (default 10). step Integer scalar. offset (years) successive moving windows. Must positive number (default 5).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"list two entries: years: Numeric vector containing mean year within window. std: Numeric vector standard deviations within window.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"Vidrio-Sahagún, C. T., , J. (2022). decomposition-based nonstationary flood frequency analysis. Journal Hydrology, 612 (September 2022), 128186. doi:10.1016/j.jhydrol.2022.128186","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) data_mw_variability(data, years) #> $std #>  [1]  7.979322 11.091337 10.834792  7.833379  6.918857  8.207443  9.093049 #>  [8] 11.037079 10.865376  8.024952  8.950729 10.082149  9.835107  8.926596 #> [15] 13.342132 15.260867 11.322819  8.959743  7.579580 #>  #> $year #>  [1] 1905.5 1910.5 1915.5 1920.5 1925.5 1930.5 1935.5 1940.5 1945.5 1950.5 #> [11] 1955.5 1960.5 1965.5 1970.5 1975.5 1980.5 1985.5 1990.5 1995.5 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"Performs bootstrapped version Mann-Kendall trend test account serial correlation annual maximum series data. procedure uses Spearman’s serial correlation test estimate least insignificant lag, applies bootstrap procedure obtain empirical p-value confidence bounds Mann-Kendall S-statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"","code":"eda_bbmk_test(data, alpha = 0.05, samples = 10000L, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. samples Integer scalar. number bootstrap samples. Default 10000. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"List; results test, including: data: data argument. s_bootstrap: Vector bootstrapped Mann-Kendall S-statistics. s_statistic: Mann-Kendall S-statistic computed original series. p_value: Empirical two-sided p-value derived bootstrap distribution. bounds: Confidence interval bounds null distribution statistic. reject: Logical. TRUE, null hypothesis rejected alpha. msg: Character string summarizing test result (printed quiet = FALSE).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"block size bootstrap selected least_lag + 1, least_lag estimated using eda_spearman_test(). Bootstrap samples generated resampling blocks original data without replacement computing Mann-Kendall S-statistic. procedure removes serial correlation data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"Bayazit, M., 2015. Nonstationarity hydrological records recent trends trend analysis: state---art review. Environ. Processes 2 (3), 527–542. doi:10.1007/s40710-015-0081-7 Khaliq, M.N., Ouarda, T.B.M.J., Gachon, P., Sushama, L., St-Hilaire, ., 2009. Identification hydrological trends presence serial cross correlations: review selected methods application annual flow regimes Canadian rivers. J. Hydrol. 368 (1–4), 117–130. doi:10.1016/j.jhydrol.2009.01.035 Sonali, P., Nagesh Kumar, D., 2013. Review trend detection methods application detect temperature changes India. J. Hydrol. 476, 212–227. doi:10.1016/j.jhydrol.2012.10.034","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_bbmk_test(data, samples = 1000L) #> $data #>   [1] 100.65487  89.01491  93.66822  79.36346 126.48932  88.46602  96.59362 #>   [8] 107.86363  87.29487 105.42142 100.75106 105.58514 104.15406  85.47700 #>  [15] 109.41206  96.61064  99.24426 100.40204 101.24301  90.01567 112.33390 #>  [22] 103.40424  95.27298 107.08753  84.71041 102.37425  86.87186 107.47029 #>  [29]  84.37482 100.71053  93.60465  91.54804 106.75245 111.53376  83.13495 #>  [36]  90.97185 113.17634 111.00190 112.03768  85.68729 113.82911 100.03126 #>  [43]  99.22113 104.41428 101.28923  91.69786  94.96407  88.06359  92.48277 #>  [50] 114.55841  91.71396 102.89774  95.19947  93.95171 114.60110 101.49679 #>  [57]  85.66679  99.89697  97.87764  90.93660  78.97848 118.93360  90.31874 #>  [64]  98.97397 102.39960 100.60899  78.22424  98.82140 101.12295 100.07886 #>  [71] 118.77744 121.58757 107.09715 107.66983  96.91789 110.12002  90.80948 #>  [78] 105.63380 103.22483 103.66674 111.29835  90.58502 102.17838 114.15412 #>  [85]  96.16267  98.25914  97.78255  89.90471 104.80725 116.04407  84.84975 #>  [92]  85.83976 108.76777 106.24132 121.12277  96.43876  89.35536 110.77117 #>  [99] 111.81576 101.98392 #>  #> $s_bootstrap #>    [1] -410 -276 -322 -136  538 1006  116  200  -44   80  148  234  -86   32 #>   [15]  360  146 -152  -28 -142   86 -134  550 -104 -148  166 -118  494 -124 #>   [29] -186  206  294 -338  262  270  148 -280 -174  522  342  106    2   78 #>   [43]    6  232 -146 -208  256  -58 -242  512   42  264  522 -218   88 -542 #>   [57] -244 -240   34  -42 -226  258  406 -300   80   76 -248  798 -642  434 #>   [71]  414 -138   34  616  500 -552  380 -568  286  110   44  334  390 -570 #>   [85]  266 -372  -42  434  516 -304  450  128  554   18 -356  738 -188 -374 #>   [99]  -96 -254  152  336  298 -532 -880   26 -128 -504 -442 -276  -28   36 #>  [113]  -76  -48  120  146  -94 -256  406   86 -180 -268  396  312  162  372 #>  [127] -372  336  -82  138   92 -146  576  -80  296   22  -76 -646  658 -532 #>  [141]  194 -214 -238  136  134  658 -156 -276  -54 -266 -508 -226  162  236 #>  [155]  148  236  112  106  488 -146  316 -562  190  428  694 -388  -10 -436 #>  [169]  256  710  610  106 -106   26   44  626  224 -264  112   14 -304   16 #>  [183]    2  -76  458  286 -256 -170 -526  448 -508  240  298  282  -36  728 #>  [197]  286   38 -344 -436 -430  348 -534 -270 -524   -2 -166  216 -406 -342 #>  [211]   80 -196  476  110  360  536  570 -204 -550 -348  154  288  158 -182 #>  [225] -136   20  370  288   74  164  404  -40 -224  708  230   44   48  204 #>  [239]  494 -324 -330 -138  -56 -132  116  528   20  240    4  -90 -350  -26 #>  [253] -952  274 -202  -98 -952  138 -442  490 -612   34  408  284 -248  122 #>  [267] -144  330 -104  690 -494 -444  -36 -936  196  230   82  390   92  -60 #>  [281]  152   66  104 -118 -150  -84   14 -420  252 -356  -26 -338   48 -276 #>  [295] -276  392  144  368 -176   20 -256  486  260  396 -382  562   16 -568 #>  [309] -418  -70  324  -66  310 -530  574  164  402 -340   46 -116   52 -192 #>  [323] -526  -12  386  -10  130  -50 -204  358  230  106 -544   54  320  276 #>  [337]  652 -528  -50  436 -192  134  -74 -130  -22 -482  330  230  408  324 #>  [351]  430  242  610  584 -132 -390  112 -518 -292  454  252   22  276 -230 #>  [365]  -70  422 -198  412  358  204 -386 -366 -540  360  152  178  594  170 #>  [379]  274 -420  194  -88 -692 -378 -358 -366 -480  118  -74   -6 -168   54 #>  [393]  132  398   80 -230  -84 -710 -358 -242  310  164  414   90  244 -478 #>  [407]  -64 -150  176 -360   72  280  -48 -176 -102  -64   68 -138   64 -224 #>  [421]  154   92  410  510 -114 -696 -206  310  302  172  100   98   84 -186 #>  [435]   36  180 -560    0  488 -104 -122 -238  624  308  184   28   54 -670 #>  [449]  626   14  -50  318   44 -160   34 -174  178 -848  600  -46  244  414 #>  [463] -296 -206  592 -298   86   56   88  530   42 -358 -500  214 -222  -20 #>  [477] -544  312  426  234 -254  316 -440 -366  360  -76 -156 -250   46 -452 #>  [491]   24   80  108  196  382 -470 -400  372 -360   90  576 -278  186 -368 #>  [505] -486 -224   -6  206 -406 -434 -312 -506 -872    8  218  -58 -132  132 #>  [519]  586 -102 -212  444   58    8 -622  344  298 -236  214 -232 -206   94 #>  [533] -148  256  606 -244 -144 -204  260 -174  158   32  538   54 -584 -406 #>  [547]  232   46  -10 -498   84  196 -446 -474  152   44 -290 -304  116 -286 #>  [561] -262 -190  110  340 -616  -50 -838 -416   96  130    8  192  292  312 #>  [575] -380  192   24  216 -490 -120  114  220  362   40  -78 -252    8  180 #>  [589]  194 -308   32  334 -208   52  -62  -12  420  468 -170 -180  144 -516 #>  [603]   14 -156   -6  700  388 -320 -316  552  -24   26  676 -116  -32 -596 #>  [617] -214 -652  644 -196 -276 -358  372 -428   72  -10   82  130    6  -96 #>  [631] -330  -68 -612  614 -310  712  -16 -114 -286 -316 -256 -138   76  506 #>  [645]  412 -328   10    6  100  600 -164  -40  546 -132 -152 -790   24 -254 #>  [659] -306  172  330    8  218   60  234  618  -68 -678  506 -276   18  266 #>  [673] -142  416 -120 -598 -336 -242   66 -292 -578  142 -498 -336 -236 -238 #>  [687]  216 -154 -270  428 -200 -112   82  -82 -384   92  210  194 -216  420 #>  [701]  382  482  -82  -20  100   28  -36 -300   58 -294 -740  282   94  -70 #>  [715]   22  242  -72  530  476  428  222  -54  592   10  242  354 -764  400 #>  [729] -218 -276  198 -142 -702 -204  154  162  364  -28 -334  414 -132 -194 #>  [743] -144   50  534  568  102 -190   10 -140   36 -548 -660  -24  702  148 #>  [757]  328  308  264 -120  -30   36 -324  388 -464  -56  340  236  148 -486 #>  [771]  562  176 -268 -436  622   72 -234 -366 -574   38  196 -558 -304  -66 #>  [785] -312 -948 -232  508 -118 -440 -496 -324 -244 -300  264  348 -180  -78 #>  [799]  -54  214 -242  504 -266  840   56   14  134  126 -170   52  192 -352 #>  [813]  -88 -282 -162  492  166 -258   64  -56 -282 -178  108   66  392  666 #>  [827]  206  204 -160  224 -304  350 -178 -230 -164  286 -366 -698  526 -836 #>  [841]  186  226 -116  306   42 -478  -70  224   44  -10 -428  346   34 -140 #>  [855] -474 -208 -824 -318  -20 -408 -314 -326  -42   74  560 -554   40  782 #>  [869]  120  160 -500  112  358 -100  -56   26 -108  168 -296  416  336 -438 #>  [883] -132 -488  -94  372  128   64 -332  -34   94 -104 -596 -486  442  160 #>  [897]  122  258   72 -660 -294 -366 -206 -492 -324 -648 -228 -468  700  706 #>  [911]  -20  -30  118  274 -140  296  296  680   44  162  -12 -660  434   86 #>  [925] -156 -106  214  320  294  392  410  192   -2   38 -160    0  -62   54 #>  [939]  186  224   50  -78 -346  400  210  322  472 -194 -110 -154  112  212 #>  [953]  254   36  470  482 -200  628 -478  458 -248  -50 -234  124  406  304 #>  [967]  -92   74 -178 -106  402  -30  318  178  552  -70  146 -388 -150 -106 #>  [981]   82  158  484 -404 -584  406  -48 -268   12 -194 -364  626 -430 -416 #>  [995]  478  340 -180 -428  172  -98 #>  #> $s_statistic #> [1] 472 #>  #> $p_value #> [1] 0.172 #>  #> $bounds #>    2.5%   97.5%  #> -646.05  626.00  #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The BBMK test had a p-value of 0.172.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence of a trend given the serial correlation.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"Performs KPSS unit root test annual maximum series data. null hypothesis time series trend-stationary linear trend constant drift (thus deterministic linear trend). alternative hypothesis time series unit root (thus stochastic trend).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"","code":"eda_kpss_test(data, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"list containing test results, including: data: data argument. statistic: KPSS test statistic. p_value: interpolated p-value. See note regarding discrete thresholds. reject: Logical scalar. , TRUE null hypothesis rejected alpha. msg: Character string summarizing test outcome, printed quiet = FALSE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"implementation KPSS test based aTSA package, interpolates significance table Hobjin et al. (2004). Therefore, result \\(p = 0.01\\) implies \\(p \\leq 0.01\\) result \\(p = 0.10\\) implies \\(p \\geq 0.10\\). implementation uses Type III KPSS test, accounts linear trend data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"Hobijn, B., Franses, P.H. Ooms, M. (2004), Generalizations KPSS-test stationarity. Statistica Neerlandica, 58: 483-502. Kwiatkowski, D.; Phillips, P. C. B.; Schmidt, P.; Shin, Y. (1992). Testing null hypothesis stationarity alternative unit root. Journal Econometrics, 54 (1-3): 159-178.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_kpss_test(data) #> $data #>   [1]  87.50984 102.95252  90.26103  73.53136 100.23273 111.47362 115.61049 #>   [8]  87.35983  88.33181  91.75555  94.76172  98.89976 121.99260  95.34879 #>  [15] 120.36984 100.39004  87.96905 119.83484  90.29670  85.67438 104.83300 #>  [22] 101.28824  84.71710 104.98693  86.50927  97.41662  83.55172  98.98267 #>  [29]  97.63843 106.02731 109.66670 107.35570 109.18831 102.81522 109.64195 #>  [36]  94.23139  97.94809 107.97812 108.19274 121.59665 104.90342 111.42943 #>  [43] 100.70440  93.71694  99.09350 105.10520  98.99026  81.75223 112.77722 #>  [50]  88.81335 110.26617 106.83853  90.09093  93.36497  98.52802  99.89112 #>  [57] 118.42932 103.24793 102.18773 106.94797  95.30401 100.08250  80.78876 #>  [64] 100.51796  94.84747  95.93285  92.80528  94.86763 105.97930 109.77976 #>  [71]  99.80091 114.75578 101.09780 100.12387  98.95186 107.50888  97.77118 #>  [78]  93.79625 113.14000 116.23621  88.10228 101.15881 116.18140  99.90063 #>  [85]  92.66700 106.42069 108.95565  91.35165 100.35780 107.02140 110.87775 #>  [92] 110.32847 112.30771  90.03516  90.82555  94.35715 103.97653  99.42904 #>  [99]  94.74145 104.28256 #>  #> $statistic #> [1] 0.04758024 #>  #> $p_value #> [1] 0.1 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The KPSS test had a p-value of 0.1.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence of a unit root..\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann–Kendall Trend Test — eda_mk_test","title":"Mann–Kendall Trend Test — eda_mk_test","text":"Performs Mann–Kendall trend test numeric vector detect presence monotonic trend (increasing decreasing) time. test nonparametric accounts tied observations data. null hypothesis assumes monotonic trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann–Kendall Trend Test — eda_mk_test","text":"","code":"eda_mk_test(data, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann–Kendall Trend Test — eda_mk_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann–Kendall Trend Test — eda_mk_test","text":"list containing test results, including: data: data argument. s_statistic: Mann–Kendall test statistic \\(S\\). s_variance: variance test statistic null hypothesis. p_value: p-value associated two-sided hypothesis test. reject: Logical. TRUE, null hypothesis rejected alpha. msg: character string summarizing result, printed quiet = FALSE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mann–Kendall Trend Test — eda_mk_test","text":"statistic \\(S\\) computed sum pairs \\(< j\\) sign difference \\(x_j - x_i\\). Ties explicitly accounted calculating variance \\(S\\), using grouped frequencies tied observations. test statistic \\(Z\\) computed based sign magnitude \\(S\\), p-value derived standard normal distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mann–Kendall Trend Test — eda_mk_test","text":"Kendall, M. (1975). Rank Correlation Methods. Griffin, London, 202 pp. Mann, H. B. (1945). Nonparametric Tests Trend. Econometrica, 13(3): 245-25","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann–Kendall Trend Test — eda_mk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_mk_test(data) #> $data #>   [1] 116.11412  90.69241 103.37862 105.22782  82.64148 109.39183 105.45024 #>   [8]  84.75166  94.25823 111.23967  86.69933  97.37938  96.58283 111.08042 #>  [15] 114.25324  99.55259  98.79250 106.57130 110.35033  88.61991  93.08293 #>  [22] 100.83571 104.75665 102.37172  92.25124 103.24165 108.40478 116.61977 #>  [29] 111.01600 108.00191 104.89789 108.15966  75.26442  89.19149 105.21227 #>  [36]  86.71029 118.16608 102.27068  87.32682 106.03875  88.81822 103.22338 #>  [43] 102.98355 114.61274 119.20752  89.24305  93.12479 106.15612  99.96043 #>  [50] 100.60333  97.72133  91.09217  99.29099  87.82165  96.03174 116.78254 #>  [57] 119.72330  98.41525  96.38403  92.93475 108.29597  92.21121  96.49941 #>  [64]  94.03990  95.46888  87.32682  93.65167 106.19333 105.58708  99.05894 #>  [71]  99.19472 100.19550  97.85936 107.34841  99.84156  88.23479  97.79369 #>  [78] 115.64516 111.22041 104.63076 106.33357  95.12631  89.60322  75.68793 #>  [85] 102.59373  96.36258 110.89977 107.88251 105.74549  98.24206 100.42963 #>  [92] 101.62222  97.24310  99.82175 102.24486  83.05105  98.18668 108.51155 #>  [99] 105.74684 107.53031 #>  #> $s_statistic #> [1] -60 #>  #> $s_variance #> [1] 112750 #>  #> $p_value #> [1] 0.8605227 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The Mann-Kendall test had a p-value of 0.861.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence of a monotonic trend.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"Performs Mann–Kendall–Sneyers (MKS) test detect beginning monotonic trend annual maximum series data. test computes normalized progressive regressive Mann–Kendall statistics identifies statistically significant crossing points, indicating potential change points trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"","code":"eda_mks_test(data, years, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"list containing test results, including: data: data argument. years: years argument. s_progressive: Normalized progressive Mann–Kendall-Sneyers statistics. s_regressive: Normalized regressive Mann–Kendall-Sneyers statistics. bound: Critical confidence bound significance based alpha. crossing_df: Crossing points, including indices, years, test statistics. change_df: Subset crossing_df statistically significant crossings. p_value: Two-sided p-value derived maximum crossing statistic. reject: Logical. TRUE, null hypothesis change point rejected. msg: Character string summarizing test result (printed quiet = FALSE).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"function computes progressive regressive Mann–Kendall statistics \\(S_t\\), normalized expected values variances null hypothesis. crossing points difference normalized statistics changes sign identified using linear interpolation. significance detected crossings assessed using quantiles normal distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"Sneyers, R. (1990). statistical analysis series observations. Technical note . 143, World Meteorological Organization, Geneva.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_mks_test(data, years) #> $data #>   [1]  85.09204  98.48259  96.75074 111.55520  98.43460 110.63326 102.35489 #>   [8] 120.92595  83.07251  89.94641 116.74478  95.62255 113.27158 114.27544 #>  [15]  84.60421 111.82677 106.54959 113.19297  95.98798  94.25990  81.96696 #>  [22] 100.44151 100.24345 111.49112  97.26690  94.35158 107.04075 105.20372 #>  [29] 107.43372 101.73053 109.10044  93.58330  88.93986  92.14111 105.30740 #>  [36] 112.18120  84.70178 105.51114  94.83542  96.01779 103.24808 107.26851 #>  [43]  96.57706  94.41080  96.02413  99.10775 110.40952 102.40919  96.55350 #>  [50]  91.02249  98.98338  92.13937  90.92910 114.08476 102.50388  94.02291 #>  [57]  94.74065  94.91006  92.55806  91.13979 118.16085  83.30854 111.22617 #>  [64] 107.17357  96.59280  99.14638 103.38835  96.73917 101.31666  98.82788 #>  [71] 108.98828 110.77115 107.69158  85.54915  85.71614  97.22417 101.68775 #>  [78] 109.77722 102.96900  97.91774  96.94300 102.01555  89.55891 110.86274 #>  [85]  85.63202 104.14338  97.27396 109.76791  93.27818 107.34289 103.56664 #>  [92] 101.41236 103.49810 109.90516  95.04841 101.62542 115.25917 102.32179 #>  [99]  94.17772  98.77404 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $s_progressive #>   [1]  0.000000000  1.000000000  0.522232968  1.358732441  0.979795897 #>   [6]  1.315071011  1.351690671  1.979486637  0.834057656  0.268328157 #>  [11]  0.856348839  0.411435289  0.854124427  1.259132473  0.544358825 #>  [16]  0.810405304  0.823852555  1.098453328  0.734697000  0.324442842 #>  [21] -0.301969221 -0.253781368 -0.237694107  0.000000000 -0.140129810 #>  [26] -0.418789464 -0.229316010 -0.118539117  0.075032247  0.089205155 #>  [31]  0.288939088 -0.064865813 -0.433843555 -0.726397723 -0.582258714 #>  [36] -0.217934306 -0.601628535 -0.465160477 -0.641134244 -0.745666212 #>  [41] -0.651452411 -0.444332963 -0.554667287 -0.748455410 -0.841279499 #>  [46] -0.823729207 -0.559397660 -0.479954179 -0.586148819 -0.861580350 #>  [51] -0.852832167 -1.104750685 -1.365385099 -0.977312631 -0.863885270 #>  [56] -1.060130239 -1.197789713 -1.308057256 -1.510621544 -1.734796427 #>  [61] -1.331703750 -1.646076163 -1.370081699 -1.170311681 -1.188890886 #>  [66] -1.134491337 -1.001131697 -1.026919897 -0.953031061 -0.937886780 #>  [71] -0.719726334 -0.476402214 -0.285740204 -0.564675074 -0.827946905 #>  [76] -0.852123612 -0.782898632 -0.565199731 -0.469899066 -0.498559490 #>  [81] -0.546506476 -0.476530197 -0.719686431 -0.479022813 -0.736325519 #>  [86] -0.615424633 -0.641562445 -0.439699360 -0.616628533 -0.449597451 #>  [91] -0.346254058 -0.310297708 -0.212404716 -0.009798813 -0.138248896 #>  [96] -0.107617931  0.174532479  0.217920290  0.045347031  0.017868701 #>  #> $s_regressive #>   [1] -0.01786870  0.25092024  0.29158349  0.37399817  0.13927026  0.18326016 #>   [7] -0.02939644 -0.08628942 -0.39799054 -0.09941948  0.14986582 -0.15592905 #>  [13] -0.02883274 -0.31894819 -0.63034402 -0.33400333 -0.62582013 -0.79834069 #>  [19] -1.11724307 -1.01144482 -0.84755113 -0.52916562 -0.54794172 -0.56298329 #>  [25] -0.87903278 -0.83709549 -0.66734327 -0.85722061 -1.03058438 -1.26572562 #>  [31] -1.35359876 -1.62636822 -1.45039202 -1.17430042 -0.94633180 -1.14359980 #>  [37] -1.50634177 -1.18028683 -1.40311289 -1.24458294 -1.10975948 -1.27520000 #>  [43] -1.52271281 -1.43184058 -1.25802122 -1.12522871 -1.14144147 -1.48811634 #>  [49] -1.64134387 -1.53509790 -1.26309352 -1.27573566 -1.01323660 -0.70612492 #>  [55] -1.12671007 -1.27170157 -1.03165475 -0.80583738 -0.57438163 -0.26956651 #>  [61]  0.06990621 -0.39919679  0.06285952 -0.39236644 -0.65380292 -0.38343867 #>  [67] -0.31131331 -0.46483238 -0.19459744 -0.11897492 -0.01784103 -0.33764511 #>  [73] -0.82977382 -1.22996769 -0.72737117 -0.23354968  0.04960881  0.07923137 #>  [79] -0.36657309 -0.54354460 -0.38933141 -0.10495671 -0.11363310  0.49431153 #>  [85] -0.09004503  0.64333316  0.38321423  0.85412443  0.41143529  1.32344821 #>  [91]  0.98386991  0.62554324  0.98974332  0.75093926  0.18786729  0.97979590 #>  [97]  1.35873244  0.52223297 -1.00000000  0.00000000 #>  #> $bound #> [1] 1.959964 #>  #> $crossing_df #>   cross year  statistic       max #> 1    53 1953 -1.1899384  90.92910 #> 2    55 1955 -0.9197108 102.50388 #> 3    57 1957 -1.1372399  94.74065 #> 4    73 1973 -0.4376558 107.69158 #> 5    75 1975 -0.7933734  85.71614 #> 6    80 1980 -0.4898663  97.91774 #> 7    81 1981 -0.5092288  96.94300 #> 8    99 1999  0.1790096  94.17772 #>  #> $change_df #> [1] cross     year      statistic max       #> <0 rows> (or 0-length row.names) #>  #> $p_value #> [1] 0.2340706 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The Mann-Kendall-Sneyers test had a p-value of 0.234.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence of change point(s).\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Performs nonparametric Pettitt test detect single abrupt shift mean time series. null hypothesis, change point.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"","code":"eda_pettitt_test(data, years, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"list containing test results, including: data: data argument. years: years argument. u_t: Numeric vector absolute U-statistics time indices. k_statistic: Numeric scalar. maximum absolute U-statistic. k_critical: Numeric scalar. critical K-statistic value given alpha. p_value: Numeric scalar. Approximate p-value test. change_index: Integer scalar. Index detected change point (0 none). change_year: Integer scalar. Year detected change point (0 none). reject: Logical scalar. TRUE, null hypothesis rejected. msg: Character scalar. formatted summary message describing test result.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Pettitt test computes maximum absolute value U-statistic possible split points. p-value approximated using asymptotic formula.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Pettitt, .N., 1979. Non-parametric Approach Change-point Problem. J. Royal Statist. Soc. 28 (2), 126–135. http://www.jstor.org/stable/2346729","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_pettitt_test(data, years) #> $data #>   [1] 110.10684 109.21671  99.00200  94.00343  89.97952  96.54386  96.87132 #>   [8] 118.40742  81.72863 100.76640 100.55287 103.52433  99.65863 104.98293 #>  [15] 123.86866  86.82425  89.81833  78.07199 109.07017 105.91076  95.54329 #>  [22] 109.39690  79.70020  95.64596  94.12719 107.52656 106.84281  90.71340 #>  [29] 103.15814 101.68861  89.16990  94.98362 107.85188 104.65562 106.01239 #>  [36]  98.39976  97.98901 103.80865 104.51256  96.98454  85.77457  88.90572 #>  [43]  99.96630 121.10423 111.00964  87.02501  87.80226  95.98337 124.83532 #>  [50] 100.11715  88.47333 112.44132 119.73193  89.69074 106.60512 106.76343 #>  [57] 112.06801  90.97239 104.50397 107.26423 112.04740 113.73421  93.75126 #>  [64] 100.81992 112.55942  88.79528  87.33852 100.56045 113.85555  98.87681 #>  [71]  79.61201  93.19376  92.09872  93.18624 103.82141 102.02935 112.10449 #>  [78]  85.42835 107.26397  88.20753 108.59298 100.01181  90.54158 111.24859 #>  [85] 116.50599  99.71808  95.68262 109.62970 101.42725  92.26551  98.38343 #>  [92] 102.72831 111.78279  99.34285  96.73675 106.16976 114.48573 104.01289 #>  [99] 107.36656 106.75189 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $u_t #>   [1]  65 124 107  60   5  38  67  24  69  68  71  56  69  40  57  30  97 196 #>  [19] 139 108 149  88 183 222 267 216 173 234 221 214 285 328 275 248 215 236 #>  [37] 261 244 219 246 335 408 417 322 255 340 421 456 357 362 439 360 267 336 #>  [55] 299 258 183 242 219 172  99  16  65  62  19  56 139 140  55  74 171 222 #>  [73] 279 332 313 304 227 318 273 352 297 304 367 298 209 220 257 194 189 244 #>  [91] 267 256 185 200 231 196 109  88  39  39 #>  #> $k_statistic #> [1] 456 #>  #> $k_critical #> [1] 710.1279 #>  #> $p_value #> [1] 0.291 #>  #> $change_index #> [1] 0 #>  #> $change_year #> [1] 0 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The Pettitt test had a p-value of 0.291.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence of a change point.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Phillips–Perron Unit Root Test — eda_pp_test","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"Applies Phillips–Perron (PP) test check unit root annual maximum series data. null hypothesis assumes time series contains unit root (thus stochastic trend). alternative hypothesis time series trend-stationary (thus deterministic linear trend).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"","code":"eda_pp_test(data, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"List; test results, consisting : data: data argument. statistic: Z-statistic used perform test. p_value: Reported p-value test. See notes interpolation thresholds. reject: Logical. TRUE, null hypothesis rejected alpha. msg: Character string summarizing test result, printed quiet = FALSE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"implementation test based aTSA package, interpolates p-values table critical values presented Fuller W. . (1996). critical values available \\(\\alpha \\geq 0.01\\). Therefore, reported p-value 0.01 indicates \\(p \\leq 0.01\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"Fuller, W. . (1976). Introduction Statistical Time Series. New York: John Wiley Sons Phillips, P. C. B.; Perron, P. (1988). Testing Unit Root Time Series Regression. Biometrika, 75 (2): 335-346","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_pp_test(data) #> $data #>   [1] 105.71910  95.62950 115.22793  90.09813 101.21090 105.45931 108.28352 #>   [8]  94.04016  97.61715 104.73747 103.40918  96.95804 107.33999 103.13770 #>  [15] 111.29980 103.81615 103.68654 108.84609 109.21164 117.78567  92.96911 #>  [22]  75.93637  99.68249  97.04275 106.00636 111.60364 100.56538  95.59872 #>  [29]  98.35395  90.02786  76.48258  97.01634  78.53935  97.08140  93.10026 #>  [36]  94.97523 106.05890  97.37607  96.90605 119.81818  94.51492  92.73484 #>  [43] 101.06323 114.59809  93.10381 114.15768 100.04895 101.07439  98.37847 #>  [50]  89.26774 100.03078 110.44615  98.93937 107.17062  87.33825  69.94219 #>  [57] 108.75675 106.93614 112.83858 109.99143  86.73613  81.15200 101.48586 #>  [64]  99.01536  91.65490 102.34030 104.16639  89.90877  92.40957  81.75752 #>  [71]  98.91953 104.97110 115.84434 105.76548 116.35644 105.87302  91.87373 #>  [78] 100.21493 102.16915 106.43384  90.75542 112.09305 115.66475 106.29210 #>  [85]  93.57340 109.91148 123.90197 111.88599 107.95127 112.67272  96.37174 #>  [92]  90.85030 109.63619 110.11232 103.51880  85.45366  96.87146 101.49090 #>  [99]  85.91269 110.95705 #>  #> $statistic #> [1] -79.64662 #>  #> $p_value #> [1] 0.01 #>  #> $reject #> [1] TRUE #>  #> $msg #> [1] \"\\n - The Phillips-Perron test had a p-value of 0.01.\\n - At a significance level of 0.05, we reject the null hypothesis.\\n - Therefore, there is NO evidence of a unit root..\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Applies Wald–Wolfowitz runs test numeric vector residuals order assess whether behave random sequence. test statistic’s p-value compared significance level alpha, decision returned along human-readable summary message.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"","code":"eda_runs_test(results, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"results fitted linear model produced eda_sens_trend(). alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"list containing test results, including: residuals: Numeric vector residual values fitted linear model. n: length residuals vector removing median. n_plus: number residuals median. n_minus: number residuals median. runs: number runs transformed sequence residuals. statistic: runs test statistic, computed using runs. p_value: P-value Wald–Wolfowitz runs test applied residuals. reject: Logical. TRUE, null hypothesis random residuals rejected. msg: Character string summarizing test result, printed quiet = FALSE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Wald–Wolfowitz runs test examines sequence residuals test randomness around median. small p-value suggests nonrandom clustering, may indicate linear model inappropriate data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Wald, . Wolfowitz, J. (1940). test whether two samples population. Annals Mathematical Statistics, 11(2), 147–162.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) sens <- eda_sens_trend(data, years) eda_runs_test(sens) #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $residuals #>   [1]   3.4591070  -0.2548210   4.0780276  -5.7121758  -4.1019963   5.8170220 #>   [7]  18.3759451   7.8448449 -19.3704826   3.1951557  -4.8548835 -14.0041231 #>  [13]  15.8960238   9.7043435   7.7599675  -2.6344192  12.4022537   5.2769517 #>  [19]   5.9751249  -0.3766194  -8.9044044   0.4777749  -2.8826902  -7.0580551 #>  [25]  -6.4190872   4.2534043   0.2057172  14.2050622 -13.0367103  -2.4429078 #>  [31]  -6.3697003 -13.2841977  -5.0320028 -11.9802453  -3.8846573  -5.7262198 #>  [37]   4.5316228   7.6894095  10.4028158  10.9720948  -3.2556775   2.3393429 #>  [43] -10.4254574   8.8172799   1.9941589  -4.5579976  20.0140418   3.7121135 #>  [49]  -2.5697982  -9.5932598  -9.0913520 -16.7248099 -12.6076036   1.1704120 #>  [55]  14.2431448   5.5670667  -2.7751031  -7.6384031   0.4798927  18.3112193 #>  [61] -13.8913171  -5.2786273   9.3185863   7.5079721  -9.9864054   8.2432909 #>  [67]  -0.2057172   3.8273357  14.6473824  -0.8514123   3.0004590   7.0521799 #>  [73]  12.6558942  23.8521577 -11.5999526 -10.6746966 -11.1816573  -3.1532257 #>  [79]  -2.8515510   6.4116198 -14.4396657   3.4544708  -0.4803302  -6.9933186 #>  [85]   5.9791544   6.2065308  -7.1883797  16.3031722  -8.8611832   4.9651717 #>  [91]  13.5735386  23.8327449  18.3549657 -15.3155336  -4.2107676  20.1174146 #>  [97] -11.5633922   2.9811871  -7.6860026  -6.6695637 #>  #> $n #> [1] 100 #>  #> $n_plus #> [1] 50 #>  #> $n_minus #> [1] 50 #>  #> $runs #> [1] 50 #>  #> $statistic #> [1] -0.2010178 #>  #> $p_value #> [1] 0.8406846 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The runs test had a p-value of 0.841.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence that a linear model is inappropriate.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"Sen's Trend Estimator — eda_sens_trend","title":"Sen's Trend Estimator — eda_sens_trend","text":"Computes Sen's linear trend estimator univariate time series.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sen's Trend Estimator — eda_sens_trend","text":"","code":"eda_sens_trend(data, years, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sen's Trend Estimator — eda_sens_trend","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sen's Trend Estimator — eda_sens_trend","text":"list containing estimated trend: data: data argument. years: years argument. slope: Median slope pairwise data-year combinations. intercept: Median intercept estimate fitted line. residuals: Vector residuals observed fitted values. msg: Character string summarizing results.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sen's Trend Estimator — eda_sens_trend","text":"Sen's slope estimator robust, nonparametric trend estimator based median pairwise slopes data points. corresponding intercept median \\(y_i - mx_i\\) \\(m\\) estimated slope.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sen's Trend Estimator — eda_sens_trend","text":"Sen, P.K. (1968). Estimates regression coefficient based Kendall's tau. Journal American Statistical Association, 63(324), 1379–1389.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sen's Trend Estimator — eda_sens_trend","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_sens_trend(data, years) #> $data #>   [1] 106.92862 100.25897 102.30677 113.45502  84.21815  98.97677  82.43465 #>   [8] 103.70060 105.35396  91.20770  97.68624  93.26708 104.92886  79.27116 #>  [15]  97.78326 101.73428 106.31450 103.22489  73.27027  95.80033 103.70320 #>  [22] 102.10024  99.97592  83.25465  99.17297  91.39310 105.19352  93.22492 #>  [29]  99.17705  84.72953 118.55731 103.49558  82.49623  96.23500  98.72704 #>  [36] 105.71291  97.50484 108.02381 117.10142  95.18903  86.38487  80.38076 #>  [43] 103.62647  90.84430 112.93500 109.10819  91.70940  97.33396 118.54191 #>  [50] 125.12024  96.60533 101.08595 114.59925  91.33009  91.55568 100.06430 #>  [57] 112.65379  87.15250  79.90941 100.66470  96.72762  97.51682  85.97496 #>  [64] 101.36356  93.11784 102.07516 104.08187 106.84038 108.13680  95.52265 #>  [71] 121.98109 121.29389 110.50041  71.14720 114.04081  85.53392  97.67344 #>  [78]  90.89083 103.29376  99.21390  98.90397  89.27138 103.95860 108.25451 #>  [85] 108.57277  98.29088 101.00560  95.65229  95.56905  89.66521 122.50497 #>  [92]  94.90634 107.83315 106.31107 111.51340 102.09891  98.66040 107.10639 #>  [99] 102.32650  93.56602 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $slope #> [1] 4.073809 #>  #> $intercept #> [1] 98.07508 #>  #> $residuals #>   [1]   8.81280410   2.10240745   4.10947612  15.21698100 -14.06061752 #>   [6]   0.65726046 -15.92560351   5.29961713   6.91223949  -7.27476579 #>  [11]  -0.83696179  -5.29685538   6.32418254 -19.37425178  -0.90289104 #>  [16]   3.00739133   7.54687039   4.41652710 -25.57883673  -3.08950872 #>  [21]   4.77262151   3.12892459   0.96386544 -15.79814328   0.07943578 #>  [26]  -7.74117533   6.01850770  -5.99082596  -0.07943578 -14.56769291 #>  [31]  19.21934370   4.11687477 -16.92320726  -3.22517479  -0.77387587 #>  [36]   6.17125220  -2.07755547   8.40067587  17.43755213  -4.51557266 #>  [41] -13.36047035 -19.40531874   3.79965319  -9.02325725  13.02670623 #>  [46]   9.15915834  -8.28037423  -2.69654990  18.47065789  25.00825173 #>  [51]  -3.54739108   0.89248606  14.36504662  -8.94484585  -8.76000051 #>  [56]  -0.29211471  12.25663939 -13.28538916 -20.56921799   0.14533092 #>  [61]  -3.83248368  -3.08402654 -14.66662587   0.68123669  -7.60521663 #>  [66]   1.31136327   3.27733533   5.99510320   7.25079120  -5.40409794 #>  [71]  21.01360311  20.28566444   9.45144431 -29.94250111  12.91036975 #>  [76] -15.63725540  -3.53847814 -10.36182353   2.00037202  -2.12023325 #>  [81]  -2.47089906 -12.14422362   2.50225456   6.75742932   7.03494788 #>  [86]  -3.28768030  -0.61369798  -6.00774504  -6.13171757 -12.07630191 #>  [91]  20.72271847  -6.91664208   5.96942836   4.40660696   9.56820195 #>  [96]   0.11296797  -3.36627632   5.03897227   0.21835134  -8.58287229 #>  #> $msg #> [1] \"Estimated trend: y = 4.074x + 98.08.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Spearman Test for Autocorrelation — eda_spearman_test","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"Performs Spearman rank serial correlation test annual maximum series data check serial correlation various lags. Reports smallest lag serial correlation statistically significant given significance level.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"","code":"eda_spearman_test(data, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"list containing test results, including: data: data argument. rho: Numeric vector serial correlation estimates lags \\(1\\) \\(n-3\\). sig: Logical vector indicating lags exhibit significant serial correlation least_lag: smallest lag serial correlation insignificant. reject: Logical. TRUE, least_lag > 0. msg: Character string summarizing test result, printed quiet = FALSE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"lag \\(1\\) \\(n - 3\\), function computes Spearman correlation coefficient original series lagged series. first lag insignificant serial correlation coefficient returned least_lag.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_spearman_test(data) #> $data #>   [1] 115.53949  97.62048  91.48151 103.99375  78.75553 109.02592 109.87513 #>   [8]  91.57034  75.35796  83.06758 111.02988 110.79918  97.81132 115.99110 #>  [15]  97.49414 114.96522 104.48972 101.82078  93.83436  86.25984  92.93219 #>  [22] 108.05278 101.79365 100.54119  84.71055 104.00399  96.18705 100.58256 #>  [29] 103.80280 101.53855 114.89921 104.92200 103.21021 101.94214 107.42460 #>  [36] 116.84394  92.50584 104.87693 100.38928  91.57844 110.66950 112.50907 #>  [43]  99.43985 111.01152 108.60272  94.35932  79.94742 102.48602 102.09311 #>  [50] 105.64982 104.92798  97.24127 102.44770 101.24951 102.63553  93.00900 #>  [57]  79.43679 102.37812  99.58353 106.73590  90.05232 106.93567 105.46208 #>  [64] 113.96973  95.44503 104.04250 103.99922  76.23319 104.59000 111.99336 #>  [71] 106.43052 102.14418 113.51713  86.05348  86.47162 106.82030  93.79462 #>  [78] 101.08264 111.23510  95.33119 103.83775  77.06348 117.92758  78.22464 #>  [85]  91.43614 109.47363 105.26578  81.73983 112.47440  99.33391 109.85445 #>  [92] 112.67286 100.08714  87.93782  95.52039  88.28031 107.00460 115.12215 #>  [99] 101.99070  93.67655 #>  #> $rho #>  [1] -0.088620903 -0.124393525 -0.013412582 -0.135349973 -0.056187010 #>  [6]  0.128158075 -0.026707648 -0.108564647 -0.045548654  0.208494876 #> [11] -0.144603337 -0.053661372 -0.036104833 -0.091806217 -0.047058824 #> [16]  0.060443454 -0.076445153 -0.039170231  0.236833785  0.088185654 #> [21] -0.068597858  0.107424221 -0.178978916 -0.204812030  0.098890469 #> [26] -0.151958534  0.031685795  0.336356036  0.124346076 -0.154614644 #> [31]  0.077968579 -0.023743177 -0.218173837  0.074793863  0.114597902 #> [36] -0.162042125  0.122503840  0.277731611 -0.141882602 -0.176382328 #> [41]  0.039625950 -0.038973823 -0.132745657  0.055502392 -0.113492063 #> [46] -0.290032399  0.280519271  0.296337403 -0.068506787  0.026458583 #> [51] -0.096632653 -0.169778550  0.094935245 -0.024360160  0.049407115 #> [56]  0.115715292  0.180761099 -0.138157362  0.053832753  0.006754221 #> [61] -0.100000000 -0.049786629  0.079895685 -0.175546976  0.156022409 #> [66]  0.023682200  0.075200535 -0.348240469  0.267741935 -0.155951057 #> [71] -0.171921182  0.200875753 -0.131257631 -0.187008547  0.523076923 #> [76]  0.039130435  0.015810277 -0.169960474  0.183116883  0.037593985 #> [81] -0.108771930 -0.011351909 -0.284313725 -0.150000000  0.496428571 #> [86]  0.221978022 -0.109890110 -0.188811189 -0.463636364  0.127272727 #> [91]  0.850000000  0.142857143 -0.535714286 -0.257142857 -0.400000000 #> [96]  0.000000000  1.000000000 #>  #> $sig #>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE #> [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [73] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [85] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE #> [97]  TRUE #>  #> $least_lag #> [1] 1 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The Spearman test found a least insignificant lag of 1.\\n - There is NO evidence of serial correlation.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":null,"dir":"Reference","previous_headings":"","what":"White Test for Heteroskedasticity — eda_white_test","title":"White Test for Heteroskedasticity — eda_white_test","text":"Performs White test heteroskedasticity regressing squared residuals linear model original regressors squared terms. null hypothesis homoskedasticity.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"White Test for Heteroskedasticity — eda_white_test","text":"","code":"eda_white_test(data, years, alpha = 0.05, quiet = TRUE)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"White Test for Heteroskedasticity — eda_white_test","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"White Test for Heteroskedasticity — eda_white_test","text":"list containing results White test: data: data argument. years: years argument. r_squared: Coefficient determination auxiliary regression. statistic: White test statistic based sample size r_squared. p_value: p-value derived Chi-squared distribution df = 2. reject: Logical. TRUE, null hypothesis rejected alpha. msg: Character string summarizing test result, printed quiet = FALSE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"White Test for Heteroskedasticity — eda_white_test","text":"White test regresses squared residuals primary linear model lm(data ~ years) original regressor square. test statistic calculated \\(nR^2\\), \\(R^2\\) coefficient determination auxiliary regression. null hypothesis, test statistic \\(\\chi^2\\) distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"White Test for Heteroskedasticity — eda_white_test","text":"White, H. (1980). heteroskedasticity-consistent covariance matrix estimator direct test heteroskedasticity. Econometrica, 48(4), 817–838.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"White Test for Heteroskedasticity — eda_white_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_white_test(data, years) #> $data #>   [1] 106.48141 101.00782  82.42012 109.38275  84.40313  97.26097 107.97217 #>   [8]  96.08833 109.67785  93.54223 100.93528 107.62956  94.67642  97.07130 #>  [15] 102.06642  79.20201 108.58147 107.13222  84.83731 109.16774  89.74668 #>  [22]  91.85919 108.46643  94.93178 107.50644 106.77331 101.41293  85.65508 #>  [29]  86.16541  92.84438 122.92140  90.07804 104.59519  97.62281 108.35991 #>  [36]  93.65053  80.76932  98.64659 108.60061 113.31049  83.67603  97.24631 #>  [43]  97.62521 107.06400  99.04726 127.25076 106.30267  88.88680  96.44126 #>  [50] 110.38200  87.75264  93.26501 118.97439  96.53224  78.59880 124.76428 #>  [57]  95.97234 103.79369  92.51198 105.05991  94.64354 103.41252  92.41732 #>  [64]  95.76410  88.48226 115.30293 101.12761  98.74202  85.32868 109.61289 #>  [71] 109.64497 112.58596  84.62194 107.85550 103.97192 106.98846 104.50714 #>  [78] 106.40800 112.20660 110.78431  96.80989  87.26127  93.49333  92.57200 #>  [85]  87.74771  96.87723 110.71671  98.46020  91.09966  84.26416 105.62013 #>  [92]  94.57179 111.64665 103.88534 108.28514 100.32738  93.51255  98.24003 #>  [99]  91.33492 102.79443 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $r_squared #> [1] 0.04015465 #>  #> $statistic #> [1] 4.015465 #>  #> $p_value #> [1] 0.1342928 #>  #> $reject #> [1] FALSE #>  #> $msg #> [1] \"\\n - The White test had a p-value of 0.134.\\n - At a significance level of 0.05, we fail to reject the null hypothesis.\\n - Therefore, there is NO evidence of heteroskedasticity.\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/ffaframework-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Flood Frequency Analysis Framework — ffaframework-package","title":"Flood Frequency Analysis Framework — ffaframework-package","text":"package provides tools stationary (S-FFA) nonstationary (NS-FFA) flood flood frequency analysis annual maximum series data. Methods framework_* prefix orchestrate EDA /FFA modules Vidrio-Sahagún et al. (2024) generate reports. Users wish develop customized workflows may use methods following prefixes: eda_*: Explore annual maximum series data evidence nonstationarity inform approach selection (S-FFA NS-FFA): Detect statistically significant change points. Detect statistically significant temporal trends mean variability. select_*: Select suitable probability distribution using L-moments. fit_*: Fit parameters given distribution approach (S-FFA NS-FFA). uncertainty_*: Compute return level estimates confidence intervals. model_assessment() evaluates model performance using variety metrics. Additional utility functions visualization computation also available: data_* methods load, transform, decompose annual maximum series data. plot_* methods produce diagnostic summary plots. quantile_*, loglik_*, lmom_* implement distribution-specific computations. Datasets five hydrometric stations Canada provided representative use cases (datasets /inst/extdata testing purposes ): Athabasca River Athabasca (CAN-07BE001): unregulated station statistical evidence trends change points (S-FFA recommended). Kootenai Kiver Porthill (CAN-08NH21): regulated station outside evidence abrupt change mean 1972 (piecewise NS-FFA recommended). Bow River Banff (CAN-05BB001). unregulated station statistical evidence trend mean (NS-FFA recommended). Chilliwack River Chilliwack Lake (CAN-08MH016): unregulated station statistical evidence linear trend variability (NS-FFA recommended). Okanagan River Penticton (CAN-08NM050): regulated station statistical evidence linear trend mean variability (NS-FFA recommended). package assumes familiarity statistical techniques used FFA, including L-moments, maximum likelihood estimation, parametric bootstrap. explanation methods, see FFA Framework wiki. examples, see vignettes exploratory data analysis flood frequency analysis.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/ffaframework-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Flood Frequency Analysis Framework — ffaframework-package","text":"Maintainer: Riley Wheadon rileywheadon@gmail.com Authors: Cuauhtémoc Vidrio-Sahagún ct.vidrio-sahagun@usask.ca Alain Pietroniro alain.pietroniro@ucalgary.ca Jianxun jianhe@ucalgary.ca","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","title":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","text":"helper function used fit_lmom_xxx(). function validate parameters designed use methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","text":"","code":"fit_lmom_fast(data, distribution)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_fast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","text":"list containing results parameter estimation: method: \"L-moments\". params: numeric vector 2 3 parameters depending distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_fast.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_fast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper Function for L-moments Parameter Estimation — fit_lmom_fast","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmom_fast(data, \"PE3\") #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 100.3453856  10.2827266  -0.1400513 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"functions estimates parameters four-parameter Kappa distribution using method L-moments. Since known closed form solution parameters terms L-moments, parameters computed numerically using Newton-Raphson iteration.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"","code":"fit_lmom_kappa(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"list containing results parameter estimation: method: \"L-moments\". params: numeric vector 4 parameters order location, scale, shape (2).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"First, sample L-moments data computed using lmom_sample() method. , stats::optim() function used determine parameters minimizing euclidian distance sample theoretical L-moment ratios. implementation routine based deprecated homtest package, formerly avilable https://CRAN.R-project.org/package=homtest.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_kappa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmom_kappa","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmom_kappa(data) #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 97.64945854 10.02823515  0.32276353  0.03890407 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter Estimation with L-Moments — fit_lmom_xxx","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"Estimate parameters nine different distributions (\"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\") using method L-moments.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"","code":"fit_lmom_gum(data)  fit_lmom_nor(data)  fit_lmom_lno(data)  fit_lmom_gev(data)  fit_lmom_glo(data)  fit_lmom_gno(data)  fit_lmom_pe3(data)  fit_lmom_lp3(data)  fit_lmom_wei(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"list containing results parameter estimation: method: \"L-moments\". params: numeric vector 2 3 parameters depending distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"First, sample L-moments data computed using lmom_sample() method. formulas Hosking (1997) used compute parameters L-moments. Distributions \"GNO\", \"PE3\", \"LP3\" use rational approximation parameters.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmom_xxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameter Estimation with L-Moments — fit_lmom_xxx","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmom_lp3(data) #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 4.59988427 0.10628129 0.06803559 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"Estimates parameters probability distribution optional nonstationary structure  maximizing log‐likelihood. Initial values obtained L‐moment parameter estimation, optimization performed via stats::nlminb() repeated perturbations needed.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"","code":"fit_maximum_likelihood(   data,   distribution,   prior = NULL,   years = NULL,   structure = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". prior Numeric vector length 2. Specifies Beta prior shape parameters \\((p, q)\\) shape parameter \\(\\kappa\\). used distribution = \"GEV\". years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"list containing results parameter estimation: params: Numeric vector estimated parameters. mll: Maximum log‐likelihood value.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"Calls fit_lmom_fast() data obtain initial parameter estimates. Initializes trend parameters zero necessary. WEI models, sets location parameter zero ensure support. Defines objective function using loglik_fast() general_loglik_fast(). Runs stats::nlminb() box constraints. Attempts optimization 100 times maximum found.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"Although modern stats::optim() function preferred stats::nlminb(), use stats::nlminb() supports infinite values likelihood function.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_maximum_likelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Likelihood Parameter Estimation — fit_maximum_likelihood","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) structure <- list(location = TRUE, scale = FALSE) fit_maximum_likelihood(data, \"GNO\", NULL, years, structure) #> $method #> [1] \"MLE\" #>  #> $params #> [1] 99.45758050  1.59710972 11.41849812 -0.07884203 #>  #> $mll #> [1] -385.4173 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Log-Likelihood Helper Function — general_loglik_fast","title":"Generalized Log-Likelihood Helper Function — general_loglik_fast","text":"helper function used general_loglik_gev(). function validate parameters designed use methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Log-Likelihood Helper Function — general_loglik_fast","text":"","code":"general_loglik_fast(data, distribution, params, prior, years, structure)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Log-Likelihood Helper Function — general_loglik_fast","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. prior Numeric vector length 2. Specifies Beta prior shape parameters \\((p, q)\\) shape parameter \\(\\kappa\\). used distribution = \"GEV\". years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_fast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Log-Likelihood Helper Function — general_loglik_fast","text":"Numeric scalar. generalized log-likelihood value.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_fast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Log-Likelihood Helper Function — general_loglik_fast","text":"","code":"# Initialize data, params, prior, years, and structure data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(0, 1, 1, 0, 0) prior <- c(5, 10) years <- seq(from = 1901, to = 2000) structure <- list(location = TRUE, scale = TRUE)  # Compute the generalized log-likelihood general_loglik_fast(data, \"GEV\", params, prior, years, structure) #> [1] NaN"},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"Computes generalized log-likelihood stationary nonstationary variants Generalized Extreme Value (GEV) distribution geophysical (Beta) prior distribution shape parameter (Martins Stedinger, 2000).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"","code":"general_loglik_gev(data, params, prior, years = NULL, structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. prior Numeric vector length 2. Specifies Beta prior shape parameters \\((p, q)\\) shape parameter \\(\\kappa\\). used distribution = \"GEV\". years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"Numeric scalar. generalized log-likelihood value.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"generalized log-likelihood defined sum log-likelihood specified model log-density Beta prior parameters \\((p, q)\\). contribution prior : $$\\log \\pi(\\kappa) = (p-1) \\log(0.5-\\kappa) + (q-1) \\log(0.5+\\kappa) - \\log (\\beta(p, q))$$","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"El Adlouni, S., Ouarda, T.B.M.J., Zhang, X., Roy, R., Bob´ee, B., 2007. Generalized maximum likelihood estimators nonstationary generalized extreme value model. Water Resour. Res. 43 (3), 1–13. doi:10.1029/2005WR004545 Martins, E. S., Stedinger, J. R. (2000). Generalized maximum-likelihood generalized extreme-value quantile estimators hydrologic data. Water Resources Research, 36(3), 737–744. doi:10.1029/1999WR900330","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/general_loglik_gev.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Log-Likelihood Functions for GEV Models — general_loglik_gev","text":"","code":"# Initialize data, params, prior, years, and structure data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(0, 1, 1, 0) prior <- c(5, 10) years <- seq(from = 1901, to = 2000) structure <- list(location = TRUE, scale = FALSE)  # Compute the generalized log-likelihood general_loglik_gev(data, params, prior, years, structure) #> [1] NaN"},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Function for L-moments Ratios — lmom_fast","title":"Helper Function for L-moments Ratios — lmom_fast","text":"helper function used lmom_theoretical(). function validate parameters designed use methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Function for L-moments Ratios — lmom_fast","text":"","code":"lmom_fast(distribution, params)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Function for L-moments Ratios — lmom_fast","text":"distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Function for L-moments Ratios — lmom_fast","text":"numeric vector four elements: \\(\\lambda_1\\): L-mean \\(\\lambda_2\\): L-variance \\(\\tau_3\\): L-skewness \\(\\tau_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Helper Function for L-moments Ratios — lmom_fast","text":"function returns identical L-moment ratios \"\"/\"LNO\" \"PE3\"/\"LP3\" since L-moments \"LNO\" \"LP3\" distributions compared sample L-moments log-transformed data internally.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Helper Function for L-moments Ratios — lmom_fast","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_fast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper Function for L-moments Ratios — lmom_fast","text":"","code":"lmom_fast(\"GLO\", c(0, 1, 0)) #> [1]       NaN       NaN 0.0000000 0.1666667"},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample L-moments — lmom_sample","title":"Sample L-moments — lmom_sample","text":"Computes first four sample L-moments L-moment ratios numeric vector data. L-moments linear combinations order statistics provide robust alternatives conventional moments, advantages parameter estimation heavy-tailed skewed distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample L-moments — lmom_sample","text":"","code":"lmom_sample(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample L-moments — lmom_sample","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample L-moments — lmom_sample","text":"numeric vector containing first four sample L-moments L-moment ratios: \\(l_1\\): L-mean \\(l_2\\): L-variance \\(t_3\\): L-skewness \\(t_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample L-moments — lmom_sample","text":"Given probability weighted moments \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\), first four sample L-moments : \\(l_1 = \\beta_0\\) \\(l_2 = 2\\beta_1 - \\beta_0\\) \\(l_3 = 6\\beta_2 - 6\\beta_1 + \\beta_0\\) \\(l_4 = 20\\beta_3 - 30\\beta_2 + 12\\beta_1 - \\beta_0\\) , sample L-skewness \\(t_3 = l_3 / l_2\\) sample L-kurtosis \\(t_4 = l_4 / l_2\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample L-moments — lmom_sample","text":"Hosking, J. R. M. (1990). L-moments: Analysis estimation distributions using linear combinations order statistics. Journal Royal Statistical Society: Series B (Methodological), 52(1), 105–124.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_sample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample L-moments — lmom_sample","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) lmom_sample(data) #> [1] 98.710675680  5.046018614 -0.001798337  0.096414266"},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":null,"dir":"Reference","previous_headings":"","what":"Theoretical L-moments of Probability Distributions — lmom_theoretical","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"Computes first four L-moments L-moment ratios seven different probability distributions (\"GUM\", \"\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"WEI\") given parameters distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"","code":"lmom_theoretical_gum(params)  lmom_theoretical_nor(params)  lmom_theoretical_gev(params)  lmom_theoretical_glo(params)  lmom_theoretical_gno(params)  lmom_theoretical_pe3(params)  lmom_theoretical_wei(params)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"numeric vector four elements: \\(\\lambda_1\\): L-mean \\(\\lambda_2\\): L-variance \\(\\tau_3\\): L-skewness \\(\\tau_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"distributions \"GUM\", \"\", \"GEV\", \"GLO\", \"WEI\" closed-form solutions L-moments L-moment ratios terms parameters. distributions \"GNO\" \"PE3\" use rational approximations L-moment ratios Hosking (1997).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/lmom_theoretical.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Theoretical L-moments of Probability Distributions — lmom_theoretical","text":"","code":"lmom_theoretical_gev(c(0, 1, 0)) #> [1] NaN NaN NaN NaN"},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood Helper Function — loglik_fast","title":"Log-Likelihood Helper Function — loglik_fast","text":"helper function used loglik_xxx(). function validate parameters designed use methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood Helper Function — loglik_fast","text":"","code":"loglik_fast(data, distribution, params, years, structure)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood Helper Function — loglik_fast","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_fast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood Helper Function — loglik_fast","text":"Numeric scalar. log-likelihood value.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_fast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood Helper Function — loglik_fast","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(0, 1, 0) years <- seq(from = 1901, to = 2000) structure <- list(location = FALSE, scale = FALSE) loglik_fast(data, \"GEV\", params, years, structure) #> [1] NaN"},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_xxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood Functions for Probability Models — loglik_xxx","title":"Log-Likelihood Functions for Probability Models — loglik_xxx","text":"Compute log-likelihood value stationary nonstationary variants nine different distributions: \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". total, methods compute log-likelihood 36 different probability models.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_xxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood Functions for Probability Models — loglik_xxx","text":"","code":"loglik_gum(data, params, years = NULL, structure = NULL)  loglik_nor(data, params, years = NULL, structure = NULL)  loglik_lno(data, params, years = NULL, structure = NULL)  loglik_gev(data, params, years = NULL, structure = NULL)  loglik_glo(data, params, years = NULL, structure = NULL)  loglik_gno(data, params, years = NULL, structure = NULL)  loglik_pe3(data, params, years = NULL, structure = NULL)  loglik_lp3(data, params, years = NULL, structure = NULL)  loglik_wei(data, params, years = NULL, structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_xxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood Functions for Probability Models — loglik_xxx","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_xxx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood Functions for Probability Models — loglik_xxx","text":"Numeric scalar. log-likelihood value.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/loglik_xxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood Functions for Probability Models — loglik_xxx","text":"","code":"# Initialize data, params, years, and structure data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(0, 1, 1, 0) years <- seq(from = 1901, to = 2000) structure <- list(location = TRUE, scale = FALSE)  # Compute the log-likelihood loglik_gno(data, params, years, structure) #> [1] NaN"},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate Goodness-of-Fit for Fitted Flood Models — model_diagnostics","title":"Evaluate Goodness-of-Fit for Fitted Flood Models — model_diagnostics","text":"Computes multiple performance metrics diagnostic indicators assess quality fitted flood frequency model. includes accuracy (residual statistics), fitting efficiency (information criteria), uncertainty (coverage-based metrics using confidence intervals).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate Goodness-of-Fit for Fitted Flood Models — model_diagnostics","text":"","code":"model_diagnostics(   data,   distribution,   params,   uncertainty,   years = NULL,   structure = NULL,   alpha = 0.05,   pp_formula = \"Weibull\" )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate Goodness-of-Fit for Fitted Flood Models — model_diagnostics","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. uncertainty List; estimated reutrn levels confidence intervals generated uncertainty_bootstrap() uncertainty_rfpl(). years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. pp_formula Character (1); string specifying plotting position formula. Must one \"Weibull\", \"Blom\", \"Cunnane\", \"Gringorten\", \"Hazen\"","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate Goodness-of-Fit for Fitted Flood Models — model_diagnostics","text":"List containing model assessment metrics: data: data argument. estimates: Quantile estimates empirical return periods. R2: Coefficient determination linear regression estimates vs. data. RMSE: Root mean squared error quantile estimates. bias: Mean bias quantile estimates. AIC: Akaike Information Criterion. BIC: Bayesian Information Criterion. AIC_MLL: Akaike Information Criterion, computed using MLE. BIC_MLL: Bayesian Information Criterion, computed using MLE. AW: Average width confidence interval(s). POC: Percent observations covered confidence interval(s). CWI: Confidence width index, metric combines AW POC.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate Goodness-of-Fit for Fitted Flood Models — model_diagnostics","text":"","code":"# Initialize example data and params data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 10)  # Perform uncertainty analysis uncertainty <- uncertainty_bootstrap(data, \"NOR\", \"L-moments\")  # Evaluate model diagnostics model_diagnostics(data, \"NOR\", params, uncertainty) #> $data #>   [1] 113.79449  86.25379  95.89541 101.91088 110.64448  92.80289  66.20745 #>   [8] 101.76545 105.14418  97.68805  83.51785 102.70968  86.82404 111.54073 #>  [15]  97.98395  99.96687  99.81895  95.15258  87.57367  95.40822  91.69506 #>  [22]  88.04409 101.20507 105.82843  93.86866 104.63807  97.09908 107.45821 #>  [29] 104.61719  93.12696  87.88099  88.90739  90.79209  92.38459  88.58345 #>  [36] 117.87419 107.94493  95.44703 102.17106  90.41650  69.52560 118.92147 #>  [43]  98.87746  95.92466 100.85646 102.19875  93.54169 102.07378 102.21039 #>  [50] 107.09135  96.45425 101.78812 125.52394  92.14230 101.96464 117.70845 #>  [57]  95.69500  97.02246  80.92915  99.49001  82.79532 130.00649 100.68805 #>  [64]  88.34959  96.66235 106.53280 114.47210  98.23928  95.30328  97.86018 #>  [71]  90.53086 107.57747  90.35654 108.57547  85.90441 100.53240 100.39905 #>  [78] 115.23569  91.24060 110.07792  97.39674  78.80304  93.12105 116.86685 #>  [85]  76.67217 109.59920  93.22673  99.73017  91.59067  77.74570  95.81638 #>  [92] 120.79266  94.38469  94.98544  87.66035  95.80415  71.69704  99.85433 #>  [99]  97.61136 104.81938 #>  #> $estimates #>   [1] 123.30079 120.57856 118.85177 117.55301 116.49673 115.59780 114.80973 #>   [8] 114.10420 113.46263 112.87214 112.32341 111.80947 111.32497 110.86568 #>  [15] 110.42824 110.00990 109.60838 109.22178 108.84850 108.48716 108.13657 #>  [22] 107.79571 107.46367 107.13967 106.82300 106.51302 106.20918 105.91097 #>  [29] 105.61792 105.32963 105.04569 104.76577 104.48953 104.21668 103.94693 #>  [36] 103.68003 103.41572 103.15377 102.89397 102.63612 102.38000 102.12543 #>  [43] 101.87224 101.62024 101.36926 101.11915 100.86973 100.62085 100.37236 #>  [50] 100.12409  99.87591  99.62764  99.37915  99.13027  98.88085  98.63074 #>  [57]  98.37976  98.12776  97.87457  97.62000  97.36388  97.10603  96.84623 #>  [64]  96.58428  96.31997  96.05307  95.78332  95.51047  95.23423  94.95431 #>  [71]  94.67037  94.38208  94.08903  93.79082  93.48698  93.17700  92.86033 #>  [78]  92.53633  92.20429  91.86343  91.51284  91.15150  90.77822  90.39162 #>  [85]  89.99010  89.57176  89.13432  88.67503  88.19053  87.67659  87.12786 #>  [92]  86.53737  85.89580  85.19027  84.40220  83.50327  82.44699  81.14823 #>  [99]  79.42144  76.69921 #>  #> $R2 #> [1] 0.9772745 #>  #> $RMSE #> [1] 3.047736 #>  #> $bias #> [1] 2.079555 #>  #> $AIC #> [1] 115.4399 #>  #> $BIC #> [1] 120.6502 #>  #> $AW #> [1] 5.087545 #>  #> $POC #> [1] 97.95918 #>  #> $CWI #> [1] 4.795182 #>  #> $MLL_AIC #> [1] 770.7833 #>  #> $MLL_BIC #> [1] 775.9936 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/mu_sigma.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Location and Scale of Kappa Distribution — mu_sigma","title":"Compute Location and Scale of Kappa Distribution — mu_sigma","text":"Compute Location Scale Kappa Distribution","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/mu_sigma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Location and Scale of Kappa Distribution — mu_sigma","text":"","code":"mu_sigma(l1, l2, k, h)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'alpha' — param-alpha","title":"Parameter 'alpha' — param-alpha","text":"Parameter 'alpha'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'alpha' — param-alpha","text":"alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-data.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'data' — param-data","title":"Parameter 'data' — param-data","text":"Parameter 'data'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'data' — param-data","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'distribution' — param-distribution","title":"Parameter 'distribution' — param-distribution","text":"Parameter 'distribution'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'distribution' — param-distribution","text":"distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'method' — param-method","title":"Parameter 'method' — param-method","text":"Parameter 'method'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'method' — param-method","text":"method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-p.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'p' — param-p","title":"Parameter 'p' — param-p","text":"Parameter 'p'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'p' — param-p","text":"p Numeric vector probabilities 0 1 missing values.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-params.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'params' — param-params","title":"Parameter 'params' — param-params","text":"Parameter 'params'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'params' — param-params","text":"params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-periods.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'periods' — param-periods","title":"Parameter 'periods' — param-periods","text":"Parameter 'periods'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-periods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'periods' — param-periods","text":"periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'prior' — param-prior","title":"Parameter 'prior' — param-prior","text":"Parameter 'prior'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'prior' — param-prior","text":"prior Numeric vector length 2. Specifies Beta prior shape parameters \\((p, q)\\) shape parameter \\(\\kappa\\). used distribution = \"GEV\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-quiet.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'quiet' — param-quiet","title":"Parameter 'quiet' — param-quiet","text":"Parameter 'quiet'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-quiet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'quiet' — param-quiet","text":"quiet Logical scalar. FALSE, prints summary statistical test console. Default TRUE.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'samples' — param-samples","title":"Parameter 'samples' — param-samples","text":"Parameter 'samples'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'samples' — param-samples","text":"samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'slice' — param-slice","title":"Parameter 'slice' — param-slice","text":"Parameter 'slice'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'slice' — param-slice","text":"slice Numeric scalar specifying year evaluate quantiles nonstationary probability distribution. slice element years argument. Note structure$location structure$scale FALSE, argument effect output function.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-slices.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'slices' — param-slices","title":"Parameter 'slices' — param-slices","text":"Parameter 'slices'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-slices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'slices' — param-slices","text":"slices Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. slices elements years argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-structure.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'structure' — param-structure","title":"Parameter 'structure' — param-structure","text":"Parameter 'structure'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-structure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'structure' — param-structure","text":"structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-years.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'years' — param-years","title":"Parameter 'years' — param-years","text":"Parameter 'years'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-years.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'years' — param-years","text":"years Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Annual Maximum Series Data — plot_ams_data","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"Generates plot annual maximum series data optional line connecting data points.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"","code":"plot_ams_data(data, years, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. show_line TRUE (default), draw line data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"ggplot; plot containing: Black dots (data, year) pair. optional line thorugh data points (show_line == TRUE)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) plot_ams_data(data, years)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"Generates histogram bootstrapped Mann–Kendall S‐statistics vertical lines indicating observed S‐statistic confidence bounds.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"","code":"plot_bbmk_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"results List BB‐MK test results generated eda_bbmk_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"ggplot; plot containing: gray histogram distribution bootstrapped S‐statistics. red vertical line lower upper confidence bounds. black vertical line observed S‐statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- eda_bbmk_test(data, samples = 1000L) plot_bbmk_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"Generates plot L-moment ratios L-skewness x-axis L-kurtosis y-axis. Plots sample log-sample L-moment ratios alongside theoretical L-moment ratios set candidate distributions. Also includes small inset around L-moment ratios recommended distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"","code":"plot_lmom_diagram(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"results List distribution selection results generated select_ldistance(), select_lkurtosis(), select_zstatistic(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"ggplot; plot object containing L-moment ratio diagram, : L-moment ratio curves 3-parameter distribution. Points L-moment ratios 2-parameter distribution. Sample log-sample L-moment ratio \\((t_3, t_4)\\) points.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- select_ldistance(data) plot_lmom_diagram(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"Constructs two‐panel visualization MKS test. upper panel plots normalized progressive regressive Mann–Kendall S‐statistics time, dashed confidence bounds potential trend‐change points. lower panel contains annual maximum series data change points highlighted.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"","code":"plot_mks_test(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"results list generated eda_mks_test(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'top_xlabel', 'top_ylabel', 'bottom_xlabel' 'bottom_ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"patchwork object two ggplot2 panels stacked vertically.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- eda_mks_test(data, years) plot_mks_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Model Assessment Results — plot_model_diagnostics","title":"Plot Model Assessment Results — plot_model_diagnostics","text":"Creates quantile–quantile plot comparing observed annual maximum series data quantile estimates fitted parametric model. 1:1 line drawn black parametric model estimates plotted semi‐transparent red points.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Model Assessment Results — plot_model_diagnostics","text":"","code":"plot_model_diagnostics(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Model Assessment Results — plot_model_diagnostics","text":"results List; model assessment results generated model_diagnostics(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Model Assessment Results — plot_model_diagnostics","text":"ggplot; plot containing: black line representing model deviation emprical quantiles. Red points denoting estimated quantiles empirical quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_model_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Model Assessment Results — plot_model_diagnostics","text":"","code":"# Initialize example data and params data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 10)  # Perform uncertainty analysis uncertainty <- uncertainty_bootstrap(data, \"NOR\", \"L-moments\")  # Evaluate model diagnostics results <- model_diagnostics(data, \"NOR\", params, uncertainty)  # Generate a model assessment plot plot_model_diagnostics(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Return Levels and Confidence Intervals for NS-FFA — plot_nsffa","title":"Plot Return Levels and Confidence Intervals for NS-FFA — plot_nsffa","text":"Generates plot effective return periods x-axis effective return levels (annual maxima magnitudes) y-axis 5 time slices. slice displayed distinct color. Confidence bounds shown semi-transparent ribbons, point estimates  overlaid solid lines. Return periods depicted logarithmic scale.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Return Levels and Confidence Intervals for NS-FFA — plot_nsffa","text":"","code":"plot_nsffa(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Return Levels and Confidence Intervals for NS-FFA — plot_nsffa","text":"results list estimated return levels confidence intervals generated uncertainty_bootstrap() uncertainty_rfpl(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Return Levels and Confidence Intervals for NS-FFA — plot_nsffa","text":"ggplot; plot one line ribbon per slice.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Return Levels and Confidence Intervals for NS-FFA — plot_nsffa","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000)  # Run the uncertainty bootstrap at slices 1920, 1960, 2000 results <- uncertainty_bootstrap(      data,    \"GEV\",    \"L-moments\",    years = years,    structure = list(location = TRUE, scale = FALSE),    slices = c(1920, 1960, 2000),      samples = 1000L )  # Generate the plot plot_nsffa(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"Creates two‐panel visualization Mann–Whitney–Pettitt test. upper panel plots Pettitt \\(U_t\\) statistic time along significance threshold potential change point. lower panel displays annual maximum series data optional trend line, period mean(s), potential change point(s).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"","code":"plot_pettitt_test(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"results list generated eda_pettitt_test(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'top_xlabel', 'top_ylabel', 'bottom_xlabel' 'bottom_ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"patchwork object two ggplot2 panels stacked vertically.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- eda_pettitt_test(data, years) plot_pettitt_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Runs Test Results — plot_runs_test","title":"Plot Runs Test Results — plot_runs_test","text":"Generates residual plot Sen’s estimator applied annual maximum series data (variability data) horizontal dashed line zero annotation indicating p-value Runs test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Runs Test Results — plot_runs_test","text":"","code":"plot_runs_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Runs Test Results — plot_runs_test","text":"results list runs test results generated eda_runs_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Runs Test Results — plot_runs_test","text":"ggplot; plot containing: Black points residual year. red dashed horizontal line \\(y = 0\\). text annotation “Runs p-value: X.XXX” plot area.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Runs Test Results — plot_runs_test","text":"","code":"# Initialize data and years data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000)  # Generate runs test plot  sens <- eda_sens_trend(data, years) results <- eda_runs_test(sens) plot_runs_test(results, \"mean\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sens_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Sen’s Trend Estimator — plot_sens_trend","title":"Plot Sen’s Trend Estimator — plot_sens_trend","text":"Produces scatterplot annual maximum series data variance time, optionally overlaid Sen’s trend estimator mean /variability.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sens_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Sen’s Trend Estimator — plot_sens_trend","text":"","code":"plot_sens_trend(   data,   years,   mean_trend = NULL,   variability_trend = NULL,   show_line = TRUE,   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sens_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Sen’s Trend Estimator — plot_sens_trend","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. mean_trend Trend mean estimated eda_sens_trend(). variability_trend Trend variability estimated eda_sens_trend(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sens_trend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Sen’s Trend Estimator — plot_sens_trend","text":"ggplot; plot containing: Gray points year’s annual maximum series value. Optional gray line connecting data show_line = TRUE. solid black line representing constant mean, mean_trend == NULL. solid blue line representing trend mean, mean_trend != NULL. dashed black line representing constant variability, variability_trend == NULL. dashed blue line representing trend variability, variability_trend != NULL. equation trend mean, written form \\(mx + b\\).","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sens_trend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Sen’s Trend Estimator — plot_sens_trend","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) mean_trend <- eda_sens_trend(data, years) plot_sens_trend(data, years, meant_trend = mean_trend)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Return Levels and Confidence Intervals for S-FFA — plot_sffa","title":"Plot Return Levels and Confidence Intervals for S-FFA — plot_sffa","text":"Generates plot return periods x-axis return levels (annual maxima magnitudes) y-axis S-FFA. confidence bound shown semi-transparent ribbon, point estimates overlaid solid line. Return periods shown logarithmic scale.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Return Levels and Confidence Intervals for S-FFA — plot_sffa","text":"","code":"plot_sffa(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Return Levels and Confidence Intervals for S-FFA — plot_sffa","text":"results list estimated return levels confidence intervals generated uncertainty_bootstrap() uncertainty_rfpl(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Return Levels and Confidence Intervals for S-FFA — plot_sffa","text":"ggplot; plot showing: semi-transparent gray ribbon results$ci_lower results$ci_upper. solid black line point estimates.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Return Levels and Confidence Intervals for S-FFA — plot_sffa","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- uncertainty_bootstrap(data, \"WEI\", \"L-moments\") plot_sffa(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"Visualizes Spearman’s rho serial correlation coefficients shaded points indicating statistical significance.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"","code":"plot_spearman_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"results list generated eda_spearman_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"ggplot; plot showing: Vertical segments \\(y=0\\) \\(\\rho\\) value lag. Filled circles lag, filled black serial correlation detected.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- eda_spearman_test(data) plot_spearman_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_fast.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper Function for Quantile Functions — quantile_fast","title":"Helper Function for Quantile Functions — quantile_fast","text":"helper function used quantile_xxx(). function validate parameters designed use methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_fast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper Function for Quantile Functions — quantile_fast","text":"","code":"quantile_fast(p, distribution, params, slice, structure)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_fast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper Function for Quantile Functions — quantile_fast","text":"p Numeric vector probabilities 0 1 missing values. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. slice Numeric scalar specifying year evaluate quantiles nonstationary probability distribution. slice element years argument. Note structure$location structure$scale FALSE, argument effect output function. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_fast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper Function for Quantile Functions — quantile_fast","text":"numeric vector quantiles length p.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_fast.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper Function for Quantile Functions — quantile_fast","text":"","code":"# Initialize p, params, and structure p <- runif(n = 10) params <- c(0, 1, 1, 0) structure <- list(location = FALSE, scale = TRUE)  # Compute the log-likelihood in the year 2000 quantile_fast(p, \"GEV\", params, 2000, structure) #>  [1]  1.6119281 -0.7093861 -1.2223080 -0.7742434  0.9181472 -0.8100189 #>  [7]  4.3439162  1.9114303  3.4545270  1.2281361"},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_xxx.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Functions for Probability Models — quantile_xxx","title":"Quantile Functions for Probability Models — quantile_xxx","text":"Compute quantiles stationary nonstationary variants nine different distributions: \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". total, methods compute quantiles 36 different probability models.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_xxx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Functions for Probability Models — quantile_xxx","text":"","code":"quantile_gum(p, params, slice = 1900, structure = NULL)  quantile_nor(p, params, slice = 1900, structure = NULL)  quantile_lno(p, params, slice = 1900, structure = NULL)  quantile_gev(p, params, slice = 1900, structure = NULL)  quantile_glo(p, params, slice = 1900, structure = NULL)  quantile_gno(p, params, slice = 1900, structure = NULL)  quantile_pe3(p, params, slice = 1900, structure = NULL)  quantile_lp3(p, params, slice = 1900, structure = NULL)  quantile_wei(p, params, slice = 1900, structure = NULL)  quantile_kap(p, params, slice = 1900, structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_xxx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Functions for Probability Models — quantile_xxx","text":"p Numeric vector probabilities 0 1 missing values. params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. slice Numeric scalar specifying year evaluate quantiles nonstationary probability distribution. slice element years argument. Note structure$location structure$scale FALSE, argument effect output function. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_xxx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Functions for Probability Models — quantile_xxx","text":"numeric vector quantiles length p.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/quantile_xxx.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Functions for Probability Models — quantile_xxx","text":"","code":"# Initialize p and params p <- runif(n = 10) params <- c(0, 1, 0)  # Compute the quantiles quantile_wei(p, params) #>  [1]   0 Inf Inf   0   0   0   0 Inf   0   0"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Distance Method for Distribution Selection — select_ldistance","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"Selects distribution set candidate distributions minimizing Euclidean distance theoretical L-moment ratios \\((\\tau_3, \\tau_4)\\) sample L-moment ratios \\((t_3, t_4)\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"","code":"select_ldistance(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"list results distribution selection: method: \"L-distance\". data: data argument. metrics: list L-distance metrics candidate distribution. recommendation: name distribution smallest L-distance.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"candidate distribution, method computes Euclidean distance sample L-moment ratios (\\(\\tau_3\\), \\(\\tau_4\\)) closest point theoretical distribution's L-moment curve. two-parameter distributions (Gumbel, Normal, Log-Normal), theoretical L-moment ratios compared directly sample L-moment ratios. distribution minimum distance selected. distribution fit log-transformed data (Log-Normal Log-Pearson Type III), L-moment ratios log-transformed sample used instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_ldistance(data) #> $method #> [1] \"L-distance\" #>  #> $data #>   [1] 105.50888  95.11776 108.97312  81.70875 103.55607 111.35757 108.24657 #>   [8]  92.00188  85.72684  95.36425  85.03508  85.35188  89.46015  94.55967 #>  [15] 105.16984 104.29304 106.06805  91.04149 108.23841 104.48857 104.34418 #>  [22]  91.08970  93.56836 114.11590  88.27081  89.45632 104.03920 104.79253 #>  [29] 116.49868  98.45517 141.44174 107.19363 105.30876  95.07604 102.71694 #>  [36]  93.16386 113.56993 115.54153 101.96406  96.39743 113.18202  99.75882 #>  [43] 105.89203 102.38840  98.76708 100.50590  96.98711  95.43674  96.38334 #>  [50]  95.18110  94.10146  90.65543 114.77908 118.29996  90.75872  97.29535 #>  [57]  99.32922  90.32297  82.05011 103.88287  81.25267  86.52339  95.95108 #>  [64] 100.33890  95.51435  96.20210 100.56687 107.18240  98.69194  83.38249 #>  [71] 126.97296 104.12097  93.21544  98.72096 109.38441 117.33438 103.91108 #>  [78] 102.22118 108.38415 101.01798 116.86989  94.62226  91.73635 104.95056 #>  [85] 103.69007  99.91300  93.53077  86.69027 114.98008  92.02169 105.61363 #>  [92] 108.22062 107.05678 101.79175 107.80714  74.17870  85.06983 110.84752 #>  [99] 123.70490  86.89288 #>  #> $metrics #> $metrics$GUM #> [1] 0.1205486 #>  #> $metrics$NOR #> [1] 0.05605174 #>  #> $metrics$LNO #> [1] 0.02155606 #>  #> $metrics$GEV #> [1] 0.03361533 #>  #> $metrics$GLO #> [1] 0.0195169 #>  #> $metrics$GNO #> [1] 0.02452334 #>  #> $metrics$PE3 #> [1] 0.0257812 #>  #> $metrics$LP3 #> [1] 0.02057492 #>  #> $metrics$WEI #> [1] 0.04542831 #>  #>  #> $recommendation #> [1] \"GLO\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"Selects probability distribution minimizing absolute distance theoretical L-kurtosis (\\(\\tau_4\\)) sample L-kurtosis (\\(t_4\\)). supports 3-parameter distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"","code":"select_lkurtosis(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"list results distribution selection: method: \"L-kurtosis\". data: data argument. metrics: list L-kurtosis metrics distribution. recommendation: Name distribution smallest L-kurtosis metric.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"method computes distance sample theoretical L-kurtosis values fixed L-skewness. three parameter distributions, shape parameter best replicates sample L-skewness determined using stats::optim().","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_lkurtosis(data) #> $method #> [1] \"L-kurtosis\" #>  #> $data #>   [1] 102.56928  97.68225  72.17210 106.98132 101.15245  72.87185  98.46018 #>   [8] 101.75773  97.67156  90.50121 113.06182  95.83942 103.72385 101.94554 #>  [15]  94.65623  76.35925 107.50753 100.23578 112.95685 104.52338 108.84731 #>  [22] 100.58835 102.51379 103.85555  87.34236 103.05540  96.86775  96.07440 #>  [29]  94.67134  93.00802  73.18456 102.90506 117.04368  95.54740 105.50263 #>  [36]  83.87351 113.75235 103.23683  90.53634  99.54861  93.73578 100.86708 #>  [43] 101.32189 106.35173  93.95137 108.27911  97.68586 108.75957 101.26202 #>  [50] 102.42864 117.77877 106.00204  93.59048 117.69072 103.19826  94.83803 #>  [57] 100.08120 108.81954 119.15510  85.23162 103.83925  99.22607 109.92254 #>  [64]  92.66711 102.46391 108.62512 102.93538 103.78512 101.40673 105.30224 #>  [71] 114.79813 102.88134 108.42450  98.82199 107.07486 109.63430 105.38478 #>  [78]  95.13129  96.01258 116.88485 102.94479 100.76935  93.30077  89.89977 #>  [85]  90.65092  93.12266  91.76308 104.91010  95.36140  95.45133  77.20147 #>  [92]  91.00006  96.47586 103.08095 102.79732  95.16230 109.32038 107.69312 #>  [99]  97.39382 110.75419 #>  #> $metrics #> $metrics$GEV #> [1] 0.09368644 #>  #> $metrics$GLO #> [1] 0.02331306 #>  #> $metrics$GNO #> [1] 0.06782938 #>  #> $metrics$PE3 #> [1] 0.07245138 #>  #> $metrics$LP3 #> [1] 0.08458052 #>  #> $metrics$WEI #> [1] 0.07170038 #>  #>  #> $recommendation #> [1] \"GLO\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":null,"dir":"Reference","previous_headings":"","what":"Z-Statistic Method for Distribution Selection — select_zstatistic","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"Selects best-fit distribution comparing bias-corrected Z-statistic sample L-kurtosis (\\(\\tau_4\\)) theoretical L-moments set candidate distributions. distribution smallest absolute Z-statistic selected.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"","code":"select_zstatistic(data, samples = 10000L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"list results distribution selection: method: \"Z-selection\". data: data argument. metrics: List computed Z-statistics candidate distribution. recommendation: Name distribution smallest Z-statistic. reg_params: Kappa distribution parameters data. reg_bias_t4: Bias L-kurtosis bootstrap. reg_std_t4: Standard deviation L-kurtosis bootstrap. log_params: Kappa distribution parameters log-transformed data. log_bias_t4: Bias L-kurtosis bootstrap (using log_params). log_std_t4: Standard deviation L-kurtosis bootstrap (using log_params).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"method performs distribution selection using raw log-transformed data. distributions use raw data GEV, GLO, PE3, GNO, WEI. LP3 distribution uses log-transformed data. Z-statistic determined fitting four-parameter Kappa distribution raw log-transformed data. , bootstrapped samples Kappa distribution L-moments bootstrapped samples used estimate Z-statistic distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_zstatistic(data) #> $method #> [1] \"Z-statistic\" #>  #> $data #>   [1]  98.71231  87.44428 113.74320  98.59197 100.22562 109.20876 103.82194 #>   [8]  81.06874 104.76641  84.67994  95.87834 111.43625 105.54843  90.80927 #>  [15] 100.60267  93.03966  76.63447  77.61610 101.04823  92.22512 100.13588 #>  [22]  94.33938 101.96622 102.67541  94.12358 118.53351  91.66731 100.00403 #>  [29]  87.55059  95.38149  92.23427 111.40751  90.37736  69.82771 111.86987 #>  [36] 100.98394 117.22366  94.35362  87.27311  97.95392  96.64070  84.96178 #>  [43] 105.77021  89.38498  98.61668  85.87479 103.87733 101.01316 103.84718 #>  [50] 101.98688  77.39291 100.08806 102.84134  87.52278 104.09981 116.37956 #>  [57] 108.31126 103.36415 106.11138 102.76687  86.39754 116.50380  90.10366 #>  [64]  97.54708  99.30036 105.50950 110.84722 111.69896 102.70129 108.29034 #>  [71]  77.88446  93.68704 113.97375  91.05490  82.25543 112.07571  98.65243 #>  [78] 106.26876 104.31282 103.00279 104.16331 106.77664 101.68825 110.02731 #>  [85] 106.10248  86.36331 130.44276  87.90837  89.36656  96.92901 105.06571 #>  [92]  94.63129  98.64158  99.61956 103.15962  91.79914 109.98052 106.22324 #>  [99]  95.16031 117.26171 #>  #> $metrics #> $metrics$GEV #> [1] -1.178528 #>  #> $metrics$GLO #> [1] 0.6907137 #>  #> $metrics$GNO #> [1] -0.5772312 #>  #> $metrics$PE3 #> [1] -0.6128178 #>  #> $metrics$LP3 #> [1] -0.6499557 #>  #> $metrics$WEI #> [1] -0.8519829 #>  #>  #> $recommendation #> [1] \"GNO\" #>  #> $reg_params #> [1] 98.1165044  7.7447346  0.1816291 -0.4521360 #>  #> $reg_bias_t4 #> [1] -0.0002260735 #>  #> $reg_std_t4 #> [1] 0.03484813 #>  #> $log_params #> [1]  4.58713119  0.07839819  0.24553311 -0.48295119 #>  #> $log_bias_t4 #> [1] 0.0001351028 #>  #> $log_std_t4 #> [1] 0.03832123 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/sumquad_tau3tau4.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","title":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","text":"Compute L-moment Distance Kappa Distribution","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/sumquad_tau3tau4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","text":"","code":"sumquad_tau3tau4(k.h, t3.t4)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"Computes return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using parametric bootstrap method. function supports variety probability models parameter estimation methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"","code":"uncertainty_bootstrap(   data,   distribution,   method,   prior = NULL,   years = NULL,   structure = NULL,   slices = 1900,   alpha = 0.05,   samples = 10000L,   periods = c(2, 5, 10, 20, 50, 100) )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". prior Numeric vector length 2. Specifies Beta prior shape parameters \\((p, q)\\) shape parameter \\(\\kappa\\). used distribution = \"GEV\". years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. slices Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. slices elements years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. samples Integer scalar. number bootstrap samples. Default 10000. periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"list containing following three items: method: \"Bootstrap\" structure: value structure argument. slices: list lists containing results slice. element slices list following five items: estimates: Estimated quantiles return period. ci_lower: Lower bound confidence interval return period. ci_upper: Upper bound confidence interval return period. periods: Vector return periods; defaults c(2, 5, 10, 20, 50, 100). year: year estimates computed (nonstationary models ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"bootstrap procedure samples fitted distribution via inverse transform sampling. bootstrapped sample, parameters re-estimated using method argument. , bootstrapped parameters used compute new set bootstrapped quantiles. Confidence intervals obtained empirical nonexceedance probabilities bootstrapped quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"parametric bootstrap known give unreasonably wide confidence intervals small datasets. function detects confidence interval 5+ times wider return levels , return error recommend RFPL uncertainty quantification (uncertainty_rfpl).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric Bootstrap Confidence Intervals for Flood Quantile Estimates — uncertainty_bootstrap","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) uncertainty_bootstrap(data, \"WEI\", \"L-moments\") #> $method #> [1] \"Bootstrap\" #>  #> $structure #> $structure$location #> [1] FALSE #>  #> $structure$scale #> [1] FALSE #>  #>  #> $slices #> $slices[[1]] #> $slices[[1]]$estimates #> [1]  97.93658 106.06081 110.12869 113.38419 116.93573 119.23883 #>  #> $slices[[1]]$ci_lower #> [1]  95.82566 103.85554 107.60610 110.39732 113.30335 115.08755 #>  #> $slices[[1]]$ci_upper #> [1] 100.0072 108.1946 112.6594 116.4664 120.8853 123.9460 #>  #> $slices[[1]]$periods #> [1]   2   5  10  20  50 100 #>  #> $slices[[1]]$year #> NULL #>  #>  #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":null,"dir":"Reference","previous_headings":"","what":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"Calculates return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using Regula-Falsi profile likelihood Regula-Falsi generalized profile likelihood root‐finding methods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"","code":"uncertainty_rfpl(   data,   distribution,   prior = NULL,   years = NULL,   structure = NULL,   slices = 1900,   alpha = 0.05,   eps = 0.01,   periods = c(2, 5, 10, 20, 50, 100) )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"data Numeric vector annual maximum series values. Must strictly positive, finite, missing. distribution Character scalar. three-character code indicating distribution family. Must one : \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". prior Numeric vector length 2. Specifies Beta prior shape parameters \\((p, q)\\) shape parameter \\(\\kappa\\). used distribution = \"GEV\". years Numeric vector observation years corresponding data. Must length data strictly increasing. structure Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. slices Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. slices elements years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. eps Numeric scalar. log-likelihood tolerance Regula-Falsi convergence (default 0.01). periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"list containing following three items: method: \"Bootstrap\" structure: value structure argument. slices: list lists containing results slice. element slices list following five items: estimates: Estimated quantiles return period. ci_lower: Lower bound confidence interval return period. ci_upper: Upper bound confidence interval return period. periods: Vector return periods; defaults c(2, 5, 10, 20, 50, 100). year: year estimates computed (nonstationary models ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"Fits distribution using fit_maximum_likelihood() obtain parameter estimates log‐likelihood. Defines objective function \\(f(y_p, p)\\) using reparameterized log-likelihood function. Iteratively brackets root rescaling initial guesses 0.05 \\(f(y_p, p)\\) changes sign. Uses Regula Falsi method solve \\(f(y_p, p) = 0\\) return-period probability. Returns lower upper confidence bounds significance level alpha given return level estimates.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"Although modern stats::optim() function preferred stats::nlminb(), use stats::nlminb() supports infinite values likelihood function. RFPL uncertainty quantification can numerically unstable datasets. function encounters issue, return error recommend using parametric bootstrap method (uncertainty_bootstrap) instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151 Vidrio-Sahagún, C.T., , J. & Pietroniro, . Multi-distribution regula-falsi profile likelihood method nonstationary hydrological frequency analysis. Stoch Environ Res Risk Assess 38, 843–867 (2024). doi:10.1007/s00477-023-02603-0","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Generalized) Regula-Falsi Confidence Intervals for Flood Quantile Estimates — uncertainty_rfpl","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_rfpl(data, \"GLO\") #> $method #> [1] \"RFPL\" #>  #> $structure #> $structure$location #> [1] FALSE #>  #> $structure$scale #> [1] FALSE #>  #>  #> $slices #> $slices[[1]] #> $slices[[1]]$estimates #> [1] 101.1298 108.5625 112.8805 116.8398 121.8331 125.5208 #>  #> $slices[[1]]$ci_lower #> [1]  99.25391 106.54348 110.45048 113.82004 117.79865 120.55549 #>  #> $slices[[1]]$ci_upper #> [1] 102.9703 110.9292 116.1821 121.4801 128.8411 134.7545 #>  #> $slices[[1]]$periods #> [1]   2   5  10  20  50 100 #>  #> $slices[[1]]$year #> NULL #>  #>  #>"}]
