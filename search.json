[{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU Affero General Public License","title":"GNU Affero General Public License","text":"Version 3, 19 November 2007 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU Affero General Public License","text":"GNU Affero General Public License free, copyleft license software kinds works, specifically designed ensure cooperation community case network server software. licenses software practical works designed take away freedom share change works. contrast, General Public Licenses intended guarantee freedom share change versions program–make sure remains free software users. speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. Developers use General Public Licenses protect rights two steps: (1) assert copyright software, (2) offer License gives legal permission copy, distribute /modify software. secondary benefit defending users’ freedom improvements made alternate versions program, receive widespread use, become available developers incorporate. Many developers free software heartened encouraged resulting cooperation. However, case software used network servers, result may fail come . GNU General Public License permits making modified version letting public access server without ever releasing source code public. GNU Affero General Public License designed specifically ensure , cases, modified source code becomes available community. requires operator network server provide source code modified version running users server. Therefore, public use modified version, publicly accessible server, gives public access source code modified version. older license, called Affero General Public License published Affero, designed accomplish similar goals. different license, version Affero GPL, Affero released new version Affero GPL permits relicensing license. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions.","title":"GNU Affero General Public License","text":"“License” refers version 3 GNU Affero General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code.","title":"GNU Affero General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions.","title":"GNU Affero General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law.","title":"GNU Affero General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies.","title":"GNU Affero General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions.","title":"GNU Affero General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: work must carry prominent notices stating modified , giving relevant date. work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms.","title":"GNU Affero General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms.","title":"GNU Affero General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: Disclaiming warranty limiting liability differently terms sections 15 16 License; Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; Limiting use publicity purposes names licensors authors material; Declining grant rights trademark law use trade names, trademarks, service marks; Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination.","title":"GNU Affero General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies.","title":"GNU Affero General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients.","title":"GNU Affero General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents.","title":"GNU Affero General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom.","title":"GNU Affero General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_13-remote-network-interaction-use-with-the-gnu-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Remote Network Interaction; Use with the GNU General Public License.","title":"GNU Affero General Public License","text":"Notwithstanding provision License, modify Program, modified version must prominently offer users interacting remotely computer network (version supports interaction) opportunity receive Corresponding Source version providing access Corresponding Source network server charge, standard customary means facilitating copying software. Corresponding Source shall include Corresponding Source work covered version 3 GNU General Public License incorporated pursuant following paragraph. Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU General Public License single combined work, convey resulting work. terms License continue apply part covered work, work combined remain governed version 3 GNU General Public License.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License.","title":"GNU Affero General Public License","text":"Free Software Foundation may publish revised /new versions GNU Affero General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU Affero General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU Affero General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU Affero General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty.","title":"GNU Affero General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability.","title":"GNU Affero General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16.","title":"GNU Affero General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://rileywheadon.github.io/ffa-package/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU Affero General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. software can interact users remotely computer network, also make sure provides way users get source. example, program web application, interface display “Source” link leads users archive code. many ways offer source, different solutions better different programs; see section 13 specific requirements. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU AGPL, see https://www.gnu.org/licenses/.","code":"<one line to give the program's name and a brief idea of what it does.>     Copyright (C) <year>  <name of author>      This program is free software: you can redistribute it and/or modify     it under the terms of the GNU Affero General Public License as     published by the Free Software Foundation, either version 3 of the     License, or (at your option) any later version.      This program is distributed in the hope that it will be useful,     but WITHOUT ANY WARRANTY; without even the implied warranty of     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the     GNU Affero General Public License for more details.      You should have received a copy of the GNU Affero General Public License     along with this program.  If not, see <https://www.gnu.org/licenses/>."},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Change Point Detection","text":"vignette explore Kootenai River Porthill (08NH021) station, located border British Columbia Idaho. station located downstream Libby Dam, finished construction 1972. Data station provided CAN-08NH021.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-08NH021.csv\") head(df) #>   year  max #> 1 1928 2350 #> 2 1929 1680 #> 3 1930 1730 #> 4 1931 1470 #> 5 1932 2190 #> 6 1933 2640  plot_ams_data(df$max, df$year, title = \"Kootenai River at Porthill (08NH021)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"the-pettitt-test","dir":"Articles","previous_headings":"","what":"The Pettitt Test","title":"Change Point Detection","text":"rank-based test detects single abrupt change median time series. null hypothesis assumes change point. Use eda_pettitt_test function perform test. requires two arguments: data: annual maximum series (AMS) years: corresponding numeric vector years  Conclusion: p-value <0.001 provides strong evidence change point year 1972.","code":"pettitt_test <- eda_pettitt_test(df$max, df$year)  print(pettitt_test$p_value) #> [1] 0  print(pettitt_test$change_year) #> NULL  plot_pettitt_test(pettitt_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"the-mks-test","dir":"Articles","previous_headings":"","what":"The MKS Test","title":"Change Point Detection","text":"Mann-Kendall-Sneyers (MKS) test identifies trend changes data. Use eda_mks_test arguments .  Conclusion: p-value 0.015, evidence trend changes 1960 1985. Note: Since MKS test can identify multiple change points, reported p-value determined using significant change point.","code":"mks_test <- eda_mks_test(df$max, df$year)  print(mks_test$p_value) #> [1] 0.01495225  print(mks_test$change_df$year) #> NULL  plot_mks_test(mks_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/change-points.html","id":"interpreting-and-selecting-change-points","dir":"Articles","previous_headings":"","what":"Interpreting and Selecting Change Points","title":"Change Point Detection","text":"example, Pettitt MKS tests suggest structural changes time series. Consider following guidelines choosing split data: Incorporate domain knowledge case-specific understanding. example, know water regulation structure built 1972 (Libby dam). supports results Pettitt test. Avoid overpartitioning. Pettitt MKS tests operate independently may detect multiple change points. minimize sample size issues reduce uncertainty, retain significant change points physical justification. Prioritize based p-value. Lower p-values indicate stronger evidence given weight.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"change-point-detection","dir":"Articles","previous_headings":"","what":"Change Point Detection","title":"Change Point Detection","text":"EDA module FFA Framework includes two statistical tests detecting change points annual maximum series data: Mann-Kendall-Sneyers (MKS) test Pettitt test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"mann-kendall-sneyers-test","dir":"Articles","previous_headings":"Change Point Detection","what":"Mann-Kendall-Sneyers Test","title":"Change Point Detection","text":"Mann-Kendall-Sneyers (MKS) test detects trend change time series: Null hypothesis: change points. Alternative hypothesis: one change points. Define \\(\\mathbb{}(y_{} > y_{j})\\) \\(1\\) \\(y_{} > y_{j}\\) \\(0\\) otherwise. Given time series \\(y_{1}, \\dots, y_{n}\\), compute progressive series \\(S^{F}_{t}\\): \\[ S^{F}_{t} = \\sum_{=}^{t} \\sum_{j=1}^{-1} \\mathbb{}(y_{} > y_{j}) \\] Next, reverse time series \\(y\\). gives us new time series \\(y'\\) \\(y_{}' = y_{n+1-}\\). compute regressive series \\(S^{B}_{t}\\), \\(\\text{rev}()\\) indicates vector reversed: \\[ S^{B}_{t} = \\text{rev}\\left( \\sum_{=}^{t} \\sum_{j=1}^{-1} \\mathbb{}(y'_{} > y'_{j})\\right) \\] , compute normalized progressive series \\(UF_{t}\\) normalized regressive series \\(UB_{t}\\): \\[ UF_{t} = \\frac{S^{F}_{t} - \\mathbb{E}[S^{F}_{t}]}{\\sqrt{\\text{Var}\\,(S^{F}_{t})}}, \\quad UB_{t} = \\frac{S^{B}_{t} - \\mathbb{E}[S^{B}_{t}]}{\\sqrt{\\text{Var}\\,(S^{B}_{t})}} \\] progressive regressive series, expectation variance follows: \\[ \\mathbb{E}[S^{F}_{t}] = \\mathbb{E}[S^{B}_{t}] = \\frac{t(t-1)}{4}, \\quad \\text{Var}(S^{F}_{t}) = \\text{Var}(S^{B}_{t}) = \\frac{t(t-1)(2t+5)}{72} \\] Finally, plot \\(UF_{t}\\) \\(UB_{t}\\) confidence bounds \\(\\alpha/2\\) \\(1 - (\\alpha /2)\\) quantiles standard normal distribution, \\(\\alpha\\) chosen significance level. crossing point \\(UF_{t}\\) \\(UB_{t}\\) lies outside confidence bounds potential change point.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-change-points.html","id":"pettitt-test","dir":"Articles","previous_headings":"Change Point Detection","what":"Pettitt Test","title":"Change Point Detection","text":"Pettitt test detects abrupt changes mean time series. Null hypothesis: abrupt changes. Alternative hypothesis: one abrupt change. Define \\(\\text{sign}(x)\\) \\(1\\) \\(x > 0\\), \\(0\\) \\(x = 0\\), \\(-1\\) otherwise. Given time series \\(y_{1}, \\dots, y_{n}\\), compute following test statistic: \\[ U_{t} = \\sum_{=1}^{t} \\sum_{j=t+1}^{n} \\text{sign} (y_{j} - y_{}), \\quad K = \\max_{t}|U_{t}| \\] value \\(t\\) \\(U_{t} = K\\) potential change point. p-value potential change point can approximated using following formula one-sided test: \\[ p \\approx \\exp \\left(-\\frac{6K^2}{n^3 + n^2}\\right) \\] p-value less significance level \\(\\alpha\\), reject null hypothesis conclude evidence abrupt change mean potential change point.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"introduction-to-exploratory-data-analysis-eda","dir":"Articles","previous_headings":"","what":"Introduction to Exploratory Data Analysis (EDA)","title":"","text":"EDA module FFA Framework used evaluate whether available evidence supports assumption stationarity. , EDA module applies structured sequence statistical tests data detect statistically significant nonstationary signatures. statistical tests serve three purposes: Detect change points (.e., abrupt shifts trend changes). Detect trends mean identify deterministic/stochastic, linear/non-linear. Detect trends variability (.e., heteroskedasticity trends standard deviation). primary goal EDA inform choice stationary nonstationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"stationary-and-nonstationary-ffa","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA)","what":"Stationary and Nonstationary FFA","title":"","text":"Prior performing FFA, necessary choose stationary (S-FFA) nonstationary (NS-FFA) approach. using S-FFA, assumed time series independent identically distributed. Evidence change point(s) /time dependence violates assumptions stationarity indicates NS-FFA may necessary.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"identifying-change-points","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA) > The EDA Workflow","what":"Identifying Change Points","title":"","text":"change point abrupt shift (jump) temporal pattern switch (trend change) time series. Change points indicate inhomogeneous periods (nonstationarity), meaning single model may represent entire record adequately. Instead, piecewise analysis applied homogeneous subperiod. Pettitt test MKS test used identify abrupt shifts temporal pattern switches respectively. However, statistically significant result one tests conclusively identify change point. Type 1 errors issues data quality can cause Pettitt MKS tests identify spurious change points, type 2 errors can cause true change points go unnoticed. Therefore, always important use station-specific knowledge addition results tests.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-introduction.html","id":"identifying-time-dependence","dir":"Articles","previous_headings":"Introduction to Exploratory Data Analysis (EDA) > The EDA Workflow","what":"Identifying Time Dependence","title":"","text":"many types time dependence, FFA framework focuses identifying linear trends mean /variability using two groups statistical tests. Identifying trends mean: First, Mann-Kendall test used identify evidence linear trend mean. trend identified, Spearman test used check evidence autocorrelation, known cause issues Mann-Kendall test. autocorrelation identified, BB-MK test used place Mann-Kendall test identify linear trend mean. Finally, trend identified, PP KPSS tests used check trend deterministic stochastic. Identifying trends variability: variability time series can estimated computing sample standard deviation sequential subsets data (moving window). MW-MK test applies Mann-Kendall test variability time series identify linear trend. White test also used identify general time-dependence (e.g. nonlinear trends) variability. Trend estimation: Sen’s trend estimator robust, nonparametric estimator used estimate linear trend. can applied trends mean variability. linear trend estimated, fit can assessed using runs test, checks randomness residuals. residuals non-random, linear trend may suitable data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"detecting-and-characterizing-trends-in-the-mean","dir":"Articles","previous_headings":"","what":"Detecting and Characterizing Trends in the Mean","title":"","text":"section describes statistical tests (listed alphabetical order) used detect characterize significant trends mean annual maximum series. tests help identify trend, identify autocorrelation, determine whether trend deterministic/stochastic linear/non-linear.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"bb-mk-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"BB-MK Test","title":"","text":"Block Bootstrap Mann-Kendall (BB-MK) Test assesses presence statistically significant monotonic trend time series. BB-MK test insensitive autocorrelation, known produce false positives MK test. Null hypothesis: monotonic trend. Alternative hypothesis: monotonic upward downward trend exists. conduct BB-MK test, rely results MK test Spearman autocorrelation test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > BB-MK Test","what":"Steps","title":"","text":"Compute MK test statistic (see ). Use Spearman test (see ) identify least insignificant lag \\(k\\). Resample time series blocks size \\(k+1\\) without replacement. Compute MK test statistic bootstrapped sample. Derive empirical distribution MK test statistic bootstrapped statistics. Estimate significance observed test statistic using empirical distribution.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"kpss-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"KPSS Test","title":"","text":"KPSS Test determines whether autoregressive time series unit root. test helps assess time series deterministic linear trend. Null hypothesis: time series deterministic linear trend. Alternative hypothesis: time series unit root (stochastic trend). autoregressive time series shown unit root \\(\\sigma_{v}^2 > 0\\): \\[ \\begin{align} y_{t} &= \\mu_{t} + \\beta t +  \\epsilon_{t} \\\\[5pt] \\mu_{t} &= \\mu_{t-1} + v_{t} \\\\[5pt] v_{t} &\\sim \\mathcal{N}(0, \\sigma_{v}^2) \\end{align} \\] : \\(\\mu_{t}\\) drift, deviation \\(y_{t}\\) \\(0\\). null hypothesis, \\(\\mu_{t}\\) constant (since \\(v_{t}\\) constant). alternative hypothesis, \\(\\mu_t\\) stochastic process unit root. \\(\\beta t\\) linear trend, represents deterministic nonstationarity (e.g., climate change). \\(\\epsilon_{t}\\) stationary noise, corresponding reversible fluctuations \\(y_{t}\\). hydrology, \\(\\epsilon_{t}\\) represents fluctuations streamflow due natural variability. \\(v_{t}\\) random walk innovation, irreversible fluctuations \\(\\mu_{t}\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-1","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > KPSS Test","what":"Steps","title":"","text":"Fit linear model \\(y_{t}\\) get residuals \\(\\hat{r}_{t}\\). Compute cumulative partial-sum statistics \\(S_{k}\\) using following formula: \\[ S_{k} = \\sum_{t=1}^{k} \\hat{r}_{t} \\] null hypothesis, \\(S_{k}\\) behave like random walk finite variance. \\(y_{t}\\) unit root, sums “drift” much. Estimate long-run variance time series using Newey-West estimator: \\[ \\hat{\\lambda}^2 = \\hat{\\gamma}_0 + 2 \\sum_{j=1}^{q} \\left(1 - \\frac{j}{q+1} \\right) \\hat{\\gamma}_j \\] \\(q = \\left\\lfloor \\frac{3\\sqrt{n}}{13} \\right\\rfloor\\) autocovariance \\(\\hat{\\gamma}_j\\) : \\[ \\hat{\\gamma}_j = \\frac{1}{n} \\sum_{t = j+1}^{n} \\hat{r}_t \\hat{r}_{t-j} \\] Compute test statistic \\(z_{K}\\): \\[ z_{K} = \\frac{1}{n^2\\hat{\\lambda }^2}\\sum_{k=1}^{n}  S_{k}^2 \\] Since test statistic \\(z_{K}\\) non-normally distributed, compute p-value interpolating table quantiles Hobijn et al. (2004) shown . Warning: interpolation works \\(0.01 < p < 0.10\\) (p-values \\(0.01\\) \\(0.10\\) truncated) significance levels \\(\\alpha\\) \\(0.01\\) \\(0.10\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"mann-kendall-mk-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Mann-Kendall (MK) Test","title":"","text":"Mann-Kendall (MK) Test detects statistically significant monotonic trends time series assumption independence (.e. autocorrelation). Null hypothesis: monotonic trend. Alternative hypothesis: (upward downward) monotonic trend exists. Define \\(\\text{sign} (x)\\) \\(1\\) \\(x > 0\\), \\(0\\) \\(x = 0\\), \\(-1\\) otherwise. test statistic \\(S\\) defined follows: \\[ S = \\sum_{k-1}^{n-1}  \\sum_{j - k + 1}^{n} \\text{sign} (y_{j} - y_{k}) \\] Next, need compute \\(\\text{Var}(S)\\), depends number tied groups data. Let \\(g\\) number tied groups \\(t_{p}\\) number observations \\(p\\)-th group. \\[\\text{Var}(S) = \\frac{1}{18} \\left[n(n-1)(2n + 1) - \\sum_{p-1}^{g} t_{p}(t_{p} - 1)(2t_{p} + 5) \\right]\\] , compute normally distributed test statistic \\(Z_{MK}\\) follows: \\[ Z_{MK} = \\begin{cases} \\frac{S-1}{\\sqrt{\\text{Var}(S)}} &\\text{} S > 0 \\\\ 0 &\\text{}  S = 0 \\\\ \\frac{S+1}{\\sqrt{\\text{Var}(S)}} &\\text{} S < 0 \\end{cases} \\] two-sided test, reject null hypothesis \\(|Z_{MK}| \\geq Z_{1 - (\\alpha/2) }\\) conclude statistically significant monotonic trend data. information, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"phillips-perron-pp-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Phillips-Perron (PP) Test","title":"","text":"PP Test identifies autoregressive time series unit root. Null hypothesis: time series unit root (stochastic trend). Alternative hypothesis: time series deterministic linear trend. Precisely, let \\(x_{t}\\) AR(1) model. Let \\(y_{t}\\) function \\(x_{t}\\) drift \\(\\beta_{0}\\) trend \\(\\beta_{1} t\\). \\[ \\begin{align} y_{t} &= \\beta_{0} + \\beta_{1} t + x_{t} \\\\[5pt] x_{t} &= \\rho x_{t-1} + \\epsilon_{t} \\end{align} \\] \\(\\rho = 1\\), \\(x_t\\) hence \\(y_t\\) unit root (null hypothesis). \\(\\rho < 1\\), \\(y_t\\) trend stationary (alternative hypothesis).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-2","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Phillips-Perron (PP) Test","what":"Steps","title":"","text":"Fit linear autoregressive model time series \\(y_{t}\\). Let \\(\\hat{r}_{t}\\) residuals model. model, can determine \\(\\hat{\\rho}\\) (estimated coefficient \\(y_{t-1}\\)) \\(\\text{SE}(\\hat{\\rho})\\). Estimate variance residuals \\(\\hat{\\sigma}^2\\): \\[ \\hat{\\sigma^2} = \\frac{1}{n - 3} \\sum_{t=1}^{n} \\hat{r}_{t}^2 \\] \\(n\\) number data points sample. \\(n-3\\) degrees freedom since three parameters autoregressive model (\\(\\beta_{0}\\), \\(\\beta_{1}\\), \\(\\rho\\)). Estimate long-run variance \\(\\hat{\\lambda}^2\\) using Newey-West style estimator. estimator corrects additional variability \\(\\epsilon_{t}\\) caused autocorrelation heteroskedasticity. \\[ \\hat{\\lambda}^2 = \\hat{\\gamma}_{0} + 2\\sum_{j=1}^{q} \\left(1 - \\frac{j}{q + 1} \\right)  \\gamma_{j} \\] sample autocovariances \\(\\gamma_{j}\\) computed \\(q = \\left\\lfloor \\sqrt[4]{\\frac{n}{25}}\\right\\rfloor\\) lags: \\[ \\hat{\\gamma}_{j} = \\frac{1}{n} \\sum_{t = j + 1}^{n} \\hat{r}_{t}\\hat{r}_{t-j} \\] Compute test statistic \\(z_{\\rho}\\) using following formula: \\[ z_{\\rho } = n(\\hat{\\rho} - 1) - \\frac{n^2 \\text{SE}(\\hat{\\rho})^2}{2 \\hat{\\sigma}^2}(\\hat{\\lambda }^2 - \\hat{\\gamma}_{0}) \\] test statistic \\(z_{\\rho}\\) normally distributed. Instead, compute p-value interpolating table Fuller, W. . (1996). table shown sample sizes \\(n\\) probabilities \\(p\\): Warning: interpolation works p-values \\(p > 0.01\\) (p-values \\(0.01\\) truncated) confidence levels \\(\\alpha > 0.01\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"runs-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Runs Test","title":"","text":"Runs Test checks whether residuals regression (e.g., trend approximation Sen’s estimator) randomly distributed. Runs test identifies non-randomness residuals, strong indication nonstationarity data non-linear. Null hypothesis: Residuals distributed randomly. Alternative hypothesis: Residuals distributed randomly (e.g., due nonlinearity).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-3","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Runs Test","what":"Steps","title":"","text":"Classify data based whether (\\(+\\)) \\((-)\\) median. data points equal median removed. Compute number contiguous blocks \\(+\\) \\(-\\) (known runs) data. example, sequence \\(+++--+++-+-\\) six runs length \\((3, 2, 3, 1, 1, 1)\\). Let \\(R\\) number runs \\(N\\) data points (category counts \\(N_{+}\\) \\(N_{-}\\)). , null hypothesis, \\(R\\) asymptotically normal : \\[ \\mathbb{E}[R] = \\frac{2N_{+}N_{-}}{N} + 1, \\quad \\text{Var}(R) = \\frac{2N_{+}N_{-}(2N_{+}N_{-} - N)}{N^2(N - 1)} \\] Compute p-value normalizing \\(R\\) using expectation variance given .","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Sen’s Trend Estimator","title":"","text":"Sen’s Trend Estimator approximates slope regression line. Unlike Least Squares, Sen’s trend estimator uses non-parametric approach makes robust outliers.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"steps-4","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean > Sen’s Trend Estimator","what":"Steps","title":"","text":"pairs \\((x_i, y_i)\\) \\((x_j, y_j)\\) \\(x_i \\neq x_j\\), compute slopes: \\[ m_{ij} = \\frac{y_j - y_i}{x_j - x_i} \\] Take median slopes: \\(\\hat{m}\\). Estimate \\(y\\)-intercept \\(\\hat{b}\\) median \\(y_{} - \\hat{m}x_{}\\) \\(\\).","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-mean.html","id":"spearman-test","dir":"Articles","previous_headings":"Detecting and Characterizing Trends in the Mean","what":"Spearman Test","title":"","text":"Spearman test identifies autocorrelation time series \\(y_{t}\\). significant lag number \\(\\) correlation \\(y_{t}\\) \\(y_{t-}\\) statistically significant. least insignificant lag smallest \\(\\) significant lag. Null hypothesis: least insignificant lag \\(1\\). Alternative hypothesis: least insignificant lag greater \\(1\\). carry Spearman test, use following procedure: Compute Spearman’s correlation coefficient \\(\\rho_{}\\) \\(y_{t}\\) \\(y_{t-}\\) \\(0 \\leq  <  n\\). Compute \\(p\\)-value \\(p_{}\\) correlation coefficient \\(\\rho _{}\\) using formula: \\[ t_{}= \\rho_{} \\sqrt{\\frac{n-2}{1 - \\rho _{}^2}} \\] test statistic \\(t_{}\\) \\(t\\)-distribution \\(n-2\\) degrees freedom. Find smallest \\(\\) \\(p_{} > \\alpha\\). \\(\\) least insignificant lag confidence level \\(\\alpha\\). information, see Wikipedia pages Autocorrelation Spearman’s Rho.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"detecting-trends-in-the-variability","dir":"Articles","previous_headings":"","what":"Detecting Trends in the Variability","title":"","text":"section describes methods used detect trends changes variability (e.g., variance standard deviation) annual maximum series data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"moving-window-mann-kendall-mw-mk-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Moving Window Mann-Kendall (MW-MK) Test","title":"","text":"MW-MK test detects statistically significant monotonic trends standard deviation data. Null hypothesis: significant trend standard deviation. Alternative hypothesis: Significant monotonic trend standard deviation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"steps","dir":"Articles","previous_headings":"Detecting Trends in the Variability > Moving Window Mann-Kendall (MW-MK) Test","what":"Steps","title":"","text":"compute standard deviations data, use moving window algorithm. Let \\(w\\) length moving window \\(s\\) step size. , Initialize moving window indices \\([1, w]\\). Compute sample standard deviation within window. Move window forward \\(s\\) steps. Repeat steps 2 3 window reaches end data. produces time series moving-window standard deviations. , Mann-Kendall Test used test monotonic trend standard deviation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Sen’s Trend Estimator","title":"","text":"Used estimate slope trend standard deviations (see ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"runs-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"Runs Test","title":"","text":"Used check residuals trend fitted standard deviations randomness (see ).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"white-test","dir":"Articles","previous_headings":"Detecting Trends in the Variability","what":"White Test","title":"","text":"White Test detects changes variability (heteroskedasticity) time series. Null hypothesis: Constant variability (homoskedasticity). Alternative hypothesis: Time-dependent variability (heteroskedasticity).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/eda-trend-ams-variability.html","id":"steps-1","dir":"Articles","previous_headings":"Detecting Trends in the Variability > White Test","what":"Steps","title":"","text":"Fit simple linear regression model using ordinary least squares: \\[y_{} = \\beta_{0} + \\beta_{1} x_{} + \\epsilon_{}\\] Compute squared residuals: \\[ \\hat{r}_i^2 = \\left(y_i - \\hat{y}_i\\right)^2 \\] Fit auxiliary regression model squared residuals. model includes regressor, square regressor, cross products regressors. Since \\(x\\) regressor, regression model simply: \\[ \\hat{r}_i^2 = \\alpha_0 + \\alpha_1 x_i + \\alpha_2 x_i^2 + u_i \\] Compute coefficient determination \\(R^2\\) auxiliary model. Compute test statistic \\(nR^2 \\sim \\chi_{d}^2\\) \\(n\\) number observations \\(d = 2\\) number regressors, excluding intercept. \\(nR^2 > \\chi^2_{1-\\alpha, d}\\), reject null hypothesis conclude time series exhibits heteroskedasticity.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"overview","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA)","what":"Overview","title":"","text":"Flood Frequency Analysis (FFA) uses probability distribution fitted extreme streamflow observations (e.g., annual maxima) estimate recurrence likelihood floods. perform FFA, require probability model corresponding parameter estimates based data. FFA relates flood peak magnitudes \\(Q\\) expected frequency occurrence, expressed return period. example, flood 10-year return period—commonly referred 10-year flood—1--10 chance equaled exceeded given year. corresponds annual exceedance probability \\(p_e = 0.1\\). Since FFA Framework uses annual maxima data, equates 90th percentile (.e., \\(0.90\\) quantile) fitted probability distribution. summary return periods, exceedance probabilities, associated quantiles used default FFA framework: Let \\(F(q)\\) cumulative distribution function (CDF) fitted model. function maps flood magnitudes exceedance probabilities: \\(p_e = 1 - F(q)\\). estimate flood magnitudes given exceedance probability, use inverse CDF, better known quantile function: \\(\\hat{q} = F^{-1}(p_e)\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"example-plot","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA) > Overview","what":"Example Plot","title":"","text":"FFA results typically visualized return period \\(x\\)-axis flood magnitude \\(y\\)-axis. plots can interpreted two directions: Estimate flood magnitude given return period. example, 50-year flood estimated \\(85\\ \\text{m}^3/\\text{s}\\). Estimate return period given flood magnitude. example, streamflow \\(50\\ \\text{m}^3/\\text{s}\\) expected occur roughly every 4 years. Note: explanation confidence bounds plot, see Uncertainty Quantification.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA)","what":"Handling Nonstationarity","title":"","text":"probability model considered nonstationary statistical properties (e.g., location scale) change time. cases, quantile function becomes time-dependent: \\(F^{-1}(p_e, t)\\). result, return levels exceedance probabilities vary time, static return period curve longer valid. address , FFA framework computes effective return periods, yield flood estimates specific year based time-varying distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-introduction.html","id":"example-plot-1","dir":"Articles","previous_headings":"Flood Frequency Analysis (FFA) > Handling Nonstationarity","what":"Example Plot","title":"","text":"plot illustrates effective return levels years 1920, 1960, 2000. Remember, 100-year effective return level imply flood expected occur next 100 years. Instead, means given year, probability exceeding effective return level 1 100.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"nonparametric-models","dir":"Articles","previous_headings":"Model Assessment","what":"Nonparametric Models","title":"","text":"Plotting Position non-parametric estimator exceedance probabilities. using plotting position, can evaluate quality stationary parametric model. compute plotting position, arrange sample observations descending order magnitude: \\(x_{n:n} \\geq \\dots \\geq x_{1:n}\\). , exceedance probabilities given following formula: \\[ p_{:n} = \\frac{-}{n+1 - 2a}, \\quad \\\\{1, \\dots , n\\} \\] coefficient \\(\\) depends plotting position formula: default, FFA framework uses Weibull formula, unbiased.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"r2---coefficient-of-determination","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"\\(R^2\\) - Coefficient of Determination","title":"","text":"compute \\(R^2\\) statistic, perform linear regression annual maximum series data predictions parametric model plotting positions. \\(R^2\\) statistic describes well parametric model captures variance data. Higher better. plot shows deviation model (red dots), data (black line).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"rmse---root-mean-squared-error","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"RMSE - Root-Mean Squared Error","title":"","text":"RMSE statistic describes average squared difference data predictions parametric model. Lower better.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"bias","dir":"Articles","previous_headings":"Model Assessment > Accuracy Statistics","what":"Bias","title":"","text":"Bias statistic describes average difference data predictions parametric model. positive bias indicates model tends overestimate data negative bias indicates model tends underestimate data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"information-criterion","dir":"Articles","previous_headings":"Model Assessment","what":"Information Criterion","title":"","text":"Akaike Information Criterion (AIC) Bayesian Information Criterion (BIC) describe quality model based error (RMSE) number parameters (n_theta). Better models lower AIC/BIC, indicates less parameters lower error. Akaike/Bayesian information criterion can also computed using maximum log-likelihood maximum likelihood estimation. statistics reported AIC_MLL BIC_MLL.","code":"AIC <- (n * log(RMSE)) + (2 * n_theta) BIC <- (n * log(RMSE)) + (log(n) * n_theta) AIC_MLL <- (n * log(MLL)) + (2 * n_theta) BIC_MLL <- (n * log(MLL)) + (log(n) * n_theta)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"uncertainty-statistics","dir":"Articles","previous_headings":"Model Assessment","what":"Uncertainty Statistics","title":"","text":"FFA framework uses three statistics assess uncertainty flood quantile estimates: AW captures precision (narrower confidence intervals better). POC captures reliability (higher coverage observations better). CWI composite measure balancing precision reliability (lower better). use metrics together evaluate robustness flood frequency analysis.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"aw-average-width","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"AW – Average Width","title":"","text":"AW average width interpolated confidence intervals across return periods interest. smaller AW indicates precise quantile estimates. compute AW, use log-linear interpolation estimate confidence intervals exceedance probabilities confidence intervals computed uncertainty quantification.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"poc-percent-of-coverage","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"POC – Percent of Coverage","title":"","text":"POC percentage data points fall within corresponding confidence intervals. higher POC indicates greater reliability confidence intervals.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"cwi-confidence-width-indicator","dir":"Articles","previous_headings":"Model Assessment > Uncertainty Statistics","what":"CWI – Confidence Width Indicator","title":"","text":"CWI composite metric penalizes wide /poorly calibrated confidence intervals. lower CWI better. Wide intervals low coverage increase penalty. Ideal confidence intervals narrow well-calibrated, resulting low CWI. CWI computed using following formula, alpha significance level.","code":"CWI <- AW * exp((1 - alpha) - POC / 100)^2"},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-assessment.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Model Assessment","what":"Handling Nonstationarity","title":"","text":"working nonstationary models, adjustments must made empirical quantiles (derived plotting positions) theoretical quantiles. FFA framework, perform nonstationary model assessment standardizing quantiles based selected distribution family. Standardizing theoretical quantiles: Get nonexceedance probabilities \\(p_{(1)} \\leq \\dots \\leq p_{(n)}\\) using plotting position formula. Compute normalized theoretical quantiles \\(z^{T}_{} = \\Phi^{-1}(p_{()})\\). Standardizing empirical quantiles: Transform observation \\(x_{}\\) model-based probability \\(u_{}\\): \\[ u_i = F(x_i \\,;\\, \\mu(t_i), \\sigma(t_i), \\kappa) \\] Normalize model-based probabilities: \\[ z_{} = \\Phi^{-1}(u_{}) \\] Sort normalized empirical quantiles: \\(z^{E}_{(1)} \\leq \\dots \\leq z^{E}_{(n)}\\). , can plot \\((z_{}^{T}, z_{}^{E})\\) pairs normalized Q-Q plot. Alternatively, can use detrended Q-Q plot (also known worm plot), plots theoretical quantiles \\(z_{}^{T}\\) differences \\(\\Delta_{} = z_{}^{E} - z_{}^{T}\\). model accurately captures true distribution data, : \\[ \\text{SE}(\\Delta_{})= \\frac{1}{f(z_{}^{T})} \\sqrt{\\frac{p_{()}(1 - p_{()})}{n}} \\] can use formula plot 95% confidence interval \\(\\pm 1.96 \\cdot \\text{SE}(\\Delta _{})\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"model-selection","dir":"Articles","previous_headings":"","what":"Model Selection","title":"","text":"module selects statistical model S-FFA NS-FFA based annual maximum series. S-FFA: time-invariant probability distribution selected candidate distributions. NS-FFA: distribution chosen along nonstationary structure capture evolution time. piecewise NS-FFA, series segmented subperiods, modeled either time-invariant time-varying distributions. framework uses L-moment ratio method identify best-fit distribution family comparing sample L-moments L-moments various distribution families. NS-FFA, series decomposed isolate stationary component following Vidrio-Sahagún (2022). decomposed sample used distribution selection, S-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"an-introduction-to-l-moments","dir":"Articles","previous_headings":"Model Selection","what":"An Introduction to L-Moments","title":"","text":"Definition 1: \\(k\\)-th Order Statistic statistical sample \\(k\\)-th smallest value. Definition 2: \\(r\\)-th Population L-moment \\(\\lambda_{r}\\) linear combination expectation order statistics. Let \\(X_{k:n}\\) \\(k\\)-th order statistic sample size \\(n\\). , \\[ \\lambda_{r} = \\frac{1}{r} \\sum_{k=0}^{r-1} (-1)^{k} \\binom{r-1}{k} \\mathbb{E}[X_{r-k:r}] \\] Definition 3: Probability Weighted Moment (PWM) encodes information value’s position cumulative distribution function. \\(r\\)-th PWM, denoted \\(\\beta_{r}\\), : \\[ \\beta_{r} = \\mathbb{E}[X \\cdot  F(X)^{r}] \\] ordered sample \\(x_{1:n} \\leq  \\dots  \\leq  x_{n:n}\\), sample PWM often estimated : \\[ b_{r} = \\frac{1}{n} \\sum_{=1}^{r} x_{:n} \\left(\\frac{-1}{n-1}\\right) ^{r} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"sample-l-moments-from-pwms-and-l-moment-ratios","dir":"Articles","previous_headings":"Model Selection > An Introduction to L-Moments","what":"Sample L-Moments (from PWMs) and L-Moment Ratios","title":"","text":"first four sample L-moments can computed linear combinations PWMs: \\[ \\begin{aligned} l_{1} &= b_{0} \\\\ l_{2} &= 2b_{1} - b_{0} \\\\ l_{3} &= 6b_{2} - 6b_{1} + b_{0} \\\\ l_{4} &= 20b_{3} - 30b_{2} + 12b_{1} - b_{0} \\end{aligned} \\] L-moments used compute Sample L-variance \\(t_{2}\\), Sample L-skewness \\(t_{3}\\) Sample L-kurtosis \\(t_{4}\\) using following formulas: \\[ \\begin{aligned} t_{2} &= l_{2} / l_{1} \\\\ t_{3} &= l_{3} / l_{2} \\\\ t_{4} &= l_{4} / l_{2} \\end{aligned} \\] , compare statistics, specifically L-skewness L-kurtosis theoretical values (given ) using one three different metrics select distribution. Note: Probability distributions two parameters constant L-skewness \\(\\tau_{3}\\) L-kurtosis \\(\\tau_{4}\\) regardless parameters. L-skewness L-kurtosis probability distributions three parameters function shape parameter \\(\\kappa\\). notation \\(\\tau_{3}(\\kappa)\\) \\(\\tau_{4}(\\kappa)\\) refers L-skewness L-kurtosis curves three parameter distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"example-plot","dir":"Articles","previous_headings":"Model Selection > An Introduction to L-Moments","what":"Example Plot","title":"","text":"Shown L-moment curves GEV, GLO, GNO, PE3/LP3, WEI distributions well L-moment ratios two parameter distributions GUM /LNO. L-moment diagram depicts “L-distance” selection metric, compares euclidian distance sample theoretical L-moment ratios. inset shows GEV distribution (yellow line) closest L-moments data.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"l-distance","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"1. L-Distance","title":"","text":"Euclidean distance sample \\((t_3, t_4)\\) theoretical \\((\\tau_3, \\tau_4)\\) candidate distribution. 3-parameter distributions, minimum distance along L-moment ratio curve.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"l-kurtosis","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"2. L-Kurtosis","title":"","text":"L-kurtosis method used three-parameter probability distributions. First, shape parameter \\(\\kappa^{*}\\) \\(t_{3} = \\tau _{3}(\\kappa ^{*})\\) identified. , difference sample L-kurtosis theoretical L-kurtosis computed using metric \\(|\\tau_{4}(\\kappa ^{*}) - t_{4} |\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"z-statistic","dir":"Articles","previous_headings":"Model Selection > Selection Metrics","what":"3. Z-statistic","title":"","text":"Z-statistic selection metric calculated follows (three-parameter distributions): Fit four-parameter Kappa (K4D) distribution sample. Generate \\(N_{\\text{sim}}\\) bootstrap samples fitted K4D distribution. Calculate sample L-kurtosis \\(t_{4}^{[]}\\) synthetic dataset. Calculate bias standard deviation bootstrap distribution: \\[ B_{4} = N_{\\text{sim} }^{-1} \\sum_{= 1}^{N_{\\text{sim} }} \\left(t_{4}^{[]} - t_{4}^{s}\\right) \\] \\[ \\sigma _{4} = \\left[(N_{\\text{sim} } - 1)^{-1} \\left\\{\\sum_{- 1}^{N_{\\text{sim} }} \\left(t_{4}^{[]} - t_{4}^{s}\\right)^2 - N_{\\text{sim} } B_{4}^2\\right\\} \\right] ^{\\frac{1}{2}} \\] Identify shape parameter \\(\\kappa^{*}\\) \\(t_{3} = \\tau _{3}(\\kappa ^{*})\\). Use bootstrap distribution compute Z-statistic distribution: \\[ z = \\frac{\\tau_{4} (\\kappa ^{*}) - t_{4} + B_{4} }{ \\sigma _{4}} \\] Choose distribution smallest Z-statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Model Selection","what":"Handling Nonstationarity","title":"","text":"nonstationarity detected, annual maximum series decomposed model selection. consider three nonstationary scenarios can identified EDA: Trend mean . Trend standard deviation . Trend mean standard deviation.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-1-trend-in-mean","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 1: Trend in mean","title":"","text":"Use Sen’s Trend Estimator approximate slope \\(b_1\\) intercept \\(b_0\\). Detrend: subtract linear function \\((b_{1} \\cdot \\text{Covariate})\\) time series, covariate time index calculated using formula \\((\\text{Years} - 1900) / 100\\). Ensure positivity: necessary, shift series adding constant \\(\\min(\\text{data}) = 1\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-2-trend-in-standard-deviation","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 2: Trend in standard deviation","title":"","text":"Generate time series standard deviations using moving windows method. Use Sen’s Trend Estimator identify slope \\(c_{1}\\) intercept \\(c_{0}\\) trend standard deviations. Normalize data mean \\(0\\), divide scale factor \\(g_{t}\\). \\[ g_{t} = \\frac{(c_{1} \\cdot  \\text{Covariate} ) + c_{0}}{c_{0}} \\] Add back long-term mean \\(\\mu\\), ensure positivity Scenario 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-model-selection.html","id":"scenario-3-trend-in-both-mean-and-standard-deviation","dir":"Articles","previous_headings":"Model Selection > Handling Nonstationarity > Decomposition Steps","what":"Scenario 3: Trend in both mean and standard deviation","title":"","text":"Remove linear trend mean exactly Scenario 1. detrended series, generate rolling‐window STD series fit trend. Divide detrended data time-varying scale factor \\(g_{t}\\) (Scenario 2). Shift preserve series mean ensure positivity.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"","text":"module estimates parameters S-FFA NS-FFA. NS-FFA, parameter estimation also involves estimating regression coefficients time-varying parameters. framework supports three estimation methods: L-moments Maximum Likelihood (MLE) Generalized Maximum Likelihood (GMLE) Note: adopt GEV distribution convention Coles (2001)1, positive shape parameter \\(\\kappa\\) indicates heavy tail. differs convention used sources.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"l-moments","dir":"Articles","previous_headings":"Parameter Estimation","what":"L-Moments","title":"","text":"L-moments parameter estimation method implemented distributions S-FFA. method uses sample L-moments (\\(l_1\\), \\(l_2\\)) L-moment ratios (\\(t_3\\), \\(t_4\\)) estimate parameters. information L-moments, see . Warning: L-moment-based estimates can yield distributions support small values. However, typically issue quantile estimation mid- high-return periods.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"maximum-likelihood-mle","dir":"Articles","previous_headings":"Parameter Estimation","what":"Maximum Likelihood (MLE)","title":"","text":"MLE implemented distributions across S-FFA NS-FFA. Maximum likelihood estimation aims maximize log-likelihood function \\(\\ell(x : \\theta)\\) data \\(x = x_{1}, \\dots , x_{n}\\) given parameters \\(\\theta\\). log-likelihood functions distribution defined . find optimal parameters, use nlminb function stats library. function implements “L-BFGS-B” algorithm box-constrained optimization.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-parameter-estimation.html","id":"generalized-maximum-likelihood-gmle","dir":"Articles","previous_headings":"Parameter Estimation","what":"Generalized Maximum Likelihood (GMLE)","title":"","text":"GMLE used GEV models incorporating prior knowledge2 shape parameter \\(\\kappa\\) using Bayesian reasoning via maximum posteriori estimation, maximizes product likelihood prior distribution. Suppose \\(\\kappa\\) drawn \\(K \\sim \\text{Beta}(p, q)\\) \\(p\\) \\(q\\) determined using prior knowledge. prior PDF \\(f_{K}(\\kappa)\\) shown , \\(B(p, q)\\) Beta function. \\[ f_{K}(\\kappa) = \\frac{\\kappa ^{p - 1}(1 - \\kappa)^{q-1}}{B(p, q)} \\] case regular maximum likelihood estimation, likelihood function : \\[ f_{X}(x : \\mu, \\sigma, \\kappa) =\\prod_{=1}^{n} \\frac{1}{\\sigma}t_{}^{-1 - (1/\\kappa)} \\exp (-t_{}^{-1/\\kappa}), \\quad t_{} = 1 + \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma } \\right) \\] mentioned previously, want maximize product \\(\\mathcal{L} = f_{K}(\\kappa)f_{X}(x:\\mu ,\\sigma ,\\kappa)\\). ensure numerical stability, maximize \\(\\ln  (\\mathcal{L})\\) instead, following form: \\[ \\begin{aligned} \\ln(\\mathcal{L}) &= \\ln(f_{K}(\\kappa)) + \\ln(f_{X}(x:\\mu ,\\sigma ,\\kappa )) \\\\[10pt] \\ln(f_{K}(\\kappa)) &= (p - 1)\\ln \\kappa + (q-1) \\ln (1 - \\kappa)  - \\ln (B(p, q)) \\\\[5pt] \\ln(f_{X}(x:\\mu ,\\sigma ,\\kappa )) &= \\sum_{=1}^{n} \\left[-\\ln \\sigma - \\left(1 + \\frac{1}{\\kappa }\\right) \\ln t_{} - t_{}^{-1/\\kappa}\\right] \\end{aligned} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"candidate-probability-distributions","dir":"Articles","previous_headings":"","what":"Candidate Probability Distributions","title":"","text":"FFA framework considers nine candidate probability distributions: distribution also three nonstationary variants: trend location parameter \\(\\mu\\) (+1 parameter). trend scale parameter \\(\\sigma\\) (+1 parameter). trend location \\(\\mu\\) scale \\(\\sigma\\) (+2 parameters). FFA framework also uses four-parameter Kappa distribution (KAP) Z-statistic selection metric. Kappa distribution generalizes nine distributions listed .","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"gumbel-gum-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Gumbel (GUM) Distribution","title":"","text":"Support \\(-\\infty < x < \\infty\\) Quantiles \\(x(F) = \\mu - \\sigma \\log (-\\log F)\\) Likelihood Function probability density function (PDF) : \\[ f(x_{} : \\mu, \\sigma) = \\frac{1}{\\sigma} \\exp \\left(-z_{} - e^{-z_{}}\\right) , \\quad z_{} = \\frac{x_{} - \\mu}{\\sigma } \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma) = \\sum_{=1}^{n} \\left[-\\ln \\sigma - z_{} - e^{-z_{}} \\right] \\] L-Moments equations , \\(\\gamma \\approx 0.5772\\) Euler’s constant. \\(\\lambda_{1} = \\mu + \\sigma \\gamma\\) \\(\\lambda_{2} = \\sigma \\log 2\\) \\(\\tau_{3} = \\log(9/8)/\\log 2 \\approx 0.1699\\) \\(\\tau_{4} = (16 \\log 2 - 10\\log 3) / \\log 2 \\approx 0.1504\\) can also express parameters terms L-moments: \\(\\sigma = \\lambda_{2} / \\log 2\\) \\(\\mu = \\lambda_{1} - \\sigma \\gamma\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"normal-nor-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Normal (NOR) Distribution","title":"","text":"Support \\(-\\infty < x < \\infty\\) Quantiles \\(x(F) = \\mu  + \\sigma \\Phi^{-1}(F)\\) Likelihood Function probability density function (PDF) : \\[ f(x_{} : \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi }}e^{-z_{}^2/2} , \\quad z_{} = \\frac{x_{} - \\mu}{\\sigma } \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma) = \\sum_{=1}^{n} \\left[-\\ln (\\sigma \\sqrt{2\\pi }) - \\frac{z_{}^2}{2} \\right] \\] L-Moments \\(\\lambda_{1} = \\mu\\) \\(\\lambda_{2} = \\pi^{-1/2}\\sigma \\approx 0.5642\\sigma\\) \\(\\tau_{3} = 0\\) \\(\\tau_{4} = 30\\pi^{-1}\\arctan \\sqrt{2} - 9 \\approx 0.1226\\) can also express parameters terms L-moments: \\(\\mu = \\lambda_{1}\\) \\(\\sigma = \\pi^{1/2}\\lambda_{2}\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"log-normal-lno-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Log-Normal (LNO) Distribution","title":"","text":"Support \\(0 < x < \\infty\\) Quantiles \\(x(F) = \\exp(\\mu + \\sigma \\Phi^{-1}(F))\\) Likelihood Function derive likelihood, use fact : \\[ \\text{Data} \\sim \\text{LNO} \\Leftrightarrow \\ln (\\text{Data}) \\sim \\text{} \\] Precisely, require change variables formula, states : \\[ \\ell_{\\text{LNO}}(x ; \\mu, \\sigma) = \\ell_{\\text{}}(\\ln x ; \\mu , \\sigma) \\left|\\frac{d}{dx} \\ln  x\\right| = \\frac{\\ell_{\\text{}}(\\ln x ; \\mu , \\sigma)}{x} \\] L-Moments See Normal Distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-extreme-value-gev-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Extreme Value (GEV) Distribution","title":"","text":"Support \\[ \\begin{cases} \\mu + (\\sigma /\\kappa) \\leq x < \\infty & \\kappa > 0 \\\\[5pt] -\\infty < x < \\infty & \\kappa  = 0 \\\\[5pt] -\\infty < x \\leq \\mu + (\\sigma/\\kappa ) &\\kappa < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{dcases} \\mu + \\sigma (1 - (-\\log F)^{\\kappa })/\\kappa  &\\kappa \\neq 0\\\\[5pt] \\mu - \\sigma \\log (-\\log F) &\\kappa = 0 \\end{dcases} \\] Likelihood Function probability density function (PDF) (assume \\(t_{} > 0)\\): \\[ f(x_{} : \\mu, \\sigma, \\kappa) = \\frac{1}{\\sigma}t_{}^{-1 - (1/\\kappa)} \\exp (-t_{}^{-1/\\kappa}), \\quad t_{} = 1 + \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma } \\right) \\] Therefore, Log-likelihood : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[-\\ln \\sigma - \\left(1 + \\frac{1}{\\kappa }\\right) \\ln t_{} - t_{}^{-1/\\kappa}\\right] \\] L-Moments L-moments defined \\(\\kappa > -1\\): \\(\\lambda_{1} = \\mu + \\sigma (1 - \\Gamma (1 + \\kappa)) / \\kappa\\) \\(\\lambda_{2} = \\sigma (1 - 2^{-\\kappa })\\Gamma (1 + \\kappa) / \\kappa\\) \\(\\tau_{3} = 2(1 - 3^{-\\kappa})/(1 - 2^{-\\kappa}) - 3\\) \\(\\tau_{4} = [5(1 - 4^{-\\kappa })-10(1-3^{-\\kappa}) + 6(1-2^{-\\kappa })]/(1 - 2^{-\\kappa })\\) compute parameters L-moments, first compute \\(c\\): \\[ c = \\frac{2}{3 + \\tau_{3}} - \\frac{\\log 2}{\\log 3} \\] , use following approximation2: \\[ \\begin{cases} \\kappa \\approx 7.8590c + 2.9554c^2 \\\\[5pt] \\sigma \\approx \\lambda_{2}\\kappa / (1 - 2^{-\\kappa })\\Gamma (1 + \\kappa) \\\\[5pt] \\mu \\approx \\lambda_{1} - \\sigma (1 - \\Gamma (1 + \\kappa )) / \\kappa \\end{cases} \\] Note: sources often use different notation GEV distribution sign shape parameter \\(\\kappa\\) flipped.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-logistic-glo-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Logistic (GLO) Distribution","title":"","text":"Support \\[ \\begin{cases} -\\infty < x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa  > 0 \\\\[5pt] -\\infty  < x < \\infty  & \\kappa  = 0 \\\\[5pt] \\mu  + (\\sigma /\\kappa ) \\leq  x < \\infty  & \\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu +\\sigma [1 - ((1 - F) / F)^{\\kappa}] / \\kappa &\\kappa \\neq 0 \\\\[5pt] \\mu - \\sigma \\log ((1 - F) / F) & k = 0 \\end{cases} \\] Likelihood Function probability density function (PDF) (assume \\(t_{} > 0)\\): \\[ f(x_{} : \\mu , \\sigma , \\kappa ) = \\frac{1}{\\sigma }t_{}^{(1/\\kappa) - 1} \\left[1 + t_{}^{1/\\kappa}\\right]^{-2}, \\quad t_{} = 1 - \\kappa \\left(\\frac{x_{} - \\mu }{\\sigma }\\right) \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[-\\ln \\sigma + \\left(\\frac{1}{\\kappa }-1\\right) \\ln t_{} - 2 \\ln \\left(1 + t_{}^{1/\\kappa }\\right) \\right] \\] L-Moments L-moments defined \\(-1 < \\kappa < 1\\): \\(\\lambda_{1} = \\mu +\\sigma [(1 / \\kappa) - (\\pi / \\sin (\\kappa\\pi))]\\) \\(\\lambda_{2} = \\sigma \\kappa \\pi / \\sin (\\kappa \\pi)\\) \\(\\tau_{3} = -\\kappa\\) \\(\\tau_{4} = (1 + 5\\kappa ^2) / 6\\) can also express parameters terms L-moments: \\(\\kappa = -\\tau_{3}\\) \\(\\sigma = \\lambda_{2}\\sin (\\kappa \\pi ) / \\kappa \\pi\\) \\(\\mu = \\lambda_{1} - \\sigma [(1 / \\kappa) - (\\pi / \\sin (\\kappa\\pi))]\\)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"generalized-normal-gno-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Generalized Normal (GNO) Distribution","title":"","text":"Support \\[ \\begin{cases} -\\infty < x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa  > 0 \\\\[5pt] -\\infty  < x < \\infty  & \\kappa  = 0 \\\\[5pt] \\mu  + (\\sigma /\\kappa ) \\leq  x < \\infty  & \\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu + \\sigma [1 - \\exp(-\\kappa \\Phi^{-1}(F))] / \\kappa &\\kappa \\neq 0 \\\\[5pt] \\mu + \\sigma \\Phi^{-1}(F) &\\kappa  = 0 \\end{cases} \\] Likelihood Function L-Moments L-moments defined values \\(\\kappa\\). \\(\\lambda_{1} = \\mu + \\sigma (1 - e^{\\kappa ^2/2}) / \\kappa\\) \\(\\lambda_{2} = \\sigma e^{-\\kappa ^2/ 2}[1 - 2\\Phi (-\\kappa  / \\sqrt{2})] / \\kappa\\) compute \\(\\tau_{3}\\) \\(\\tau_{4}\\) use following approximation: \\[ \\begin{aligned} \\tau_{3} &\\approx -\\kappa \\left(\\frac{A_{0} + A_{1}\\kappa ^2 + A_{2}\\kappa ^{4} + A_{3}\\kappa ^{6}}{1 + B_{1}\\kappa ^2 + B_{2}\\kappa ^{4} + B_{3}\\kappa ^{6}}\\right)  \\\\[5pt] \\tau_{4} &\\approx \\tau_{4}^{0} + \\kappa ^2 \\left(\\frac{C_{0} + C_{1}\\kappa ^2 + C_{2}\\kappa ^{4} + C_{3}\\kappa ^{6}}{1 + D_{1}\\kappa ^2 + D_{2}\\kappa ^{4} + D_{3}\\kappa ^{6}}\\right) \\end{aligned} \\] determine parameters L-moments also use rational approximation: \\[ \\kappa \\approx -\\tau_{3} \\left(\\frac{E_{0} + E_{1}\\tau_{3}^2 + E_{2}\\tau_{3}^{4} + E_{3}\\tau _{3}^{6}}{1 + F_{1}\\tau _{3}^2 + F_{2}\\tau _{3}^{4} + F_{3}\\tau _{3}^{6}}\\right) \\] , can find \\(\\mu\\) \\(\\sigma\\) function \\(\\kappa\\): \\[ \\sigma \\approx  \\frac{\\lambda_{2}\\kappa e^{-\\kappa ^2 / 2}}{1 - 2\\Phi (-\\kappa  / \\sqrt{2})}, \\quad \\mu  \\approx  \\lambda_{1} - \\frac{\\sigma }{\\kappa }\\left(1 - e^{-\\kappa ^2 / 2 }\\right) \\] coefficients (\\(A_{}\\), \\(B_{}\\), \\(C_{}\\), \\(D_{}\\), \\(E_{}\\), \\(F_{}\\), \\(\\tau_{4}^{0}\\)) defined Appendix .8 Hosking, 19973. Although appendix covers 3-parameter log-normal distribution, L-moments generalized normal distribution .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"pearson-type-iii-pe3-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Pearson Type III (PE3) Distribution","title":"","text":"Pearson Type III distribution typically reparameterized follows \\(\\kappa \\neq 0\\): \\[ \\begin{aligned} \\alpha &= 4 / \\kappa^2 \\\\[5pt] \\beta  &= \\sigma |\\kappa | / 2 \\\\[5pt] \\xi &= \\mu  - 2\\sigma /\\kappa \\end{aligned} \\] Support \\[ \\begin{cases} \\xi \\leq  x < \\infty &\\kappa > 0 \\\\[5pt] -\\infty < x < \\infty  &\\kappa =0 \\\\[5pt] -\\infty  < x \\leq \\xi &\\kappa  < 0 \\end{cases} \\] Quantiles \\[ x(F) = \\begin{cases} \\mu - \\alpha \\beta + q(F, \\alpha, \\beta) &\\kappa > 0\\\\[5pt] \\mu + \\sigma \\Phi^{-1}(F) &\\kappa  = 0\\\\[5pt] \\mu  + \\alpha \\beta  - q(1 - F, \\alpha, \\beta) &\\kappa < 0 \\end{cases} \\] equations , \\(q\\) quantile function Gamma distribution shape \\(\\alpha\\) scale \\(\\beta\\). \\(q\\) defined , \\(\\gamma\\) lower incomplete Gamma function. \\[q(F, \\alpha, \\beta) = \\beta \\gamma ^{-1}(\\alpha, p \\Gamma (\\alpha))\\] Likelihood Function probability density function (PDF) PE3 distribution given : \\[ f(x_{} : \\mu , \\sigma , \\kappa ) = \\frac{(x_{} - \\xi)^{\\alpha  - 1}e^{-(x_{} - \\xi )/\\beta }}{\\beta ^{\\alpha } \\Gamma (\\alpha )} \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[(\\alpha  - 1) \\ln |x_{} - \\xi | - \\frac{|x_{} - \\xi  |}{\\beta } - \\alpha \\ln\\beta  - \\ln \\Gamma (\\alpha )\\right] \\] L-Moments subsequent definitions assume \\(\\kappa > 0\\). \\(\\kappa < 0\\), L-moments can obtained changing signs \\(\\lambda_{1}\\), \\(\\tau_{3}\\), \\(\\xi\\) whenever appear. \\(\\kappa = 0\\), L-moments Normal Distribution. first two L-moments defined follows: \\(\\lambda_{1} = \\xi + \\alpha \\beta\\) \\(\\lambda_{2} = \\pi ^{-1/2} \\beta \\Gamma (\\alpha  + 0.5) / \\Gamma (\\alpha )\\) Rational approximation necessary determine \\(\\tau_{3}\\) \\(\\tau_{4}\\). \\(\\alpha \\geq 1\\): \\[ \\begin{aligned} \\tau_{3} &\\approx \\alpha^{-1/2} \\left(\\frac{A_{0} + A_{1}\\alpha^{-1} + A_{2}\\alpha^{-2} + A_{3}\\alpha^{-3}}{1 + B_{1}\\alpha^{-1} + B_{2}\\alpha ^{-2}}\\right)  \\\\[5pt] \\tau_{4} &\\approx \\frac{C_{0} + C_{1}\\alpha^{-1} + C_{2}\\alpha ^{-2} +C_{3}\\alpha ^{-3}}{1 + D_{1}\\alpha ^{-1} + D_{2}\\alpha ^{-2}} \\end{aligned} \\] \\(\\alpha < 1\\), use different set coefficients: \\[ \\begin{aligned} \\tau_{3} &\\approx \\frac{1 + E_{1}\\alpha  + E_{2}\\alpha ^2 + E_{3}\\alpha ^3}{1 + F_{1}\\alpha  + F_{2}\\alpha ^2 + F_{3}\\alpha ^3} \\\\[5pt] \\tau_{4} &\\approx \\frac{1 + G_{1}\\alpha + G_{2}\\alpha ^2 + G_{3}\\alpha ^3}{1 + H_{1}\\alpha + H_{2}\\alpha ^2 + H_{3}\\alpha ^3} \\end{aligned} \\] Coefficients given Appendix .9 Hosking, 19974. estimate parameters L-moments, use one two approximations \\(\\alpha\\) depending value \\(\\tau_{3}\\): \\[ \\alpha \\approx \\begin{dcases} \\frac{1 + 0.2906z}{z + 0.1882z^2 + 0.0442z^3}, &z = 3\\pi \\tau_{3}^2, &0 < |\\tau_{3}| < \\frac{1}{3} \\\\[5pt] \\frac{0.36067z - 0.59567z^2 + 0.25361z^3}{1 - 2.78861z + 2.56096z^2 - 0.77045z^3}, &z = 1 - |\\tau_{3}|, &\\frac{1}{3} \\leq |\\tau_{3}| < 1 \\end{dcases} \\] , can determine parameters approximated \\(\\alpha\\): \\[ \\begin{aligned} \\kappa &= 2\\alpha ^{-1/2} \\text{sign} (\\tau_{3}) \\\\[5pt] \\sigma &= \\lambda_{2} \\pi^{1/2}\\alpha ^{1/2} \\Gamma (\\alpha )/\\Gamma (\\alpha + 0.5)\\\\[5pt] \\mu &= \\lambda_{1 } \\end{aligned} \\]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"log-pearson-type-iii-lp3-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Log-Pearson Type III (LP3) Distribution","title":"","text":"LP3 distribution uses reparameterization PE3 distribution. Support \\[ \\begin{cases} \\max(0, \\xi) \\leq  x < \\infty &\\kappa > 0 \\\\[5pt] 0 < x < \\infty  &\\kappa =0 \\\\[5pt] 0  < x \\leq \\max(0, \\xi) &\\kappa  < 0 \\end{cases} \\] Quantiles \\(x(F) = \\exp(x_{\\text{PE3}}(F ))\\), \\(x_{\\text{PE3}}(F)\\) quantile function PE3 distribution. Likelihood Function derive likelihood LP3 distribution, use fact : \\[ \\text{Data} \\sim \\text{LP3}  \\Leftrightarrow \\ln (\\text{Data}) \\sim \\text{PE3} \\] Precisely, require change variables formula, states : \\[ \\ell_{\\text{LP3}}(x ; \\mu, \\sigma, \\kappa) = \\ell_{\\text{PE3}}(\\ln x ; \\mu , \\sigma, \\kappa ) \\left|\\frac{d}{dx} \\ln  x\\right| = \\frac{\\ell_{\\text{PE3}}(\\ln x ; \\mu , \\sigma, \\kappa )}{x} \\] L-Moments PE3 distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"weibull-wei-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Weibull (WEI) Distribution","title":"","text":"Weibull distribution implemented reparameterized version generalized extreme value distribution: \\[ \\begin{aligned} \\kappa &= 1 / \\kappa_{\\text{GEV}} \\\\[5pt] \\sigma &= \\kappa \\sigma_{\\text{GEV} } \\\\[5pt] \\mu &= \\sigma + \\mu_{\\text{GEV} } \\end{aligned} \\] reparameterization, required \\(\\sigma > 0\\) \\(\\kappa > 0\\). Support \\(\\mu \\leq x < \\infty\\) Quantiles \\(x(F) = \\mu + \\sigma (-\\log (1 - F))^{1/\\kappa}\\) Likelihood Function probability density function (PDF) given \\(x_{} > \\mu\\): \\[ f(x_{} : \\mu, \\sigma, \\kappa) = \\frac{\\kappa}{\\sigma }\\left(\\frac{x_{} - \\mu}{\\sigma }\\right)^{\\kappa -1} \\exp \\left( - \\left(\\frac{x_{} - \\mu}{\\sigma }\\right)^{\\kappa } \\right) \\] Therefore, Log-likelihood function : \\[ \\ell(x:\\mu, \\sigma, \\kappa) = \\sum_{=1}^{n} \\left[\\ln \\kappa - \\kappa \\ln \\sigma +(\\kappa -1)\\ln (x_{}-\\mu ) - \\left(\\frac{x_{} - \\mu }{\\sigma }\\right) ^{\\kappa } \\right] \\] L-Moments First, reparameterize Weibull distribution recover GEV parameters: \\[ \\begin{aligned} \\kappa_{\\text{GEV}} &= 1 / \\kappa \\\\[5pt] \\sigma_{\\text{GEV}} &= \\sigma / \\kappa \\\\[5pt] \\end{aligned} \\] Next, compute L-moments GEV distribution \\(\\mu_{\\text{GEV}} = 0\\). , \\(\\lambda_{1} = \\mu + \\sigma - \\lambda_{1, \\text{GEV}}\\) \\(\\lambda_{2} = \\lambda_{2, \\text{GEV}}\\) \\(\\tau_{3} = -\\tau_{3, \\text{GEV}}\\) \\(\\tau_{4} = \\tau_{4, \\text{GEV} }\\) compute parameters L-moments, first flip sign \\(\\lambda_{1}\\) \\(\\tau_{3}\\). , estimate parameters GEV distribution get \\(\\hat{\\mu}_{\\text{GEV}}\\), \\(\\hat{\\sigma}_{\\text{GEV}}\\), \\(\\hat{\\kappa}_{\\text{GEV}}\\). Finally, reparameterize GEV parameters shown flip sign \\(\\mu\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-probability-distributions.html","id":"kappa-kap-distribution","dir":"Articles","previous_headings":"Candidate Probability Distributions > List of Distributions1","what":"Kappa (KAP) Distribution","title":"","text":"Kappa distribution location \\(\\mu\\), scale \\(\\sigma\\), two shape parameters \\(\\kappa\\) \\(h\\). Support \\[ \\begin{cases} \\mu + \\sigma (1 - h^{-\\kappa}) \\leq x \\leq \\mu + (\\sigma /\\kappa ) & \\kappa > 0, h > 0 \\\\[5pt] -\\infty < x \\leq \\mu + (\\sigma /\\kappa) & \\kappa > 0, h \\leq 0 \\\\[5pt] \\mu + \\sigma (1 - h^{-\\kappa}) \\leq x < \\infty &\\kappa \\leq 0, h > 0 \\\\[5pt] \\mu + (\\sigma / \\kappa ) \\leq x <\\infty &\\kappa  \\leq 0, h \\leq 0 \\end{cases} \\] Quantiles \\[ x(F) = \\mu + \\frac{\\sigma }{\\kappa }\\left[1 - \\left(\\frac{1 - F^{h}}{h}\\right)^{\\kappa }\\right] \\] L-Moments L-moments defined \\(h \\geq 0\\) \\(k > -1\\) \\(h < 0\\) \\(-1 < k < -1/h\\). \\(\\lambda_{1} = \\mu  + \\sigma (1 - g_{1})/\\kappa\\) \\(\\lambda_{2} = \\sigma(g_{1} - g_{2})/\\kappa\\) \\(\\tau_{3} = (-g_{1} + 3g_{2} - 2g_{3}) / (g_{1} - g_{2})\\) \\(\\tau_{4} = (-g_{1} + 6g_{2} - 10g_{3} + 5g_{4}) / (g_{1} - g_{2})\\) expression , \\(g_{r}\\) defined follows: \\[ g_{r} = \\begin{dcases} \\frac{r\\Gamma (1 + \\kappa )\\Gamma (r / h)}{h^{1 + \\kappa }\\Gamma (1 + \\kappa + r/h)} &h > 0 \\\\[5pt] \\frac{r\\Gamma (1 + \\kappa ) \\Gamma (-\\kappa  - r/h)}{(-h)^{1 + \\kappa }\\Gamma (1 - r/h)} &h < 0 \\end{dcases} \\] closed-form solution parameters terms L-moments. However, \\(\\tau_{3}\\) \\(\\tau_{4}\\) can computed terms \\(\\kappa\\) \\(h\\) using Newton-Raphson iteration.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"","text":"FFA framework implements three methods uncertainty quantification: Parametric bootstrap Regula-falsi profile likelihood (RFPL) Regula-falsi generalized profile likelihood (RFGPL)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"parametric-bootstrap","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Parametric Bootstrap","title":"","text":"parametric bootstrap flexible method uncertainty quantification works probability models parameter estimation methods. Let \\(n\\) size original dataset. Draw \\(N_{\\text{sim}}\\) bootstrap samples size \\(n\\) selected probability distribution. Fit probability distribution bootstrap sample using model selection method parameter estimation method used generate original distribution. Compute quantiles bootstrapped distributions. Generate confidence intervals using mean variance bootstrapped quantiles. Warning: parametric bootstrap known give unreasonably wide confidence intervals small datasets. FFA framework detects confidence interval 5+ times wider return levels , return error recommend RFPL uncertainty quantification1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"regula-falsi-profile-likelihood-rfpl","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Regula-Falsi Profile Likelihood (RFPL)","title":"","text":"Consider statistical model parameters \\((\\theta, \\psi_{1}, \\dots, \\psi_{n})\\). Profile Likelihood scalar parameter \\(\\theta\\) vector nuisance parameters \\(\\psi\\) defined : \\[ \\ell_{p}(\\theta) = \\max_{\\psi } \\ell(\\theta , \\psi) \\] Let \\(\\hat{\\theta}\\) MLE \\(\\theta\\). find confidence interval significance \\(1-\\alpha\\), find two solutions following equation (\\(\\chi_{1;1-\\alpha}^2\\) \\(1-\\alpha\\) quantile Chi-squared distribution): \\[ 2[\\ell_{p}(\\hat{\\theta }) - \\ell_{p}(\\theta )] = \\chi_{1;1-\\alpha }^2 \\] equivalent finding two points \\(\\theta_{L} < \\hat{\\theta} < \\theta_{U}\\) profile log-likelihood dropped \\(\\chi _{1;1-\\alpha }^2 / 2\\). find \\(\\theta_{L}\\) \\(\\theta_{U}\\) find roots \\(f(\\theta)\\) using secant-based algorithm. \\[ f(\\theta) = \\ell_{p}(\\theta) - \\left[\\ell_{p}(\\hat{\\theta}) - \\frac{\\chi_{1;1-\\alpha }^2}{2}\\right] \\] FFA framework, compute profile likelihood quantile \\(y\\) reparameterizing location parameter \\(\\mu\\). Let \\(q(p, \\mu, \\psi)\\) function takes exceedance probability \\(p\\), location parameter \\(\\mu\\) nuisance parameters \\(\\psi\\) returns quantile \\(y\\). quantile functions satisfy: \\[ y = q(p, \\mu, \\psi) = \\mu + q(p, 0, \\psi) \\] Therefore, can define \\(\\mu\\) function \\((p, y, \\psi)\\) shown : \\[ \\mu = y - q(p, 0, \\psi) \\] use relationship find profile likelihood \\(\\ell_{p}(y)\\) evaluating \\(\\mu(p, y, \\psi)\\) substituting log-likelihood functions listed . Warning: RFPL uncertainty quantification can numerically unstable datasets. FFA framework encounters issue, return error recommend parametric bootstrap2.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"handling-the-weibull-distribution","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Handling the Weibull Distribution","title":"","text":"Due support issues, use different reparameterization Weibull distribution: \\[ \\begin{aligned} &y = (\\mu_{0} + \\mu_{1}t) + (\\sigma_{0} + \\sigma_{1}t)(-\\log (1 - p))^{1/\\kappa}  \\\\[5pt] \\Rightarrow\\,&(\\sigma_{0} + \\sigma_{1}t) = \\frac{y - (\\mu_{0} + \\mu_{1}t)}{(-\\log (1 - p))^{1/\\kappa}} \\\\[5pt] \\Rightarrow\\,&\\sigma_{0} = \\frac{y - (\\mu_{0} + \\mu_{1}t)}{(-\\log (1 - p))^{1 / \\kappa }} - \\sigma_{1}t \\end{aligned} \\] derivation uses Weibull distribution trend mean variability. However, reparameterizations nonstationary structures can obtained easily setting \\(\\sigma_{1} = 0\\) /\\(\\mu_{1} = 0\\). solving \\(\\sigma_{0}\\) terms parameters, can use standard log-likelihood function.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"initialization-algorithm","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Initialization Algorithm","title":"","text":"can find roots \\(f\\), need identify initial values regula-falsi algorithm: Let \\(a_{0}\\) number \\(a_{0} < y\\) \\(f(a_{0}) < 0\\). Let \\(b_{0}\\) number \\(b_{0} > y\\) \\(f(b_{0}) < 0\\). find \\(a_{0}\\), start computing \\(f(^{*})\\) \\(^{*} = 0.95y\\). \\(f(^{*}) < 0\\), assign \\(a_{0} = ^{*}\\). Otherwise, update \\(^{*}\\) \\(0.95a^{*}\\) \\(f(^{*}) < 0\\). find \\(b_{0}\\), use similar process. However, instead iteratively revising \\(b^{*}\\) , revise \\(1.05b^{*}\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"iteration-algorithm","dir":"Articles","previous_headings":"Uncertainty Quantification > Regula-Falsi Profile Likelihood (RFPL)","what":"Iteration Algorithm","title":"","text":"iteration \\(\\), compute following: \\[ c_{} = \\frac{a_{-1}f(b_{-1}) - b_{-1}f(a_{-1})}{f(b_{-1}) - f(a_{-1})} \\] Evaluate \\(\\ell_{p}(c_{})\\) maximizing nuisance parameters \\(\\psi\\), find \\(f(c_{})\\). \\(|f(c_{})| < \\epsilon\\) (\\(\\epsilon\\) small), stop. \\(c_{}\\) confidence interval bound. Otherwise, assign \\(a_{} = c_{}\\) \\(f(c_{}) < 0\\) \\(b_{} = c_{}\\) \\(f(c_{}) > 0\\) continue iteration \\(+ 1\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"regula-falsi-generalized-profile-likelihood-rfgpl","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Regula-Falsi Generalized Profile Likelihood (RFGPL)","title":"","text":"regula-falsi generalized profile likelihood (RFGPL) method performs regula-falsi algorithm shown GEV distributions \\(\\text{Beta}(p, q)\\) prior shape parameter \\(\\kappa\\). information generalized parameter estimation, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/ffa-uncertainty-quantification.html","id":"handling-nonstationarity","dir":"Articles","previous_headings":"Uncertainty Quantification","what":"Handling Nonstationarity","title":"","text":"selected probability distribution nonstationary, quantiles (hence confidence intervals) bootstrapped distributions change time. See detailed discussion idea. default, FFA framework anchors uncertainty analysis last year dataset. However, model assessment requires confidence intervals every year dataset. Note: parametric bootstrap algorithm fastest algorithm computing confidence intervals years dataset probabilities used generate bootstrapped samples can reused. RFPL RFGPL algorithms far slower, since must run separately timestamp.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"changes-from-matlab-version","dir":"Articles","previous_headings":"","what":"Changes from MATLAB Version","title":"MATLAB Version","text":"page documents changes original MATLAB code.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"bug-fixes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Exploratory Data Analysis (EDA)","what":"Bug Fixes","title":"MATLAB Version","text":"show statistically significant change points Pettitt MKS plots. Fix bug causing MKS test identify one change point, even multiple change points found threshold statistical significance. Fix major bug causing MKS test identify change points based progressive series instead z-statistics crossing points. Remove unnecessary rounding moving window algorithm estimating variability. Re-implement Phillips-Perron KPSS tests account drift trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"framework-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Exploratory Data Analysis (EDA)","what":"Framework Changes","title":"MATLAB Version","text":"serial correlation identified, run Phillips-Perron KPSS tests. Add Runs test detect nonlinearity fitting Sen’s trend estimator. Run change point detection multiple stages prevent overpartitioning.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"distribution-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Distribution Changes","title":"MATLAB Version","text":"generalized Pareto (GPA) distribution removed, since likelihood function amenable maximum likelihood estimation. Issues occur GPA distribution intended peaks threshold modeling, use. R version uses three parameter Weibull distribution (location, scale, shape) parameters instead two parameter Weibull distribution (scale shape parameters). ensures consistency distributions, location parameters.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"model-selection-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Model Selection Changes","title":"MATLAB Version","text":"L-distance L-kurtosis selection methods improved using optimization algorithm find parameters closest L-moments data instead using brute force approach. computationally efficient gives precise results. procedure computing Z-statistic selection metric changed. L-moments dataset satisfy \\(\\tau_{4} \\leq (1 + 5\\tau _{3}^2)/6\\), Kappa distribution fitted candidate distributions use dataset omitted.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"parameter-estimation-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Parameter Estimation Changes","title":"MATLAB Version","text":"Parameterization PE3/LP3 distributions fails datasets MATLAB unable handle large numbers created gamma function. manage issue, MATLAB version used conventional moments (.e. sample mean/variance/skewness) occurred. avoid problem R version using lgamma (log-gamma) function. R implementation uses L-BFGS-B MLE/GMLE parameter estimation instead Nelder-Mead, since gradient well defined likelihood functions working . Additionally, L-BFGS-B method makes possible assign bounds variables. modification produced slight improvements MLL/GMLL datasets.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Uncertainty Quantification","title":"MATLAB Version","text":"Implement RFPL uncertainty quantification Weibull distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/matlab-version.html","id":"model-assessment-changes","dir":"Articles","previous_headings":"Changes from MATLAB Version > Flood Frequency Analysis (FFA)","what":"Model Assessment Changes","title":"MATLAB Version","text":"Use built-R function approx() perform log-linear interpolation return periods. MATLAB implementation uses hard-coded algorithm behaves unpredictably original interpolated \\(x\\)-values equal.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Nonstationary FFA","text":"vignette explore data Bow River Banff (05BB001), station Reference Hydrometric Basin Network. station unregulated, suggests trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"the-ns_structure-list","dir":"Articles","previous_headings":"Case Study","what":"The ns_structure List","title":"Nonstationary FFA","text":"vignette assumes scenario trend mean identified. specify trend one distribution parameters, create ns_structure (nonstationary model structure) list containing boolean items location scale. Setting items TRUE adds trend location/scale parameter respectively. Note: guidance trend detection, refer Trend Identification vignette.","code":"ns_structure <- list(location = TRUE, scale = FALSE)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"distribution-selection","dir":"Articles","previous_headings":"","what":"Distribution Selection","title":"Nonstationary FFA","text":"L-moment-based distribution selection remains applicable nonstationarity, requires dataset decomposition (detrending) prior analysis. select_* methods automatically (using data_decomposition method) ns_years ns_structure arguments supplied.  Note: sample log-sample points L-moment diagram based detrended data. Conclusion: generalized normal (GNO) distribution best-fit distribution sample.","code":"selection <- select_ldistance(     df$max,     ns_years = df$year,     ns_structure = ns_structure )  print(selection$recommendation) #> [1] \"GNO\"  plot_lmom_diagram(selection)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"Nonstationary FFA","text":"L-moments parameter estimation requires stationarity, use maximum likelihood estimation nonstationary model. fit_mle function implements maximum likelihood estimation stationary nonstationary distributions. two required arguments: data: annual maximum series observations. model: three-letter code corresponding probability distribution (ex. \"GNO\"). Since nonstationary model used, two additional arguments required: ns_years: corresponding vector years observations data. ns_structure: nonstationary structure object described .  Note: fitted parameters : \\((\\mu_0, \\mu_1, \\sigma, \\kappa)\\), time-dependent location modeled \\(\\mu(t) = \\mu_0 + \\mu_1 t\\). covariate \\(t\\) linear function years: \\((\\text{years} - 1900) / 100\\).","code":"fit <- fit_mle(     df$max,     \"GNO\",     ns_years = df$year,     ns_structure = ns_structure )  print(fit$params) #> [1] 224.0496619 -35.5153685  54.6324886  -0.3689085  print(fit$mll) #> [1] -590.7329  plot_nsffa_fit(fit, slices = c(1915, 2015))"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"Nonstationary FFA","text":"Uncertainty quantification important step NS-FFA well S-FFA. addition parametric bootstrap, framework implements regula-falsi profile likelihood (RFPL) method MLE. uncertainty_rfpl method two required arguments: data: annual maximum series observations. model: three-letter code corresponding probability distribution (ex. \"GNO\"). Since model nonstationary structure, three additional arguments required: ns_years: corresponding vector years observations data. ns_structure: nonstationary structure object described . ns_slices: years return levels computed.  Example Conclusion: 2025, \\(1/20\\) exceedance probability flood approximately \\(300\\text{m}^3/\\text{s}\\) greater. estimated return levels decreased approximately \\(50\\text{m}^3/\\text{s}\\) 1925 2025. Note: nonstationarity, return period reflects probability distribution fixed year rather long-run average. clarify difference stationary FFA, phrase “effective return period” used.","code":"uncertainty <- uncertainty_rfpl(     df$max,     \"GNO\",     ns_years = df$year,     ns_structure = ns_structure,     ns_slices = c(1915, 2015) )  plot_nsffa_estimates(uncertainty)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/non-stationary-ffa.html","id":"model-assessment","dir":"Articles","previous_headings":"","what":"Model Assessment","title":"Nonstationary FFA","text":"S-FFA model assessment, compare data (“empirical quantiles”) predictions parametric model plotting positions (“theoretical quantiles”). Unfortunately, method work NS-FFA, since method plotting positions assumes stationarity. However, normalize data using selected distribution, can remove time-dependence use method plotting positions S-FFA. model_assessment function make necessary adjustments NS-FFA automatically provided ns_years ns_structure arguments provided.  model assessment plot shown depicts normalized theoretical quantiles x-axis difference theoretical empirical quantiles y-axis. dashed black lines 95% confidence bounds. plot, can see model suitable fit almost data points.","code":"assessment <- model_assessment(     df$max,     \"GNO\",     \"MLE\",     ns_years = df$year,     ns_structure = ns_structure )  plot_nsffa_assessment(assessment)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Stationary FFA","text":"vignette explore data Athabasca River Athabasca (07BE001), unregulated hydrological monitoring station. statistical analysis data station reveal evidence trends mean variability data. Data station provided CAN-07BE001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-07BE001.csv\") head(df) #>   year  max #> 1 1913 1670 #> 2 1914 3090 #> 3 1915 2760 #> 4 1916 2080 #> 5 1917 2490 #> 6 1918 1470  plot_ams_data(df$max, df$year, title = \"Athabasca River at Athabasca (07BE001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"distribution-selection","dir":"Articles","previous_headings":"","what":"Distribution Selection","title":"Stationary FFA","text":"First, suitable probability distribution data selected using L-moments. select_ldistance chooses distribution theoretical L-skewness (\\(\\tau_3\\)) L-kurtosis (\\(\\tau_4\\)) closest sample, based Euclidean distance. select_lkurtosis selects distribution smallest difference sample theoretical L-kurtosis (three-parameter distributions ). select_zstatistic uses fitted 4-parameter Kappa distribution estimate sampling distribution L-kurtosis selects distribution smallest z-statistic.  Recommendation: Use generalized extreme value (GEV) distribution. Note: information distributions, see selection$metrics item. can find information probability distributions supported framework .","code":"selection <- select_ldistance(df$max)  print(selection$recommendation) #> [1] \"GEV\"  plot_lmom_diagram(selection)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"parameter-estimation","dir":"Articles","previous_headings":"","what":"Parameter Estimation","title":"Stationary FFA","text":"ffaframework package provides three methods parameter estimation. See information. fit_lmoments: L-moments parameter estimation. fit_mle: Maximum likelihood parameter estimation. fit_gmle: Generalized maximum likelihood parameter estimation.  Conclusion: GEV distribution location = 1600, scale = 616, shape = 0.12 used.","code":"fit <- fit_lmoments(df$max, \"GEV\")  print(fit$params) #> [1] 1600.219872  616.666030    0.120747  plot_sffa_fit(fit)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"uncertainty-quantification","dir":"Articles","previous_headings":"","what":"Uncertainty Quantification","title":"Stationary FFA","text":"probability distribution fitted, return levels (design events) can readily estimated. However, point estimates alone can misleading –informative report confidence intervals reflect estimation uncertainty. uncertainty_bootstrap function performs uncertainty quantification using parametric bootstrap method. requires three arguments: data: vector annual maximum series data. model: three-letter code probability distribution (ex. \"GEV\"). method: parameter estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". default, return levels computed 2-, 5-, 10-, 20-, 50-, 100- year return periods.  Example Conclusion: Every 10 years, can expect flood roughly \\(3{\\small,}200\\text{m}^3/\\text{s}\\) greater.","code":"uncertainty <- uncertainty_bootstrap(df$max, \"GEV\", \"L-moments\")  plot_sffa_estimates(fit, ci = uncertainty$ci)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/stationary-ffa.html","id":"model-assessment","dir":"Articles","previous_headings":"","what":"Model Assessment","title":"Stationary FFA","text":"Model performance assessed using model_assessment, reports collection assessment statistics flood frequency analysis. plot_sffa_assessment compares data (“empirical quantiles”) predictions parametric model plotting positions (“theoretical quantiles”). black line represents perfect 1:1 correspondence model data.  Conclusion: parametric model generally matches plotting positions. model slightly underestimates data \\(3{\\small,}500\\text{m}^3/\\text{s}\\) \\(5{\\small,}000\\text{m}^3/\\text{s}\\).","code":"assessment <- model_assessment(df$max, \"GEV\", \"L-moments\")  plot_sffa_assessment(assessment)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"list-of-tests","dir":"Articles","previous_headings":"","what":"List of Tests","title":"Trend Identification (Mean)","text":"Mean Trend Tests Stationarity Tests Variability Trend Tests Trend Estimation (Mean & Variability)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Trend Identification (Mean)","text":"vignette explore data Bow River Banff (05BB001) hydrological monitoring station. remoteness station means trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"mann-kendall-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Mann-Kendall Test","title":"Trend Identification (Mean)","text":"Mann-Kendall test non-parametric test used detect monotonic trends time series. null hypothesis, trend. Pass vector annual maximum series (AMS) data eda_mk_test() perform Mann-Kendall test. Conclusion: p-value \\(0.0067\\), reject null hypothesis. statistical evidence trend mean.","code":"mk_test <- eda_mk_test(df$max)  print(mk_test$p_value) #> [1] 0.006773098"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"spearman-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Spearman Test","title":"Trend Identification (Mean)","text":"Spearman test used check serial correlation, can cause Mann-Kendall test identify spurious trend. smallest lag serial correlation statistically significant known “least lag”.  Conclusion: least lag 1 provides evidence serial correlation.","code":"spearman_test <- eda_spearman_test(df$max)  print(spearman_test$least_lag) #> [1] 1  plot_spearman_test(spearman_test)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"further-tests","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Further Tests","title":"Trend Identification (Mean)","text":"Spearman test identified serial correlation, use BBMK test (eda_bbmk_test) check monotonic trend serial correlation. BBMK test uses reshuffling procedure remove serial correlation data. Phillips-Perron (eda_pp_test) KPSS (eda_kpss_test) tests used check unit root (stochastic trend) data. unit root extreme type serial correlation creates unpredictable variation data. Since find evidence serial correlation Spearman test, necessary apply tests. Phillips-Perron KPSS tests opposite hypotheses: Phillips-Perron assumes presence unit root null hypothesis, KPSS test .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Sen’s Trend Estimator","title":"Trend Identification (Mean)","text":"Mann-Kendall identified significant monotonic trend, estimate slope intercept. can estimate monotonic trend using Sen’s trend estimator, uses non-parametric approach robust outliers. eda_sens_trend() takes two arguments: annual maximum series corresponding vector years. , plot_ams_data() can used generate plot results. requires AMS data corresponding vector years. also takes optional arguments plot_mean plot_variability plotting trend mean variability respectively.  Note: covariate computed using formula \\((\\text{years} - 1900) / 100\\).","code":"plot_ams_data(     df$max,     df$year,     plot_mean = \"Trend\",     title = \"Sen's Trend Estimator (AMS Mean)\" )"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"runs-test","dir":"Articles","previous_headings":"Assessing Trends in the Mean","what":"Runs Test","title":"Trend Identification (Mean)","text":"previous statistical tests assumed nonstationarity linear. runs test assess feasibility linearity assumption checking residuals randomness. Alternatively, plot_ams_data() can used run Sen’s trend estimator data /variability series plot results. takes optional arguments plot_mean plot_variability addition data years.  Conclusion: p-value \\(0.682\\), evidence linear trend suitable data.","code":"sens_trend <- eda_sens_trend(df$max, df$year)  runs_test <- eda_runs_test(sens_trend$residuals, df$year)  print(runs_test$p_value) #> [1] 0.4392721  plot_runs_test(runs_test, title = \"Runs Test (AMS Mean)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-mean.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Trend Identification (Mean)","text":"Mann-Kendall test identified evidence nonstationarity mean AMS. Spearman test find evidence serial correlation, validating results Mann-Kendall test. runs test found linear model suitable nonstationarity. Flood frequency analysis dataset requires time-dependent probability model. Recommendation: Use NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"list-of-tests","dir":"Articles","previous_headings":"","what":"List of Tests","title":"Trend Identification (Variability)","text":"Mean Trend Tests Stationarity Tests Variability Trend Tests Trend Estimation (Mean & Variability)","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Trend Identification (Variability)","text":"vignette explore data Chilliwack River Chilliwack Lake (08MH016) hydrological monitoring station. remoteness station means trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-08MH016.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-08MH016.csv\") head(df) #>   year  max #> 1 1922 62.9 #> 2 1923 74.5 #> 3 1924 79.0 #> 4 1925 35.1 #> 5 1926 62.3 #> 6 1927 65.7  plot_ams_data(df$max, df$year, title = \"Chilliwack River at Chilliwack Lake (08MH016)\")"},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"mwmk-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"MWMK Test","title":"Trend Identification (Variability)","text":"MWMK test used detect trends variability time series. First, moving-window algorithm used estimate variability AMS data. , Mann-Kendall test applied series standard deviations check trend. data_mw_variability estimates moving-window standard deviations eda_mk_test function performs Mann-Kendall test. Conclusion: p-value \\(0.0015\\), reject null hypothesis. evidence linear trend variability data.","code":"mw <- data_mw_variability(df$max, df$year) mwmk_test <- eda_mk_test(mw$std) print(mwmk_test$p_value) #> [1] 0.001463998"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"white-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"White Test","title":"Trend Identification (Variability)","text":"White test checks heteroskedasticity, general time-dependence variability. null hypothesis homoskedasticity, constant variability data. Conclusion: p-value \\(0.1176\\), fail reject null hypothesis. statistical evidence heteroskedasticity.","code":"white_test <- eda_white_test(df$max, df$year) print(white_test$p_value) #> [1] 0.1175955"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"sens-trend-estimator","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"Sen’s Trend Estimator","title":"Trend Identification (Variability)","text":"previous tests provide evidence monotonic trend variability, estimate slope intercept trend. can estimate monotonic trend using Sen’s trend estimator, uses nonparametric approach robust outliers. eda_sens_trend() takes two arguments: data (either annual maximum series vector standard deviations) corresponding vector years. Alternatively, plot_ams_data() can used run Sen’s trend estimator data /variability series plot results. takes optional arguments plot_mean plot_variability addition data years.  Note: covariate computed using formula \\((\\text{years} - 1900) / 100\\).","code":"plot_ams_data(     df$max,     df$year,     plot_mean = \"Constant\",     plot_variability = \"Trend\",     title = \"Sen's Trend Estimator (AMS Variability)\" )"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"runs-test","dir":"Articles","previous_headings":"Assessing Trends in the Variance","what":"Runs Test","title":"Trend Identification (Variability)","text":"Sen’s trend estimator assumed nonstationarity linear. runs test assess feasibility linearity assumption checking residuals randomness. residuals random (null hypothesis), evidence underlying trend linear. eda_runs_test() function takes residuals eda_sens_trend() first argument observation years second argument.  Conclusion: p-value \\(0.3311\\), fail reject null hypothesis. evidence residuals random linear trend suitable data.","code":"sens_trend <- eda_sens_trend(mw$std, mw$year)  runs_test <- eda_runs_test(sens_trend$residuals, mw$year)  print(runs_test$p_value) #> [1] 0.3311375  plot_runs_test(runs_test, title = \"Runs Test (AMS Variability)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/trend-variability.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Trend Identification (Variability)","text":"MWMK White tests find evidence nonstationarity variability AMS. runs test confirms linear model suitable nonstationarity. Flood frequency analysis dataset requires time-dependent probability model. Recommendation: Use NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/articles/wrapper-functions.html","id":"case-study","dir":"Articles","previous_headings":"","what":"Case Study","title":"Using Wrapper Functions for Framework Orchestration","text":"vignette explore data Bow River Banff (05BB001), station Reference Hydrometric Basin Network. station unregulated, suggests trends annual maxima caused changes climate opposed changes land use cover. Data station provided CAN-05BB001.csv ffaframework package.","code":"library(ffaframework)  df <- data_local(\"CAN-05BB001.csv\") head(df) #>   year max #> 1 1909 314 #> 2 1910 230 #> 3 1911 264 #> 4 1912 174 #> 5 1913 232 #> 6 1914 214  plot_ams_data(df$max, df$year, title = \"Bow River at Banff (05BB001)\")"},{"path":"https://rileywheadon.github.io/ffa-package/articles/wrapper-functions.html","id":"exploratory-data-analysis-with-framework_eda","dir":"Articles","previous_headings":"","what":"Exploratory Data Analysis with framework_eda","title":"Using Wrapper Functions for Framework Orchestration","text":"Exploratory data analysis, first module FFA framework, identifies change points nonstationary trends data. entire module orchestrated framework_eda wrapper function, takes following arguments: data: annual maximum series observations. years: corresponding vector years. ns_splits: list years used split data prior trend detection. generate_report: TRUE, report generated based report_path report_formats. report_path: directory report saved. report_formats: list file formats (\"md\", \"pdf\", \"json\", \"html\") report. framework_eda function also returns list recommendations, including approach (either S-FFA, NS-FFA, piecewise NS-FFA), list split points, list nonstationary structures. recommendations item, can see FFA framework recommends split point 1974. Since use ns_splits argument, trend detection run complete time series. monotonic trend location identified period.","code":"results <- framework_eda(df$max, df$year, generate_report = FALSE)  print(results$recommendations) #> $approach #> [1] \"Piecewise NS-FFA\" #>  #> $ns_splits #> [1] 1974 #>  #> $ns_structures #> $ns_structures[[1]] #> $ns_structures[[1]]$location #> [1] TRUE #>  #> $ns_structures[[1]]$scale #> [1] FALSE"},{"path":"https://rileywheadon.github.io/ffa-package/articles/wrapper-functions.html","id":"selecting-split-points","dir":"Articles","previous_headings":"Exploratory Data Analysis with framework_eda","what":"Selecting Split Point(s)","title":"Using Wrapper Functions for Framework Orchestration","text":"change point detection vignette discussed multiple criteria selecting split point. first important criteria physical justification split point. case study, physical justification split point since basin unregulated. However, cases less information, often useful investigate results Pettitt MKS tests carefully. framework_eda function allows us () reading report, (b) using submodules object. submodules object list two elements: results change point detection results trend detection.   plots, can see change point 1974 identified Pettitt test, change point barely significance threshold.","code":"pettitt_results <- results$submodules[[1]]$tests$pettitt mks_results <- results$submodules[[1]]$tests$mks  plot_pettitt_test(pettitt_results) plot_mks_test(mks_results)"},{"path":"https://rileywheadon.github.io/ffa-package/articles/wrapper-functions.html","id":"flood-frequency-analysis-with-framework_full","dir":"Articles","previous_headings":"","what":"Flood Frequency Analysis with framework_full","title":"Using Wrapper Functions for Framework Orchestration","text":"Using results EDA knowledge station, clear nonstationary approach split points trend location parameter best model dataset. perform FFA, can either use framework_ffa function (perform FFA) framework_full method (perform EDA FFA). functions take arguments framework_eda function, addition ns_structures, specifies nonstationary model structure homogeneous subperiod. case, decided split data, ns_structures consist single list describing model structure entire time series. vignette use framework_full wrapper function run complete FFA framework generate report. framework_full wrapper function returns list following three items: recommendations: recommended approach, split points, model structures EDA. summary: approach, split points, model structures used FFA. submodules: results EDA (change point detection trend detection) FFA (distribution selection, parameter estimation, uncertainty quantification, model assessment). Note: code snippet shown run outside vignette environment reduce compilation time. resulting report can found .","code":"framework_full(     df$max,     df$year,     ns_splits = NULL,     ns_structures = list(list(location = TRUE, scale = FALSE)),     generate_report = TRUE,     report_path = \"~\",     report_formats = \"html\" )"},{"path":"https://rileywheadon.github.io/ffa-package/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Riley Wheadon. Author, maintainer. Cuauhtémoc Vidrio-Sahagún. Author. Alain Pietroniro. Author, funder. Jianxun . Author. Environment Climate Change Canada (ECCC). Funder.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Vidrio-Sahagún C, Ruschkowski J, J, Pietroniro (2024). “practice-oriented framework stationary nonstationary flood frequency analysis.” Environmental Modelling Software, 173(105940). doi:10.1016/j.envsoft.2024.105940.","code":"@Article{,   title = {A practice-oriented framework for stationary and nonstationary flood frequency analysis},   author = {Cuauhtémoc Vidrio-Sahagún and Jake Ruschkowski and Jianxun He and Alain Pietroniro},   journal = {Environmental Modelling and Software},   year = {2024},   volume = {173},   number = {105940},   doi = {10.1016/j.envsoft.2024.105940}, }"},{"path":"https://rileywheadon.github.io/ffa-package/index.html","id":"ffa-framework-wiki","dir":"","previous_headings":"","what":"Flood Frequency Analysis Framework","title":"Flood Frequency Analysis Framework","text":"FFA Framework open-source tool flood frequency analysis (FFA) designed support systematic repeatable workflows stationary nonstationary analysis. Development ongoing University Calgary University Saskatchewan Canada. recent version framework freely available R package. original version released stand-alone GUI MATLAB source code published Vidrio-Sahagún et al. (2024). list changes MATLAB version, see .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-05BB001 — CAN_05BB001","title":"CAN-05BB001 — CAN_05BB001","text":"dataframe annual maximum series observations station 05BB001, BOW RIVER BANFF Alberta, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-05BB001 — CAN_05BB001","text":"","code":"CAN_05BB001"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-05BB001 — CAN_05BB001","text":"dataframe 110 rows 2 columns spanning period 1909-2018.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-05BB001 — CAN_05BB001","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-05BB001 — CAN_05BB001","text":"Variables: max: Numeric; observed annual maximum series, m\\(^3\\)/s. year: Integer; corresponding years.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-05BB001 — CAN_05BB001","text":"unregulated station RHBN. Whitfield & Pomeroy (2016) found floods may caused rain, snow, combination . Therefore, practitioners careful interpreting results FFA. Minimal human intervention basin means little justification change points. EDA finds evidence decreasing trend mean.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_05BB001.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CAN-05BB001 — CAN_05BB001","text":"Whitfield P. H., Pomeroy J. W. (2016) Changes flood peaks mountain river: implications analysis 2013 flood Upper Bow River, Canada, Hydrological Processes, 30: 4657–4673. doi:10.1002/hyp.10957 .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-07BE001 — CAN_07BE001","title":"CAN-07BE001 — CAN_07BE001","text":"dataframe annual maximum series observations station 07BE001, ATHABASCA RIVER ATHABASCA Alberta, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-07BE001 — CAN_07BE001","text":"","code":"CAN_07BE001"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-07BE001 — CAN_07BE001","text":"dataframe 108 rows 2 columns spanning period 1913-2020.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-07BE001 — CAN_07BE001","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-07BE001 — CAN_07BE001","text":"Variables: max: Numeric; observed annual maximum series, m\\(^3\\)/s. year: Integer; corresponding years.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_07BE001.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-07BE001 — CAN_07BE001","text":"unregulated station RHBN. Additionally, MKS/Pettitt tests find evidence change points 0.05 significance level. Trend detection finds evidence trends mean variability. dataset excellent introductory example stationary FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08MH016 — CAN_08MH016","title":"CAN-08MH016 — CAN_08MH016","text":"dataframe annual maximum series observations station 08MH016, CHILLIWACK RIVER CHILLIWACK LAKE British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08MH016 — CAN_08MH016","text":"","code":"CAN_08MH016"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08MH016 — CAN_08MH016","text":"dataframe 95 rows 2 columns spanning period 1922-2016.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08MH016 — CAN_08MH016","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08MH016 — CAN_08MH016","text":"Variables: max: Numeric; observed annual maximum series, m\\(^3\\)/s. year: Integer; corresponding years.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08MH016.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08MH016 — CAN_08MH016","text":"unregulated station RHBN. Additionally, MKS/Pettitt tests find evidence change points 0.05 significance level. Trend detection finds evidence increasing trend variability.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08NH021 — CAN_08NH021","title":"CAN-08NH021 — CAN_08NH021","text":"dataframe annual maximum series observations station 08NH021, KOOTENAI RIVER PORTHILL British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08NH021 — CAN_08NH021","text":"","code":"CAN_08NH021"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08NH021 — CAN_08NH021","text":"dataframe 91 rows 2 columns spanning period 1928-2018.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08NH021 — CAN_08NH021","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08NH021 — CAN_08NH021","text":"Variables: max: Numeric; observed annual maximum series, m\\(^3\\)/s. year: Integer; corresponding years.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NH021.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08NH021 — CAN_08NH021","text":"regulated station RHBN. Additionally, Libby dam constructed upstream station 1972. Pettitt test finds evidence change point 1972 0.05 significance level. MKS test finds evidence change points 1960 & 1985 0.05 significance level. dataset excellent introduction change point detection piecewise NS-FFA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":null,"dir":"Reference","previous_headings":"","what":"CAN-08NM050 — CAN_08NM050","title":"CAN-08NM050 — CAN_08NM050","text":"dataframe annual maximum series observations station 08NM050, OKANAGAN RIVER PENTICTON British Columbia, Canada.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CAN-08NM050 — CAN_08NM050","text":"","code":"CAN_08NM050"},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"CAN-08NM050 — CAN_08NM050","text":"dataframe 97 rows 2 columns spanning period 1921-2017.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"CAN-08NM050 — CAN_08NM050","text":"Meteorological Service Canada (MSC) GeoMet Platform","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CAN-08NM050 — CAN_08NM050","text":"Variables: max: Numeric; observed annual maximum series, m\\(^3\\)/s. year: Integer; corresponding years.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/CAN_08NM050.html","id":"additional-information","dir":"Reference","previous_headings":"","what":"Additional Information","title":"CAN-08NM050 — CAN_08NM050","text":"regulated station part RHBN. Okanagan River upstream station regulated since 1914 due construction first dam, followed second dam 1920, regulation system early 1950s, consisting four dams 38 km engineered channel. Rapid human settlement, development, agricultural activity also occurred watershed. dataset exhibits serial correlation trends mean variability. Since station heavily influenced reservoir operations, dataset intended teaching purposes—practical flood estimation.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":null,"dir":"Reference","previous_headings":"","what":"Decompose Annual Maximum Series — data_decomposition","title":"Decompose Annual Maximum Series — data_decomposition","text":"Decomposes nonstationary annual maxima series derive stationary stochastic component, can used identify best-fit distribution using conventional stationary methods, like based L-moments. decomposition procedure follows proposed Vidrio-Sahagún (2022), relies statistical representation nonstationary stochastic processes.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decompose Annual Maximum Series — data_decomposition","text":"","code":"data_decomposition(data, ns_years, ns_structure)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decompose Annual Maximum Series — data_decomposition","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decompose Annual Maximum Series — data_decomposition","text":"Numeric vector decomposed data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decompose Annual Maximum Series — data_decomposition","text":"Internally, function following: trend location, fit Sen's trend estimator subtract away fitted trend. trend scale, estimate variability data data_mw_variability(), fit Sen's trend estimator variability vector, rescale data remove trend. necessary, shift data minimum least 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Decompose Annual Maximum Series — data_decomposition","text":"Vidrio-Sahagún, C. T., , J. (2022). decomposition-based nonstationary flood frequency analysis. Journal Hydrology, 612 (September 2022), 128186. doi:10.1016/j.jhydrol.2022.128186","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_decomposition.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decompose Annual Maximum Series — data_decomposition","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE) data_decomposition(data, ns_years, ns_structure) #>   [1] 102.48618  75.49338  99.74332 105.94756 111.14916  81.37988  97.05781 #>   [8]  97.02208  96.57003  93.79310 105.55292 119.84636  82.81923 104.18640 #>  [15]  80.36503  93.70802  98.33514 104.22413  89.58643 103.34173 102.22271 #>  [22]  85.48077 105.83698 117.27727  97.35078  88.89977  98.03175  89.85637 #>  [29]  82.93328 107.34391  99.68818 100.29315 114.02480  98.84270  96.31536 #>  [36]  78.48746  94.72897  94.31990 108.06044  98.02072  90.86215  96.68674 #>  [43]  94.60457 101.50038 124.53960  97.38374 102.62853  97.96640  77.60025 #>  [50] 105.27133  94.15111  94.45562  96.64127  96.67811 101.81379  73.50738 #>  [57] 123.00711  92.50233  98.18111 106.72402  89.26269 106.98611  93.32063 #>  [64]  83.93697  85.88710 106.22919  96.82833 100.33093  78.38314  80.60329 #>  [71]  98.08517 108.54988  97.47665 108.22563 100.21480 100.97619  93.74237 #>  [78]  96.49655  93.80447 113.88418 107.55769 101.99468 100.00202  88.89021 #>  [85] 105.41115  68.11546  92.61488  98.44372  90.21832  98.21272 104.53487 #>  [92] 104.32399  93.38884  98.56437 110.36472  90.02529 102.96539 106.60318 #>  [99]  90.40153  89.42880"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Data from MSC GeoMet API — data_geomet","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"Gets annual maximum series data hydrological monitoring station MSC GeoMet API.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"","code":"data_geomet(station_id)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"station_id character scalar containing ID hydrological monitoring station. can search station IDs name, province, drainage basin, location .","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"dataframe two columns: max: float, annual maximum series observation, m\\(^3\\)/s. year: integer, corresponding year.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_geomet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch Data from MSC GeoMet API — data_geomet","text":"","code":"# Get data for the BOW RIVER AT BANFF (05BB001) df <- data_geomet(\"05BB001\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Local Package Data — data_local","title":"Fetch Local Package Data — data_local","text":"Fetch annual maximum series data hydrological monitoring station package data directory.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Local Package Data — data_local","text":"","code":"data_local(csv_file)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Local Package Data — data_local","text":"csv_file character scalar containing file name local dataset /inst/extdata. Must one : \"CAN-05BA001.csv\": BOW RIVER LAKE LOUISE \"CAN-05BB001.csv\": BOW RIVER BANFF \"CAN-07BE001.csv\": ATHABASCA RIVER ATHABASCA \"CAN-08MH016.csv\": CHILLIWACK RIVER CHILLIWACK LAKE \"CAN-08NH021.csv\": KOOTENAI RIVER PORTHILL \"CAN-08NM050.csv\": OKANAGAN RIVER PENTICTON \"CAN-08NM116.csv\": MISSION CREEK NEAR EAST KELOWNA","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Local Package Data — data_local","text":"dataframe two columns: max: float, annual maximum series observation, m\\(^3\\)/s. year: integer, corresponding year.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_local.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch Local Package Data — data_local","text":"","code":"# Get data for the BOW RIVER AT BANFF (05BB001) df <- data_local(\"CAN-05BB001.csv\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"Generates time series standard deviations using moving window algorithm, can used explore potential evidence nonstationarity variability dataset. returns list pairs window’s mean year window standard deviation. hyperparameters size step control behaviour moving window. Following simulation findings Vidrio-Sahagún (2022), default window size step set 10 5 years respectively. However, can changed user.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"","code":"data_mw_variability(data, years, size = 10L, step = 5L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. size Integer scalar. number years moving window. Must positive number less equal length(data) (default 10). step Integer scalar. offset (years) successive moving windows. Must positive number (default 5).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"list two entries: years: Numeric vector containing mean year within window. std: Numeric vector standard deviations within window.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"Vidrio-Sahagún, C. T., , J. (2022). decomposition-based nonstationary flood frequency analysis. Journal Hydrology, 612 (September 2022), 128186. doi:10.1016/j.jhydrol.2022.128186","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_mw_variability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Variance for Annual Maximum Series Data — data_mw_variability","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) data_mw_variability(data, years) #> $std #>  [1]  7.979322 11.091337 10.834792  7.833379  6.918857  8.207443  9.093049 #>  [8] 11.037079 10.865376  8.024952  8.950729 10.082149  9.835107  8.926596 #> [15] 13.342132 15.260867 11.322819  8.959743  7.579580 #>  #> $year #>  [1] 1905.5 1910.5 1915.5 1920.5 1925.5 1930.5 1935.5 1940.5 1945.5 1950.5 #> [11] 1955.5 1960.5 1965.5 1970.5 1975.5 1980.5 1985.5 1990.5 1995.5 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_screening.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform Data Screening — data_screening","title":"Perform Data Screening — data_screening","text":"Checks missing entries generates list summary statistics dataset.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_screening.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform Data Screening — data_screening","text":"","code":"data_screening(data, years)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_screening.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform Data Screening — data_screening","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_screening.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform Data Screening — data_screening","text":"list seven entries: years_min: minimum value 'years' argument. years_max: maximum value 'years' argument. data_min: minimum value 'data' argument. data_med: median value 'data' argument. data_max: maximum value 'data' argument. missing_years: integer vector years data. missing_count: number missing entries dataset.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/data_screening.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform Data Screening — data_screening","text":"","code":"data <- rnorm(n = 10, mean = 100, sd = 10) years <- c(1900, 1902, 1903, 1904, 1905, 1907, 1909, 1911, 1912, 1914) data_screening(data, years) #> $years_min #> [1] 1900 #>  #> $years_max #> [1] 1914 #>  #> $data_min #> [1] 79.36346 #>  #> $data_med #> [1] 95.13092 #>  #> $data_max #> [1] 126.4893 #>  #> $missing_years #> [1] 1901 1906 1908 1910 1913 #>  #> $missing_count #> [1] 5 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"Performs bootstrapped version Mann-Kendall trend test adjust serial correlation annual maximum series data. BBMK test uses Spearman’s serial correlation test identify least insignificant lag, applies shuffling procedure obtain empirical p-value confidence bounds Mann-Kendall test statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"","code":"eda_bbmk_test(data, alpha = 0.05, samples = 10000L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: Mann-Kendall S-statistic computed original series. bootstrap: Vector bootstrapped Mann-Kendall test statistics. p_value: Empirical two-sided p-value derived bootstrap distribution. bounds: Empirical confidence interval bounds bootstrap distribution. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"block size reshuffling equal least_lag estimated eda_spearman_test(). Bootstrap samples generated resampling blocks original data without replacement. procedure effectively removes serial correlation data.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"Bayazit, M., 2015. Nonstationarity hydrological records recent trends trend analysis: state---art review. Environmental Processes 2 (3), 527–542. doi:10.1007/s40710-015-0081-7 Khaliq, M.N., Ouarda, T.B.M.J., Gachon, P., Sushama, L., St-Hilaire, ., 2009. Identification hydrological trends presence serial cross correlations: review selected methods application annual flow regimes Canadian rivers. Journal Hydrolology 368 (1–4), 117–130. doi:10.1016/j.jhydrol.2009.01.035 Sonali, P., Nagesh Kumar, D., 2013. Review trend detection methods application detect temperature changes India. Journal Hydrology 476, 212–227. doi:10.1016/j.jhydrol.2012.10.034","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_bbmk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Block-Bootstrap Mann-Kendall Test for Trend Detection — eda_bbmk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_bbmk_test(data, samples = 1000L) #> $data #>   [1] 105.58514 104.15406  85.47700 109.41206  96.61064  99.24426 100.40204 #>   [8] 101.24301  90.01567 112.33390 103.40424  95.27298 107.08753  84.71041 #>  [15] 102.37425  86.87186 107.47029  84.37482 100.71053  93.60465  91.54804 #>  [22] 106.75245 111.53376  83.13495  90.97185 113.17634 111.00190 112.03768 #>  [29]  85.68729 113.82911 100.03126  99.22113 104.41428 101.28923  91.69786 #>  [36]  94.96407  88.06359  92.48277 114.55841  91.71396 102.89774  95.19947 #>  [43]  93.95171 114.60110 101.49679  85.66679  99.89697  97.87764  90.93660 #>  [50]  78.97848 118.93360  90.31874  98.97397 102.39960 100.60899  78.22424 #>  [57]  98.82140 101.12295 100.07886 118.77744 121.58757 107.09715 107.66983 #>  [64]  96.91789 110.12002  90.80948 105.63380 103.22483 103.66674 111.29835 #>  [71]  90.58502 102.17838 114.15412  96.16267  98.25914  97.78255  89.90471 #>  [78] 104.80725 116.04407  84.84975  85.83976 108.76777 106.24132 121.12277 #>  [85]  96.43876  89.35536 110.77117 111.81576 101.98392  95.99595 106.16154 #>  [92] 119.74157 118.84662  84.11379  94.60077  88.30539 105.59106  81.80653 #>  [99] 103.93344 100.42134 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There is no monotonic trend in the mean of the data.\" #>  #> $alternative_hypothesis #> [1] \"There is a monotonic trend in the mean of the data.\" #>  #> $statistic #> [1] 244 #>  #> $bootstrap #>    [1]   756  -346  -912   498   760  -222  -116   430  -164  -476  -162  -224 #>   [13]   120  -324   -20   508  -824  -188  -374   220  -444   406    12   162 #>   [25]   260  -400   382    38  -368   110  -278   168   418   -52   -28   164 #>   [37]  -408   800   336   -28   412   318  -664   136   -52   834   138   614 #>   [49]   134  -220   290   376  -390  -214  -664   102   274   -26  -230  -378 #>   [61]   236  -238    48   132   450   -28     8    34  -352  -522   140   526 #>   [73]  -220  -166  -322    76   418  -704  -198  -230   592   408  -262  -330 #>   [85]   108   -32  -304   908  -130    58  -516    80   132   554  -248   194 #>   [97]  -172   -10   184  -178   -62  -156   300   -94  -176   -22   -90  -134 #>  [109]  -316  -174  -350   -16   170  -372    22  -386  -422   186   252    40 #>  [121]   -34   294  -372  -178  -180  -242  -334   172   160  -428   434   738 #>  [133]   288   -52   158   -76   -50   -86  -544  -954   126  -130  -496   254 #>  [145]    98  -364   192   482   -90   100  -178  -486  -512    52  -120  -212 #>  [157]   -38   372    14  -448  -406  -470   -40   166   380  -102   592  -120 #>  [169]    38   198   322   434   266   -72  -154    92   152  -740   -46  -800 #>  [181]   104  -326  -456    62   -86   220  -106   602  -456    16  -228  -594 #>  [193]  -482  -604   -52  -914   246   176  -192  -554  -140   -30  -226  -192 #>  [205]   -38   130     0  -122   486    52   196   712   354   612  -372   214 #>  [217]  -632   290   140   226   212    -6    -6   -12  -128   370    28   174 #>  [229]    12   184   232   408  -272  -250  -248    36  -332   186  -260  -130 #>  [241]   102   -56  -984   332   -96    16   328   224  -214  -190  -678   312 #>  [253]  -234   -30  -658  -408   138   586  -454   -16   258   -92   124  -280 #>  [265]  -130  -256   206  -572   170   102  -332   464   316   -12   -18    38 #>  [277]  -642  -164   -72   280     2  -156   202   278  -180  1074  -176    -4 #>  [289]  -468   106   158  -208    16  -528   232   136  -180     4  -180   428 #>  [301]  -262  -428  -552    26   410  -556  -104    50   -90  -204  -158  -286 #>  [313]  -206  -222   -16   262   312  -326   120  -208   424    66  -492   370 #>  [325]   610   238  -826   128  -158   526   158   200  -626  -132   -28  -516 #>  [337]  -216   730  -108   308  -106   158   -18  -202  -330  -226   234  -260 #>  [349]   120  -310  -206  -778    72    72   174   -80   226  -156  -510  -468 #>  [361]   518  -116  -618   134    10   -94   288    46  -248   -74   270   -76 #>  [373]  -536   800  -242   -30  -178   426   -68  -166   240   500   366  -266 #>  [385]   594  -108    62  -302  -454   156   382   -64   186   -16  -214  -116 #>  [397]  -254  -118  -282   -42  -296   534   -34  -796  -422    36   270   -88 #>  [409]   -72   116    60  -512   120  -126   240  -348   114   -40  -168    26 #>  [421]    92  -158  -122   498   312  -294   770   198   500  -352    90   192 #>  [433]    86  -168  -372    96   180   240  -584  -806  -214   244  -364  -576 #>  [445]   264  -422   266  -450    18   -98  -338   368  -184  -550   574  -290 #>  [457]   516  -108  -354  -108  -102  -396   350  -136   122   618    68  -300 #>  [469]  -166  -178   206  -360  -338   142    44     8    84   -62  -426  -590 #>  [481]  -340   496  -158     4   192    40   162   234   -68  -428   280   108 #>  [493]   308  -426  -314   -84  -172   180  -370    88  -110   350   368   430 #>  [505]  -720   454   922  -182   198  -144    14   -48  -212   578   198   308 #>  [517]  -584   470   510  -136  -448  -130  -284   118   424  -226   332   774 #>  [529]  -204  -178    86  -216   -92    10  -152  -132    68   -40  -706  -234 #>  [541]   144   198   642   104   490  -160   710  -358   494  -460  -108   238 #>  [553]    22  -104  -472  -778   220  -832  -542  -122  -286  -234   308   -68 #>  [565]    82   130     4  -236    14  -220   180   116  -132   436   192  -280 #>  [577]  -176    18   -52  -318   244   438   224   -58   -92    44  -392   122 #>  [589]   152   768   254   -92  -112  -446   252   284   276   406   120  -352 #>  [601]   220  -186   348  -482  -192   148    88   408  -140   304  -102   316 #>  [613]  -212   536  -720  -482  -108  -236  -220  -304  -242   180   -64  -176 #>  [625]  -510    66   -30   262  -416   490   252    84   334   286  -144   152 #>  [637]  -134   610  -368  -356    18   276  -166   -96  -384  -738    94  -240 #>  [649]   456   -20  -240  -562  -308  -720  -438  -272  -510  -486    72  -182 #>  [661]    12  -110  -108   166    90  -196   -22  -294   -20  -602   126    50 #>  [673]  -280    40   458   -92   166    26   -24   106  -330   370  -384  -140 #>  [685]   -34  -184   246  -358   216  -424    40   -74  -366  -676   240  -278 #>  [697]    78   376  -124    42   562    86  -100   -20    52   -56  -160   -18 #>  [709]   222    92   414   -62   -38   182  -274  -124  -526   104   412   390 #>  [721]   314    20  -386  -306  -470  -396    36  -482  -216    22   302  -430 #>  [733]   812     2  -290   636   152  -118   302   824   -46   384  -410  -350 #>  [745]  -344   630   -74  -378   448   624   392   240  -460  -246    20  -136 #>  [757]   244  -800  -228  -234   152   168   756  -252   596  -276  -892  -428 #>  [769]   150  -198    28   548   836  -378   496  -194   346    74    22  -296 #>  [781]   602  -240  -426  -556     0  -144  -292  -134  -252  -100   368  -204 #>  [793]  -552  -244   -76   128  -314  -706  -274    82   -16  -474   252   120 #>  [805]  -214  -154  -298  -526   224  -292   224   128  -454  -270   328  -126 #>  [817]   178  -364    68   926    50   120    98   452   478    58  -108   344 #>  [829]    80  -468  -258  -114  -274   404    70  -330  -170  -410   364  -738 #>  [841]   286    -8  -134   -74   -26   294  -312   152   -10   372  -374   722 #>  [853]   420  -134   -20   108   546   288  -284    46   -34  -122   102   -20 #>  [865]   -74  -480   214   488   316   -76 -1088   338  -416   480   -66  -284 #>  [877]  -376   -68   568   224  -434   -60    28  -226   584     0     0   348 #>  [889]   166   -34   -76   168   618  -362  -164    62   -38  -272   320  -246 #>  [901]   278  -594  -400   148  -280  -456  -268   352  -142  -312   398   -94 #>  [913]  -498   -68  -128  -384   456  -152   190  -504    44  -302   426  -324 #>  [925]    14  -158  -288   390   -60    42   624   138    34  -176   112   458 #>  [937]   -90    70    16   102  -162   530  -252   294  -318   240   722  -326 #>  [949]   206  -280   204   382   764   326  -558  -144  -316  -166   410   656 #>  [961]   114  -438  -148   482  -144   444  -190   326  -398   290  -222   414 #>  [973]  -534  -212   366   -98  -216  -654   250   842  -138    36  -168   304 #>  [985]   322  -276   320  -196   218  -184   302   170   560    38   -12   148 #>  [997]  -384  -160   642   402 #>  #> $p_value #> [1] 0.432 #>  #> $bounds #>    2.5%   97.5%  #> -676.05  642.35  #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"Performs KPSS unit root test annual maximum series data. null hypothesis time series trend-stationary linear deterministic trend constant drift. alternative hypothesis time series unit root (also known stochastic trend).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"","code":"eda_kpss_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: KPSS test statistic. p_value: interpolated p-value. See details information. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"implementation KPSS test based aTSA package, interpolates significance table Hobijn et al. (2004). Therefore, result \\(p = 0.01\\) implies \\(p \\leq 0.01\\) result \\(p = 0.10\\) implies \\(p \\geq 0.10\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"Hobijn, B., Franses, P.H. Ooms, M. (2004), Generalizations KPSS-test stationarity. Statistica Neerlandica, 58: 483-502. Kwiatkowski, D.; Phillips, P. C. B.; Schmidt, P.; Shin, Y. (1992). Testing null hypothesis stationarity alternative unit root. Journal Econometrics, 54 (1-3): 159-178.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_kpss_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Kwiatkowski–Phillips–Schmidt–Shin (KPSS) Unit Root Test — eda_kpss_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_kpss_test(data) #> $data #>   [1] 100.12387  98.95186 107.50888  97.77118  93.79625 113.14000 116.23621 #>   [8]  88.10228 101.15881 116.18140  99.90063  92.66700 106.42069 108.95565 #>  [15]  91.35165 100.35780 107.02140 110.87775 110.32847 112.30771  90.03516 #>  [22]  90.82555  94.35715 103.97653  99.42904  94.74145 104.28256  89.53636 #>  [29] 116.11412  90.69241 103.37862 105.22782  82.64148 109.39183 105.45024 #>  [36]  84.75166  94.25823 111.23967  86.69933  97.37938  96.58283 111.08042 #>  [43] 114.25324  99.55259  98.79250 106.57130 110.35033  88.61991  93.08293 #>  [50] 100.83571 104.75665 102.37172  92.25124 103.24165 108.40478 116.61977 #>  [57] 111.01600 108.00191 104.89789 108.15966  75.26442  89.19149 105.21227 #>  [64]  86.71029 118.16608 102.27068  87.32682 106.03875  88.81822 103.22338 #>  [71] 102.98355 114.61274 119.20752  89.24305  93.12479 106.15612  99.96043 #>  [78] 100.60333  97.72133  91.09217  99.29099  87.82165  96.03174 116.78254 #>  [85] 119.72330  98.41525  96.38403  92.93475 108.29597  92.21121  96.49941 #>  [92]  94.03990  95.46888  87.32682  93.65167 106.19333 105.58708  99.05894 #>  [99]  99.19472 100.19550 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The time series is trend-stationary.\" #>  #> $alternative_hypothesis #> [1] \"The time series has a unit root (stochastic trend).\" #>  #> $statistic #> [1] 0.03306532 #>  #> $p_value #> [1] 0.1 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann–Kendall Trend Test — eda_mk_test","title":"Mann–Kendall Trend Test — eda_mk_test","text":"Performs Mann–Kendall trend test numeric vector detect presence increasing decreasing monotonic trend time. test nonparametric accounts tied observations data. null hypothesis assumes monotonic trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann–Kendall Trend Test — eda_mk_test","text":"","code":"eda_mk_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann–Kendall Trend Test — eda_mk_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann–Kendall Trend Test — eda_mk_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: Mann–Kendall test statistic. variance: variance test statistic null hypothesis. p_value: p-value associated two-sided hypothesis test. reject: Logical. TRUE, null hypothesis rejected alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mann–Kendall Trend Test — eda_mk_test","text":"test statistic \\(S\\) sum pairs \\(< j\\) sign difference \\(x_j - x_i\\). Ties explicitly accounted calculating variance \\(S\\), using grouped frequencies tied observations. test statistic \\(Z\\) computed based sign magnitude \\(S\\), p-value derived standard normal distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mann–Kendall Trend Test — eda_mk_test","text":"Kendall, M. (1975). Rank Correlation Methods. Griffin, London, 202 pp. Mann, H. B. (1945). Nonparametric Tests Trend. Econometrica, 13(3): 245-25","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann–Kendall Trend Test — eda_mk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_mk_test(data) #> $data #>   [1] 107.34841  99.84156  88.23479  97.79369 115.64516 111.22041 104.63076 #>   [8] 106.33357  95.12631  89.60322  75.68793 102.59373  96.36258 110.89977 #>  [15] 107.88251 105.74549  98.24206 100.42963 101.62222  97.24310  99.82175 #>  [22] 102.24486  83.05105  98.18668 108.51155 105.74684 107.53031  92.67545 #>  [29]  85.09204  98.48259  96.75074 111.55520  98.43460 110.63326 102.35489 #>  [36] 120.92595  83.07251  89.94641 116.74478  95.62255 113.27158 114.27544 #>  [43]  84.60421 111.82677 106.54959 113.19297  95.98798  94.25990  81.96696 #>  [50] 100.44151 100.24345 111.49112  97.26690  94.35158 107.04075 105.20372 #>  [57] 107.43372 101.73053 109.10044  93.58330  88.93986  92.14111 105.30740 #>  [64] 112.18120  84.70178 105.51114  94.83542  96.01779 103.24808 107.26851 #>  [71]  96.57706  94.41080  96.02413  99.10775 110.40952 102.40919  96.55350 #>  [78]  91.02249  98.98338  92.13937  90.92910 114.08476 102.50388  94.02291 #>  [85]  94.74065  94.91006  92.55806  91.13979 118.16085  83.30854 111.22617 #>  [92] 107.17357  96.59280  99.14638 103.38835  96.73917 101.31666  98.82788 #>  [99] 108.98828 110.77115 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There is no monotonic trend in the mean of the data.\" #>  #> $alternative_hypothesis #> [1] \"There is a monotonic trend in the mean of the data.\" #>  #> $statistic #> [1] -202 #>  #> $variance #> [1] 112750 #>  #> $p_value #> [1] 0.5494387 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"Performs Mann–Kendall–Sneyers (MKS) test detect trend change annual maximum series data. test computes normalized progressive regressive Mann–Kendall statistics identifies statistically significant crossing points, indicating potential change points. null hypothesis, trend changes.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"","code":"eda_mks_test(data, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"list containing test results, including: data: data argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. progressive_series: Normalized progressive Mann–Kendall-Sneyers statistics. regressive_series: Normalized regressive Mann–Kendall-Sneyers statistics. bound: Critical confidence bound significance based alpha. change_points: dataframe potential change points. p_value: Two-sided p-value significant crossing point. reject: TRUE, null hypothesis rejected significance alpha. change_points contains years, test statistics, p-values potential change point. change points identified, change_points empty.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"function computes progressive regressive Mann–Kendall-Sneyers statistics, normalized expected values variances null hypothesis. crossing points occur difference progressive regressive statistics switches sign. significance detected crossing points assessed using quantiles normal distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"Sneyers, R. (1990). statistical analysis series observations. Technical note . 143, World Meteorological Organization, Geneva.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_mks_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mann–Kendall–Sneyers Test for Change Point Detection — eda_mks_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_mks_test(data, years) #> $data #>   [1]  85.54915  85.71614  97.22417 101.68775 109.77722 102.96900  97.91774 #>   [8]  96.94300 102.01555  89.55891 110.86274  85.63202 104.14338  97.27396 #>  [15] 109.76791  93.27818 107.34289 103.56664 101.41236 103.49810 109.90516 #>  [22]  95.04841 101.62542 115.25917 102.32179  94.17772  98.77404 105.29167 #>  [29] 110.10684 109.21671  99.00200  94.00343  89.97952  96.54386  96.87132 #>  [36] 118.40742  81.72863 100.76640 100.55287 103.52433  99.65863 104.98293 #>  [43] 123.86866  86.82425  89.81833  78.07199 109.07017 105.91076  95.54329 #>  [50] 109.39690  79.70020  95.64596  94.12719 107.52656 106.84281  90.71340 #>  [57] 103.15814 101.68861  89.16990  94.98362 107.85188 104.65562 106.01239 #>  [64]  98.39976  97.98901 103.80865 104.51256  96.98454  85.77457  88.90572 #>  [71]  99.96630 121.10423 111.00964  87.02501  87.80226  95.98337 124.83532 #>  [78] 100.11715  88.47333 112.44132 119.73193  89.69074 106.60512 106.76343 #>  [85] 112.06801  90.97239 104.50397 107.26423 112.04740 113.73421  93.75126 #>  [92] 100.81992 112.55942  88.79528  87.33852 100.56045 113.85555  98.87681 #>  [99]  79.61201  93.19376 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There are no trend changes in the data.\" #>  #> $alternative_hypothesis #> [1] \"There is at least one trend change in the data.\" #>  #> $progressive_series #>   [1]  0.000000000  1.000000000  1.566698904  2.038098661  2.449489743 #>   [6]  2.442274735  1.952442080  1.237179148  1.459600898  0.804984472 #>  [11]  1.479147994  0.685725481  1.098159977  0.930663132  1.336153480 #>  [16]  0.900450338  1.235778832  1.401474935  1.294466143  1.427548506 #>  [21]  1.872209169  1.438094419  1.346933276  1.835525823  1.821687529 #>  [26]  1.388617697  1.229967688  1.461982442  1.838290060  2.051718565 #>  [31]  1.852609449  1.427047875  0.991642412  0.726397723  0.497050122 #>  [36]  0.953462589  0.444681960  0.414872858  0.375003049  0.535947590 #>  [41]  0.471741401  0.682755528  1.098869154  0.707998361  0.371728151 #>  [46] -0.066277063  0.192579522  0.408849857  0.206876054  0.476796893 #>  [51]  0.073099900 -0.094692916 -0.306828112 -0.067143616  0.137931262 #>  [56] -0.113080559 -0.013767698  0.033539930 -0.255040001 -0.420943251 #>  [61] -0.174241612 -0.018222245  0.172001599  0.104285199  0.033968311 #>  [66]  0.160489018  0.297633748  0.179975652 -0.113949366 -0.380224370 #>  [71] -0.382199501 -0.038889977  0.266690857 -0.004666736 -0.260734661 #>  [76] -0.376728334 -0.035186455 -0.038830516 -0.283632770  0.008309325 #>  [81]  0.309958897  0.092102475  0.255626328  0.417213418  0.675597641 #>  [86]  0.481150167  0.575573165  0.735234995  0.978100431  1.230293801 #>  [91]  1.038762175  1.018585955  1.261153001  1.009277697  0.749116113 #>  [96]  0.728003649  0.978628544  0.917720657  0.613696486  0.440761285 #>  #> $regressive_series #>   [1] -0.44076128 -0.17231872  0.09514830  0.18076578  0.16459213 -0.03536600 #>   [7] -0.08165677 -0.01327529  0.07420163  0.04456735  0.26139387  0.04252611 #>  [13]  0.33157657  0.26029105  0.34687570  0.14422871  0.32449933  0.16124122 #>  [19]  0.09210247  0.07341132  0.01661865 -0.19896627 -0.07334653 -0.10555937 #>  [25] -0.40363750 -0.46200352 -0.33133827 -0.28574020 -0.40834476 -0.65023552 #>  [31] -0.88719020 -0.88051783 -0.75166302 -0.56820988 -0.48146706 -0.39629696 #>  [37] -0.72999640 -0.40924518 -0.43125981 -0.43560403 -0.49747839 -0.47738257 #>  [43] -0.59701075 -0.99127424 -0.67848335 -0.47187011 -0.08206442 -0.32216952 #>  [49] -0.45768243 -0.33301066 -0.59390490 -0.20687605 -0.07110432  0.10087499 #>  [55] -0.12308597 -0.33259887 -0.10114262 -0.15698131 -0.20591040  0.06739163 #>  [61]  0.25632276  0.03629062 -0.08800333 -0.23541986 -0.16345073 -0.07100716 #>  [67] -0.13341999 -0.24791060 -0.16216453  0.32293192  0.66011815  0.78783860 #>  [73]  0.31610431  0.10423455  0.63920497  1.16774842  1.43865537  0.92436597 #>  [79]  1.09971926  1.69102764  1.42754851  0.87463929  1.40147494  1.40054934 #>  [85]  1.35067551  1.03923048  1.58760181  1.58623108  1.50859606  1.32344821 #>  [91]  0.80498447  1.04257207  0.74230749  0.15018785  0.56360186  1.46969385 #>  [97]  1.35873244  0.52223297 -1.00000000  0.00000000 #>  #> $bound #> [1] 1.959964 #>  #> $change_points #> [1] index     year      value     statistic p_value   #> <0 rows> (or 0-length row.names) #>  #> $p_value #> [1] 0.2397069 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Performs nonparametric Pettitt test detect single abrupt change central tendency time series. null hypothesis, change.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"","code":"eda_pettitt_test(data, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"list containing test results, including: data: data argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. u_series: Numeric vector absolute U-statistics years. statistic: test statistic maximum absolute U-statistic. bound: critical value test statistic based alpha. change_points: dataframe containing potential change point. p_value: asymptotic approximation  p-value test. reject: Logical scalar. TRUE, null hypothesis rejected. change_points contains years, test statistics, p-values potential change point. change points identified, change_points empty.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"Pettitt, .N., 1979. Non-parametric Approach Change-point Problem. J. Royal Statistics Society 28 (2), 126–135. http://www.jstor.org/stable/2346729","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pettitt_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pettitt Test for Abrupt Changes in the Mean of a Time Series — eda_pettitt_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_pettitt_test(data, years) #> $data #>   [1]  93.18624 103.82141 102.02935 112.10449  85.42835 107.26397  88.20753 #>   [8] 108.59298 100.01181  90.54158 111.24859 116.50599  99.71808  95.68262 #>  [15] 109.62970 101.42725  92.26551  98.38343 102.72831 111.78279  99.34285 #>  [22]  96.73675 106.16976 114.48573 104.01289 107.36656 106.75189 100.92422 #>  [29] 105.71910  95.62950 115.22793  90.09813 101.21090 105.45931 108.28352 #>  [36]  94.04016  97.61715 104.73747 103.40918  96.95804 107.33999 103.13770 #>  [43] 111.29980 103.81615 103.68654 108.84609 109.21164 117.78567  92.96911 #>  [50]  75.93637  99.68249  97.04275 106.00636 111.60364 100.56538  95.59872 #>  [57]  98.35395  90.02786  76.48258  97.01634  78.53935  97.08140  93.10026 #>  [64]  94.97523 106.05890  97.37607  96.90605 119.81818  94.51492  92.73484 #>  [71] 101.06323 114.59809  93.10381 114.15768 100.04895 101.07439  98.37847 #>  [78]  89.26774 100.03078 110.44615  98.93937 107.17062  87.33825  69.94219 #>  [85] 108.75675 106.93614 112.83858 109.99143  86.73613  81.15200 101.48586 #>  [92]  99.01536  91.65490 102.34030 104.16639  89.90877  92.40957  81.75752 #>  [99]  98.91953 104.97110 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There are no abrupt changes in the mean of the data.\" #>  #> $alternative_hypothesis #> [1] \"There is one abrupt change in the mean of the data.\" #>  #> $u_series #>   [1]  55  28  15  68  19  34  47  14   7  64  11 106  97  54 123 132  65  44 #>  [19]  61 142 129  88 133 222 251 308 355 356 395 350 443 370 377 414 473 420 #>  [37] 393 426 447 410 465 484 561 586 609 674 741 838 777 680 669 636 677 756 #>  [55] 755 708 683 608 513 478 385 354 295 246 289 260 221 320 269 206 209 300 #>  [73] 243 330 327 332 309 230 225 298 281 332 249 150 213 262 347 418 333 242 #>  [91] 253 238 169 184 215 138  73  16  35  35 #>  #> $statistic #> [1] 838 #>  #> $bound #> [1] 710.1279 #>  #> $p_value #> [1] 0.015 #>  #> $change_points #>   index year    value statistic p_value #> 1    48 1948 117.7857       838   0.015 #>  #> $reject #> [1] TRUE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Phillips–Perron Unit Root Test — eda_pp_test","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"Applies Phillips–Perron (PP) test check unit root annual maximum series data. null hypothesis assumes time series contains unit root (also known stochastic trend). alternative hypothesis time series trend-stationary deterministic linear trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"","code":"eda_pp_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: PP test statistic. p_value: Reported p-value test. See details information. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"implementation test based aTSA package, interpolates p-values table critical values presented Fuller W. . (1996). critical values available \\(\\alpha \\geq 0.01\\). Therefore, reported p-value 0.01 indicates \\(p \\leq 0.01\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"Fuller, W. . (1976). Introduction Statistical Time Series. New York: John Wiley Sons Phillips, P. C. B.; Perron, P. (1988). Testing Unit Root Time Series Regression. Biometrika, 75 (2): 335-346","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_pp_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Phillips–Perron Unit Root Test — eda_pp_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_pp_test(data) #> $data #>   [1] 105.76548 116.35644 105.87302  91.87373 100.21493 102.16915 106.43384 #>   [8]  90.75542 112.09305 115.66475 106.29210  93.57340 109.91148 123.90197 #>  [15] 111.88599 107.95127 112.67272  96.37174  90.85030 109.63619 110.11232 #>  [22] 103.51880  85.45366  96.87146 101.49090  85.91269 110.95705  89.93695 #>  [29] 100.82613  97.13996 101.50056  91.73811  93.37605 103.32282 115.90949 #>  [36] 105.40615  78.21858 100.81197  92.78968  83.66820 113.59610 107.43217 #>  [43] 105.51555  95.14892 110.21334 103.11580 103.84172  97.51773  89.01770 #>  [50]  98.42764  95.09492  90.94731  91.61404 102.31428  98.29435 112.32145 #>  [57]  85.10743  95.72899  91.82995  84.94320  93.22315  86.30266  94.42601 #>  [64]  92.61220 102.89779 106.08334 108.82450 109.42153  95.22151 100.84429 #>  [71]  88.10724 107.37773 100.58236  94.05796 118.65775 102.38358  96.12942 #>  [78]  89.13372  89.66338  82.05767  86.20263 100.00840 113.10889 104.46057 #>  [85]  96.14615  91.31060  99.45665 117.31574  85.14095  93.78140 108.40636 #>  [92] 106.62350  89.15688 107.41433  98.99308 103.05388 113.90169  98.43064 #>  [99] 102.31027 106.38974 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The time series has a unit root (stochastic trend).\" #>  #> $alternative_hypothesis #> [1] \"The time series is trend-stationary.\" #>  #> $statistic #> [1] -83.75394 #>  #> $p_value #> [1] 0.01 #>  #> $reject #> [1] TRUE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Applies Wald–Wolfowitz runs test numeric vector order assess whether behaves random sequence. test statistic p-value computed using number runs (sequences values median). null hypothesis, data random. runs test can used assess whether residuals nonstationary model random, indicating suitability assumed nonstationary structure (e.g., linear).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"","code":"eda_runs_test(values, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"values numeric vector values check randomness. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"list containing test results, including: values: values argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. n: length input vector removing median. runs: number runs transformed sequence residuals. statistic: runs test statistic, computed using runs n. p_value: p-value derived normally distributed test statistic. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"Wald, . Wolfowitz, J. (1940). test whether two samples population. Annals Mathematical Statistics, 11(2), 147–162.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_runs_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wald–Wolfowitz Runs Test for Randomness — eda_runs_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) sens_trend <- eda_sens_trend(data, years) eda_runs_test(sens_trend$residuals, years) #> $values #>   [1]  25.46430969  -9.98727195  -9.06148722  -9.56791924  -1.53895896 #>   [6]  -1.23675557   8.02694389 -12.82381293   5.07085225   1.13658002 #>  [11]  -5.37587969   7.59712200   7.82502705  -5.56935476  17.92272579 #>  [16]  -7.24110088   6.58578273  15.19467829  25.45441327  19.97716279 #>  [21] -13.69280788  -2.58751312  21.74119769  -9.93908033   4.60602766 #>  [26]  -6.06063338  -5.04366585  -3.78884820   8.38539197   1.68850802 #>  [31]   3.70908938  14.83010696 -14.43397885   0.29741182 -16.27193945 #>  [36]   4.96679389   6.59292895  -7.58056363  -1.12924693  -5.57562782 #>  [41]   6.05892279 -19.62599883  -1.14112539   2.78266968   7.33566144 #>  [46]   4.21883084 -25.76302028  -3.26017958   4.61546335   2.98527913 #>  [51]   0.83373268 -15.91476334  -0.02367158  -7.83077000   5.94242574 #>  [56]  -6.05339522  -0.12849234 -14.60323678  19.19731253   4.10835630 #>  [61] -16.91821303  -3.20666786  -0.74185625   6.21678452  -2.01851044 #>  [66]   8.47323359  17.52362255  -4.41598954 -13.24737453 -19.27871022 #>  [71]   3.93977440  -8.86962334  13.19385284   9.33981765  -8.08620222 #>  [76]  -2.48886519  18.69185530  25.24296184  -3.29916828   1.15422156 #>  [81]  14.64029482  -8.65608495  -8.45772691   0.02367158  12.58593839 #>  [86] -12.94257747 -20.21289360   0.51516802  -3.44913389  -2.68716405 #>  [91] -14.25625068   1.10512458  -7.16781604   1.76227656   3.74176131 #>  [96]   6.47304189   7.74224258  -4.89913386  21.53207989  20.81765392 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The input vector is random.\" #>  #> $alternative_hypothesis #> [1] \"The input vector is not random.\" #>  #> $n #> [1] 100 #>  #> $runs #> [1] 53 #>  #> $statistic #> [1] 0.4020356 #>  #> $p_value #> [1] 0.6876578 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":null,"dir":"Reference","previous_headings":"","what":"Sen's Trend Estimator — eda_sens_trend","title":"Sen's Trend Estimator — eda_sens_trend","text":"Computes Sen's linear trend estimator univariate time series. estimated slope y-intercept given terms data covariate (time), derived years using formula \\((\\text{Years} - 1900) / 100\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sen's Trend Estimator — eda_sens_trend","text":"","code":"eda_sens_trend(data, years)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sen's Trend Estimator — eda_sens_trend","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sen's Trend Estimator — eda_sens_trend","text":"list containing estimated trend: data: data argument. years: years argument. slope: estimated slope. intercept: estimated y-intercept. residuals: Vector differences predicted observed values.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sen's Trend Estimator — eda_sens_trend","text":"Sen's slope estimator robust, nonparametric trend estimator based median pairwise slopes data points. corresponding intercept median \\(y_i - mx_i\\) \\(m\\) estimated slope.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sen's Trend Estimator — eda_sens_trend","text":"Sen, P.K. (1968). Estimates regression coefficient based Kendall's tau. Journal American Statistical Association, 63(324), 1379–1389.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_sens_trend.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sen's Trend Estimator — eda_sens_trend","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_sens_trend(data, years) #> $data #>   [1]  71.14720 114.04081  85.53392  97.67344  90.89083 103.29376  99.21390 #>   [8]  98.90397  89.27138 103.95860 108.25451 108.57277  98.29088 101.00560 #>  [15]  95.65229  95.56905  89.66521 122.50497  94.90634 107.83315 106.31107 #>  [22] 111.51340 102.09891  98.66040 107.10639 102.32650  93.56602  82.17235 #>  [29] 115.53949  97.62048  91.48151 103.99375  78.75553 109.02592 109.87513 #>  [36]  91.57034  75.35796  83.06758 111.02988 110.79918  97.81132 115.99110 #>  [43]  97.49414 114.96522 104.48972 101.82078  93.83436  86.25984  92.93219 #>  [50] 108.05278 101.79365 100.54119  84.71055 104.00399  96.18705 100.58256 #>  [57] 103.80280 101.53855 114.89921 104.92200 103.21021 101.94214 107.42460 #>  [64] 116.84394  92.50584 104.87693 100.38928  91.57844 110.66950 112.50907 #>  [71]  99.43985 111.01152 108.60272  94.35932  79.94742 102.48602 102.09311 #>  [78] 105.64982 104.92798  97.24127 102.44770 101.24951 102.63553  93.00900 #>  [85]  79.43679 102.37812  99.58353 106.73590  90.05232 106.93567 105.46208 #>  [92] 113.96973  95.44503 104.04250 103.99922  76.23319 104.59000 111.99336 #>  [99] 106.43052 102.14418 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $slope #> [1] 3.842688 #>  #> $intercept #> [1] 99.50288 #>  #> $residuals #>   [1] -28.39411147  14.46107059 -14.08424335  -1.98315489  -8.80418906 #>   [6]   3.56031770  -0.55797637  -0.90633097 -10.57734432   4.07144507 #>  [11]   8.32893103   8.60876081  -1.71155617   0.96473736  -4.42699849 #>  [16]  -4.54865981 -10.49093294  22.31039865  -5.32665070   7.56173095 #>  [21]   6.00122076  11.16512696   1.71220418  -1.76472890   6.64283091 #>  [26]   1.82452118  -6.97439124 -18.40648772  14.92222747  -3.03520959 #>  [31]  -9.21260971   3.26120821 -22.01543988   8.21651984   9.02730921 #>  [36]  -9.31590921 -25.56672035 -17.89552130  10.02834619   9.75922120 #>  [41]  -3.26706738  14.87428433  -3.66110199  13.77155209   3.25763108 #>  [46]   0.55025778  -7.47458763 -15.08753832  -8.45360940   6.62855464 #>  [51]   0.33099984  -0.95989488 -16.82895372   2.42605401  -5.42931041 #>  [56]  -1.07223366   2.10958088  -0.19309787  13.12914095   3.11350151 #>  [61]   1.36328726   0.05678530   5.50082462  14.88173083  -9.49479528 #>  [66]   2.83786979  -1.68820023 -10.53747372   8.51516540  10.31630230 #>  [71]  -2.79134258   8.74190230   6.29467803  -7.98715146 -22.43747678 #>  [76]   0.06269405  -0.36863970   3.14964224   2.38937319  -5.33575954 #>  [81]  -0.16776431  -1.40437689  -0.05678530  -9.72174514 -23.33237616 #>  [86]  -0.42948044  -3.26249112   3.85144901 -12.87055837   3.97436293 #>  [91]   2.46235038  10.93157667  -7.63155218   0.92749105   0.84578369 #>  [96] -26.95867768   1.35970584   8.72463670   3.12337262  -1.20139653 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Spearman Test for Autocorrelation — eda_spearman_test","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"Performs Spearman serial correlation test annual maximum series data check serial correlation various lags. Reports smallest lag serial correlation statistically significant given significance level (least insignificant lag).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"","code":"eda_spearman_test(data, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"list containing test results, including: data: data argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. rho: Numeric vector serial correlation estimates lags \\(1\\) \\(n-3\\). least_lag: smallest lag serial correlation insignificant. significant: Indicates whether serial correlation significant lag. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_spearman_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spearman Test for Autocorrelation — eda_spearman_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) eda_spearman_test(data) #> $data #>   [1]  86.05348  86.47162 106.82030  93.79462 101.08264 111.23510  95.33119 #>   [8] 103.83775  77.06348 117.92758  78.22464  91.43614 109.47363 105.26578 #>  [15]  81.73983 112.47440  99.33391 109.85445 112.67286 100.08714  87.93782 #>  [22]  95.52039  88.28031 107.00460 115.12215 101.99070  93.67655  94.53010 #>  [29] 106.48141 101.00782  82.42012 109.38275  84.40313  97.26097 107.97217 #>  [36]  96.08833 109.67785  93.54223 100.93528 107.62956  94.67642  97.07130 #>  [43] 102.06642  79.20201 108.58147 107.13222  84.83731 109.16774  89.74668 #>  [50]  91.85919 108.46643  94.93178 107.50644 106.77331 101.41293  85.65508 #>  [57]  86.16541  92.84438 122.92140  90.07804 104.59519  97.62281 108.35991 #>  [64]  93.65053  80.76932  98.64659 108.60061 113.31049  83.67603  97.24631 #>  [71]  97.62521 107.06400  99.04726 127.25076 106.30267  88.88680  96.44126 #>  [78] 110.38200  87.75264  93.26501 118.97439  96.53224  78.59880 124.76428 #>  [85]  95.97234 103.79369  92.51198 105.05991  94.64354 103.41252  92.41732 #>  [92]  95.76410  88.48226 115.30293 101.12761  98.74202  85.32868 109.61289 #>  [99] 109.64497 112.58596 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"There is no autocorrelation in the data.\" #>  #> $alternative_hypothesis #> [1] \"There is autocorrelation in the data.\" #>  #> $rho #>  [1] -0.222993197 -0.129710741 -0.011242899 -0.058572979 -0.089389698 #>  [6]  0.130672254 -0.077646146  0.111200160 -0.174964166  0.083261308 #> [11]  0.056196799 -0.136434081  0.111503973  0.087315439 -0.196873168 #> [16]  0.119530222 -0.203161076 -0.034229057  0.089859982 -0.037552743 #> [21]  0.032935735  0.172346641 -0.090015248 -0.040929597 -0.183669986 #> [26]  0.097193632  0.303683821 -0.244260081  0.154158283 -0.098976468 #> [31] -0.083120205  0.097950147  0.099329555 -0.228514769  0.238330420 #> [36]  0.001373626 -0.067588326  0.013824885 -0.058751983 -0.077188108 #> [41]  0.054646406 -0.043834015  0.083419756 -0.230211893  0.118903319 #> [46] -0.014751286 -0.065312046  0.089729361  0.356199095 -0.153325330 #> [51] -0.215000000 -0.113221884  0.049259944  0.068023435  0.081422925 #> [56]  0.177167019 -0.125339777  0.055181914 -0.018292683  0.037523452 #> [61] -0.083400810  0.169493380 -0.238027501  0.141827542  0.126890756 #> [66] -0.198166539 -0.214572193  0.368401760 -0.164516129  0.070522803 #> [71]  0.065517241 -0.095238095 -0.523809524  0.223247863  0.082307692 #> [76]  0.260000000 -0.423913043  0.338226990 -0.290909091  0.160902256 #> [81]  0.142105263  0.391124871 -0.360294118  0.220588235 -0.164285714 #> [86]  0.230769231 -0.285714286  0.223776224 -0.136363636  0.054545455 #> [91] -0.016666667  0.095238095 -0.178571429  0.371428571  0.600000000 #> [96]  0.800000000  1.000000000 #>  #> $least_lag #> [1] 2 #>  #> $significant #>  [1]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [25] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [49]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE #> [73]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE #> [97]  TRUE #>  #> $reject #> [1] TRUE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":null,"dir":"Reference","previous_headings":"","what":"White Test for Heteroskedasticity — eda_white_test","title":"White Test for Heteroskedasticity — eda_white_test","text":"Performs White test heteroskedasticity regressing squared residuals linear model original regressors squared terms. null hypothesis homoskedasticity.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"White Test for Heteroskedasticity — eda_white_test","text":"","code":"eda_white_test(data, years, alpha = 0.05)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"White Test for Heteroskedasticity — eda_white_test","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"White Test for Heteroskedasticity — eda_white_test","text":"list containing results White test: data: data argument. years: years argument. alpha: significance level specified alpha argument. null_hypothesis: string describing null hypothesis. alternative_hypothesis: string describing alternative hypothesis. statistic: White test statistic based sample size r_squared. p_value: p-value derived Chi-squared distribution df = 2. reject: TRUE, null hypothesis rejected significance alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"White Test for Heteroskedasticity — eda_white_test","text":"White test regresses squared residuals primary linear model lm(data ~ years) original regressor square. test statistic calculated \\(nR^2\\), \\(R^2\\) coefficient determination auxiliary regression \\(n\\) number elements time series. null hypothesis, test statistic \\(\\chi^2\\) distribution 2 degrees freedom.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"White Test for Heteroskedasticity — eda_white_test","text":"White, H. (1980). heteroskedasticity-consistent covariance matrix estimator direct test heteroskedasticity. Econometrica, 48(4), 817–838.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/eda_white_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"White Test for Heteroskedasticity — eda_white_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) eda_white_test(data, years) #> $data #>   [1] 107.85550 103.97192 106.98846 104.50714 106.40800 112.20660 110.78431 #>   [8]  96.80989  87.26127  93.49333  92.57200  87.74771  96.87723 110.71671 #>  [15]  98.46020  91.09966  84.26416 105.62013  94.57179 111.64665 103.88534 #>  [22] 108.28514 100.32738  93.51255  98.24003  91.33492 102.79443  74.37330 #>  [29] 105.36249 117.23348  98.92870 105.61287  89.23935 100.82991 101.78167 #>  [36]  91.55114 117.67981  82.68244 112.11189 107.36570 111.29951  90.78180 #>  [43] 101.56818  80.14524 110.30039 112.91148 105.00442 110.39921  87.44111 #>  [50]  98.86676 101.12835 111.51733  85.58585 103.89748 107.29353  86.04344 #>  [57]  96.94657 110.95199  88.58207  91.29411 109.85239  91.61905  91.71838 #>  [64] 110.01256 111.97043  95.29367  84.88836 103.47476  95.94925  96.50217 #>  [71]  84.59143  95.90070  89.02645 100.54988  90.44008 109.84374 109.39418 #>  [78]  87.61338  86.89788  92.04935  93.35320 108.44849  94.79207 103.34544 #>  [85]  93.20054  96.88521 113.29437 103.96915  98.51686  92.26959 118.54612 #>  [92] 111.78232 105.47654 106.94876 108.49706 103.51722 104.15862  84.53482 #>  [99]  87.53159 104.64329 #>  #> $years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $alpha #> [1] 0.05 #>  #> $null_hypothesis #> [1] \"The data is homoskedastic.\" #>  #> $alternative_hypothesis #> [1] \"The data is heteroskedastic.\" #>  #> $statistic #> [1] 1.428001 #>  #> $p_value #> [1] 0.4896812 #>  #> $reject #> [1] FALSE #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/ffaframework-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Flood Frequency Analysis Framework — ffaframework-package","title":"Flood Frequency Analysis Framework — ffaframework-package","text":"package provides tools stationary (S-FFA) nonstationary (NS-FFA) flood flood frequency analysis annual maximum series data. High-level wrapper functions framework_* prefix orchestrate EDA /FFA modules Vidrio-Sahagún et al. (2024) generate reports. Users wish develop customized workflows may use methods following prefixes: eda_*: Explore annual maximum series data evidence nonstationarity inform approach selection (S-FFA NS-FFA): Detect statistically significant change points. Detect statistically significant temporal trends mean variability. select_*: Select suitable probability distribution using L-moments. fit_*: Fit parameters given distribution approach (S-FFA NS-FFA). uncertainty_*: Quantify uncertainty computing confidence intervals. model_assessment() evaluates model performance using variety metrics. Additional utility functions visualization computation also available: data_* methods load, transform, decompose annual maximum series data. plot_* methods produce diagnostic summary plots. utils_* methods implement distribution-specific computations. Datasets five hydrometric stations Canada provided representative use cases (datasets /inst/extdata testing purposes ): Athabasca River Athabasca (CAN-07BE001): unregulated station statistical evidence trends change points (S-FFA recommended). Kootenai River Porthill (CAN-08NH21): regulated station evidence abrupt change mean 1972 (piecewise NS-FFA recommended). Bow River Banff (CAN-05BB001). unregulated station statistical evidence trend mean (NS-FFA recommended). Chilliwack River Chilliwack Lake (CAN-08MH016): unregulated station statistical evidence linear trend variability (NS-FFA recommended). Okanagan River Penticton (CAN-08NM050): regulated station statistical evidence linear trend mean variability (NS-FFA recommended). package assumes familiarity statistical techniques used FFA, including parameter estimation (e.g., L-moments maximum likelihood), dataset decomposition, uncertainty quantification (parametric bootstrap profile likelihood). explanation methods, see FFA Framework wiki. examples, see vignettes exploratory data analysis flood frequency analysis.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/ffaframework-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Flood Frequency Analysis Framework — ffaframework-package","text":"Maintainer: Riley Wheadon rileywheadon@gmail.com Authors: Cuauhtémoc Vidrio-Sahagún ct.vidrio-sahagun@usask.ca Alain Pietroniro alain.pietroniro@ucalgary.ca [funder] Jianxun jianhe@ucalgary.ca contributors: Environment Climate Change Canada (ECCC) [funder]","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"Estimates parameters generalized extreme value (GEV) distribution maximizing generalized log‐likelihood, incorporates Beta prior shape parameter. Initial parameter estimates obtained using method L‐moments optimization performed via stats::nlminb() repeated perturbations needed. NS-FFA: estimate parameters nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"","code":"fit_gmle(data, prior, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"list containing results parameter estimation: data: data argument. prior: prior argument. ns_years: ns_years argument, given. ns_structure: ns_structure argument, given. method: \"GMLE\". params: Numeric vector estimated parameters. mll: maximum value generalized log‐likelihood.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"Calls fit_lmoments() data obtain initial parameter estimates. Initializes trend parameters zero necessary. Defines objective function using utils_generalized_likelihood(). Runs stats::nlminb() box constraints. Attempts minimization 100 times.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"El Adlouni, S., Ouarda, T.B.M.J., Zhang, X., Roy, R., Bobee, B., 2007. Generalized maximum likelihood estimators nonstationary generalized extreme value model. Water Resources Research 43 (3), 1–13. doi:10.1029/2005WR004545 Martins, E. S., Stedinger, J. R. (2000). Generalized maximum-likelihood generalized extreme-value quantile estimators hydrologic data. Water Resources Research, 36(3), 737–744. doi:10.1029/1999WR900330","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_gmle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Maximum Likelihood Parameter Estimation — fit_gmle","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) prior <- c(6, 9) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE) fit_gmle(data, prior, ns_years, ns_structure) #> $data #>   [1]  94.02569 107.12776  93.87376 107.84242  97.69873 125.24530 103.56465 #>   [8]  93.36118 109.48751 103.26694  96.17233 113.48133  86.81124 108.93587 #>  [15] 112.09918  97.40808  85.91189 106.89636  99.71902  80.10229  92.36063 #>  [22]  83.85098 121.10798 108.58506 108.31253  94.26097 100.53390 120.76441 #>  [29] 107.26516 109.96803  91.08321 105.39807  99.44333 100.16600 118.61687 #>  [36] 110.21902 114.73549 100.36435  86.31768 109.19317 116.28756 101.60625 #>  [43]  90.94688 102.68745  97.00890  89.48579 117.41882  98.48603  99.31366 #>  [50]  86.91908 101.22587 118.70062  97.80619 109.65154 107.82251  88.81587 #>  [57]  75.86941  85.69462  97.30973  99.80566 112.09757  91.36437  95.86744 #>  [64]  92.77654 104.87393 102.51375 100.99291  95.86417  99.78147 104.83921 #>  [71] 110.42958 109.35107  97.67290 104.29871 109.35454  92.24086 108.62367 #>  [78]  85.20797  90.62383 102.25252 105.23610  94.18402 101.79172 103.95063 #>  [85] 112.68783  95.59487  92.48007  94.78395  94.88289 106.87342 107.67279 #>  [92] 115.10075 114.32144 118.17319 100.70136 102.34274  96.87547 115.08114 #>  [99] 108.78293 105.86041 #>  #> $distribution #> [1] \"GEV\" #>  #> $ns_years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $ns_structure #> $ns_structure$location #> [1] TRUE #>  #> $ns_structure$scale #> [1] FALSE #>  #>  #> $prior #> [1] 6 9 #>  #> $method #> [1] \"GMLE\" #>  #> $params #> [1] 94.4628866  4.2539652 10.1562451  0.1055145 #>  #> $mll #> [1] -269.0837 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Moments Parameter Estimation — fit_lmoments","title":"L-Moments Parameter Estimation — fit_lmoments","text":"S-FFA : Estimates parameters stationary probability model using L-moments.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Moments Parameter Estimation — fit_lmoments","text":"","code":"fit_lmoments(data, distribution)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Moments Parameter Estimation — fit_lmoments","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Moments Parameter Estimation — fit_lmoments","text":"list containing results parameter estimation: data: data argument. distribution: distribution argument. method: \"L-moments\". params: Numeric vector estimated parameters.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Moments Parameter Estimation — fit_lmoments","text":"First, sample L-moments data computed using utils_sample_lmoments(). , formulas Hosking (1997) used match parameters sample L-moments. distributions \"GNO\", \"PE3\", \"LP3\" use rational approximation parameters since closed-form expression known.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Moments Parameter Estimation — fit_lmoments","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Moments Parameter Estimation — fit_lmoments","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmoments(data, \"GUM\") #> $data #>   [1] 120.00224 103.56648  97.37379  91.94665 108.82779  82.40831  94.94096 #>   [8]  90.56819 102.17673  92.68039  98.05867  99.08948 100.12524 115.71024 #>  [15]  96.13517 111.17732  99.43153  90.23783  79.33490 104.12935 107.77373 #>  [22] 107.74647  90.52324 104.05805 117.28742  90.72178 100.51341  95.89050 #>  [29]  98.17972 102.58520  96.10162 100.28579 103.75042 102.36861 106.81857 #>  [36]  99.87023  93.63866 103.16125 101.24585 114.56949  98.74122 108.01745 #>  [43]  88.36622  92.08586  94.85833  91.17829  79.81302 106.05510  87.84966 #>  [50]  94.28917 115.41705 104.91905 115.68214  86.67678 102.79631  92.60434 #>  [57] 119.73140 117.24102 108.36749 103.51559  79.13414 101.57273 110.01306 #>  [64]  94.95882  94.36551  98.49159 114.57832  82.77162  88.09108  95.81234 #>  [71]  79.14392  84.59182  98.12339  97.29406  89.23987 112.77777 111.88500 #>  [78] 101.40517 109.86976  97.46669 114.10414  99.06067 119.42181 104.18372 #>  [85] 104.83997  95.58950  98.99218  96.55484 115.53452 106.02357  81.50147 #>  [92]  96.43393  86.41441  94.61247  99.85326 107.39677  97.63858 114.23139 #>  [99]  97.42237  87.23457 #>  #> $distribution #> [1] \"GUM\" #>  #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 95.076997  8.214399 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"function estimates parameters four-parameter Kappa distribution using method L-moments. Since closed-form solution parameters terms L-moments known, parameters estimated numerically using Newton-Raphson iteration.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"","code":"fit_lmoments_kappa(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"list containing results parameter estimation: data: data argument. distribution: \"KAP\". method: \"L-moments\". params: numeric vector 4 parameters order location, scale, shape (2).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"First, sample L-moments data computed using utils_sample_lmoments(). , stats::optim() function used determine parameters minimizing euclidian distance sample theoretical L-moment ratios. implementation routine based deprecated homtest package, formerly available https://CRAN.R-project.org/package=homtest.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_lmoments_kappa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Moments Parameter Estimation for the Kappa Distribution — fit_lmoments_kappa","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) fit_lmoments_kappa(data) #> $data #>   [1] 123.33102 129.98500 103.65176  96.13149 101.34976 127.82386  93.53035 #>   [8]  98.14358 108.50758  92.69139  99.54006 109.46315  97.90904  95.27777 #>  [15]  86.73009  85.38698 102.77775 112.91988  81.80512  94.74878 104.12961 #>  [22]  86.15792  93.61056  90.67634 107.98288  93.72856  93.11586 114.25064 #>  [29]  96.89832  85.21415 103.60718 118.07402  92.29831 116.30787  96.94046 #>  [36]  88.75006 110.70093 106.80362 106.80181  78.45343  90.59212 113.49160 #>  [43] 107.58402 105.77168  97.74529  92.92667  87.12961  97.34649 103.17341 #>  [50] 114.52780 114.82291  84.09064  97.41627  80.09692 112.52924  84.14193 #>  [57] 105.79051  92.79212  77.79175  94.06701  91.08944 102.43396 100.58815 #>  [64] 112.30860  93.74515 100.52105 103.26004 107.44203  97.91168 119.01198 #>  [71]  86.81093  95.02666  97.24043  78.01471 105.61307 103.25924 100.08636 #>  [78] 111.09707 127.78743  87.27984 123.72900  97.47131 102.77547  87.47706 #>  [85]  94.13426  96.19866 118.04711 105.96198 114.36962 115.87495 115.10900 #>  [92] 108.80649 109.96885 111.57981  94.25167  87.46057 106.31133 109.05409 #>  [99] 107.89903 114.14477 #>  #> $distribution #> [1] \"KAP\" #>  #> $method #> [1] \"L-moments\" #>  #> $params #> [1] 95.4862623 13.2031444  0.3010056  0.1682830 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum Likelihood Parameter Estimation — fit_mle","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"Estimates parameters probability distribution maximizing log‐likelihood. Initial parameter estimates obtained using method L‐moments optimization performed via stats::nlminb() repeated perturbations needed. NS-FFA: estimate parameters nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"","code":"fit_mle(data, distribution, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"list containing results parameter estimation: data: data argument. distribution: distribution argument. ns_years: ns_years argument, given. ns_structure: ns_structure argument, given. method: \"MLE\". params: Numeric vector estimated parameters. mll: maximum value log‐likelihood.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"Calls fit_lmoments() data obtain initial parameter estimates. Initializes trend parameters zero necessary. WEI models, sets location parameter zero ensure support. Defines objective function using utils_log_likelihood(). Runs stats::nlminb() box constraints. Attempts minimization 100 times.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/fit_mle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum Likelihood Parameter Estimation — fit_mle","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE) fit_mle(data, \"GNO\", ns_years, ns_structure) #> $data #>   [1] 102.26379 108.00647  94.50523  87.72731  99.77925 108.63950 112.97008 #>   [8]  96.02339  84.07061 102.54378  82.27624 100.78716  86.00637 132.19060 #>  [15]  91.81452 100.36118  94.42961  91.78141 112.85518  87.10887  98.47703 #>  [22]  90.29603 115.85079  96.85944  90.73756 113.84408  89.75266  84.38758 #>  [29] 103.32694  83.67615 110.88718 105.92150  88.93916  97.37292 105.86291 #>  [36]  91.23258 108.51698  99.39284  95.83097 107.19835  85.08089 100.34346 #>  [43]  97.53211 119.54145 100.09658 113.11216  88.64854  95.31387 103.40441 #>  [50]  98.21043 116.15922  99.69659 110.39512 102.20352 109.53315 111.88895 #>  [57]  95.33576 116.22845  92.46341 108.04747  93.51511  94.71189  76.80314 #>  [64] 111.49970  97.32005 113.35798 103.04911 110.48993  92.94706 100.24797 #>  [71] 100.81656 105.06131  94.48316 107.03604 101.50665  81.50408  96.53061 #>  [78]  99.56023  98.79920  92.41629 110.41362 100.44308 108.27265  98.96216 #>  [85]  92.11579 108.29480 116.68956 102.13646 111.57535  89.21120 113.15584 #>  [92]  93.25724  93.56120 100.40112 108.21379 114.65366 104.47294 103.40752 #>  [99] 120.89891 103.25784 #>  #> $distribution #> [1] \"GNO\" #>  #> $ns_years #>   [1] 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 #>  [16] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 #>  [31] 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 #>  [46] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 #>  [61] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 #>  [76] 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 #>  [91] 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 #>  #> $ns_structure #> $ns_structure$location #> [1] TRUE #>  #> $ns_structure$scale #> [1] FALSE #>  #>  #> $prior #> NULL #>  #> $method #> [1] \"MLE\" #>  #> $params #> [1] 97.08225431  6.57788171  9.78909788 -0.08641844 #>  #> $mll #> [1] -370.0208 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":null,"dir":"Reference","previous_headings":"","what":"Orchestrate Exploratory Data Analysis — framework_eda","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"First, method identifies change points original annual maximum series data. , user given option split dataset two homogenous subperiods (trend-free monotonic trends). Finally, method performs collection statistical tests identifying monotonic nonstationarity mean variability subperiod (dataset split) entire dataset (split). results EDA can help guide FFA approach selection (stationary nonstationary) FFA model determination.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"","code":"framework_eda(   data,   years,   ns_splits = NULL,   generate_report = TRUE,   report_path = NULL,   report_formats = \"html\",   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. ns_splits integer vector years used split data homogeneous subperiods. S-FFA, set NULL (default). NS-FFA, specify integer vector years physical justification change points, NULL years exist. R, integers suffix L, 1950L valid input ns_splits, 1950 (since R may interpret floating point number). generate_report TRUE (default), generate report. report_path character scalar, file path generated report. NULL (default), report saved new temporary directory. report_formats character vector specifying output format report. Supported values \"md\", \"pdf\", \"html\", \"json\". ... Additional arguments. See \"Optional Arguments\" section complete list.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"recommendations: list containing recommended FFA approach, split point(s) nonstationary structure(s) EDA: approach: Either \"S-FFA\", \"NS-FFA\" (single homogeneous period), \"Piecewise NS-FFA\" (multiple homogeneous subperiods). ns_splits: split point(s) identified change point detection test lowest statistically significant p-value, NULL point exists. ns_structures: list structure objects homogeneous subperiod. structure list boolean items location scale, represent linear trend mean variability data, respectively. trends found homogeneous subperiod, ns_structures NULL. submodules: list lists statistical tests. list contains: name: Either \"Change Point Detection\" \"Trend Detection\". start: first year homogeneous subperiod. end: last year homogeneous subperiod. Additional items statistical tests within submodule.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_eda.html","id":"optional-arguments","dir":"Reference","previous_headings":"","what":"Optional Arguments","title":"Orchestrate Exploratory Data Analysis — framework_eda","text":"alpha: numeric significance level statistical tests (default 0.05). bbmk_samples: number samples used Block-Bootstrap Mann-Kendall (BBMK) test (default 10000). Must integer. window_size: size window used compute variability series. window_step: number years successive moving windows. Used compute variability series.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":null,"dir":"Reference","previous_headings":"","what":"Orchestrate Flood Frequency Analysis — framework_ffa","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"Performs frequency analysis annual maximum series data including distribution selection, parameter estimation, uncertainty quantification, model assessment. Supports stationary (S-FFA) nonstationary (NS-FFA) flood frequency analysis.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"","code":"framework_ffa(   data,   years,   ns_splits = NULL,   ns_structures = NULL,   generate_report = TRUE,   report_path = NULL,   report_formats = \"html\",   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. ns_splits integer vector years used split data homogeneous subperiods. S-FFA, set NULL (default). NS-FFA, specify integer vector years physical justification change points, NULL years exist. R, integers suffix L, 1950L valid input ns_splits, 1950 (since R may interpret floating point number). ns_structures S-FFA, set NULL (default) use stationary model homogeneous subperiods. NS-FFA, provide list length(ns_splits) + 1 sublists specifying nonstationary model structure homogeneous subperiod. sublist must contain logical elements location scale, indicating monotonic trends mean variability, respectively. generate_report TRUE (default), generate report. report_path character scalar, file path generated report. NULL (default), report saved new temporary directory. report_formats character vector specifying output format report. Supported values \"md\", \"pdf\", \"html\", \"json\". ... Additional arguments. See \"Optional Arguments\" section complete list.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"summary: list describing model(s) used analysis. approach: Either \"S-FFA\", \"NS-FFA\", \"Piecewise NS-FFA\". ns_splits: ns_splits argument, given. ns_structures: ns_structures argument, given. submodules: list lists containing results frequency analysis. list contains: name: Either \"Distribution Selection\", \"Parameter Estimation\", \"Uncertainty Quantification\", \"Model Assessment\". start: first year homogeneous subperiod. end: last year homogeneous subperiod. Additional items specific submodule.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_ffa.html","id":"optional-arguments","dir":"Reference","previous_headings":"","what":"Optional Arguments","title":"Orchestrate Flood Frequency Analysis — framework_ffa","text":"selection: Distribution selection method (default \"L-distance\"). Must one \"L-distance\", \"L-kurtosis\" \"Z-statistic\". Alternatively, set selection three-letter distribution code (e.g., \"GUM\") use specific distribution. s_estimation: Parameter estimation method S-FFA (default \"L-moments\"). Must \"L-moments\", \"MLE\", \"GMLE\". Method \"GMLE\" requires selection = \"GEV\". ns_estimation: Parameter estimation method NS-FFA (default \"MLE\"). Must \"MLE\" \"GMLE\". Method \"GMLE\" requires selection = \"GEV\". s_uncertainty: Uncertainty quantification method S-FFA (default \"Bootstrap\"). Must one \"Bootstrap\", \"RFPL\", RFGPL\". Using method \"RFPL\" requires s_estimation = \"MLE\" method \"RFGPL\" requires s_estimation = \"GMLE\". ns_uncertainty: Uncertainty quantification method NS-FFA (default \"RFPL\"). Must one \"Bootstrap\", \"RFPL\", RFGPL\". Using method \"RFPL\" requires ns_estimation = \"MLE\" method \"RFGPL\" requires ns_estimation = \"GMLE\". z_samples: Integer number bootstrap samples selection method \"Z-statistic\" (default 10000). gev_prior: Parameters prior distribution shape parameter GEV distribution (default 6, 9). Used estimation method \"GMLE\". return_periods: Integer list return periods (years) estimating return levels. Uses 2, 5, 10, 20, 50, 100 year return periods default. ns_slices: Integer vector years estimate return levels nonstationary models. Slices outside period ignored (default 1925, 1975, 2025). bootstrap_samples: Integer number samples uncertainty quantification method `\"Bootstrap\" (default 10000). rfpl_tolerance: Log-likelihood tolerance uncertainty quantification method \"RFPL\"(default 0.01). pp_formula: Plotting position formula model assessment. Must one : \"Weibull\" (default): \\(/ (n + 1)\\) \"Blom\": \\((- 0.375) / (n + 0.25)\\) \"Cunnane\": \\((- 0.4) / (n + 0.2)\\) \"Gringorten\": \\((- 0.44) / (n + 0.12)\\) \"Hazen\": \\((- 0.5) / n\\)","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":null,"dir":"Reference","previous_headings":"","what":"Orchestrate the Full FFA Framework — framework_full","title":"Orchestrate the Full FFA Framework — framework_full","text":"Runs entire flood frequency analysis framework using results exploratory data analysis (EDA) guide approach selection (stationary nonstationary) perform flood frequency analysis. Returns comprehensive reproducible summary results.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Orchestrate the Full FFA Framework — framework_full","text":"","code":"framework_full(   data,   years,   ns_splits = NULL,   ns_structures = NULL,   generate_report = TRUE,   report_path = NULL,   report_formats = \"html\",   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Orchestrate the Full FFA Framework — framework_full","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. ns_splits integer vector years used split data homogeneous subperiods. S-FFA, set NULL (default). NS-FFA, specify integer vector years physical justification change points, NULL years exist. R, integers suffix L, 1950L valid input ns_splits, 1950 (since R may interpret floating point number). ns_structures S-FFA, set NULL (default) use stationary model homogeneous subperiods. NS-FFA, provide list length(ns_splits) + 1 sublists specifying nonstationary model structure homogeneous subperiod. sublist must contain logical elements location scale, indicating monotonic trends mean variability, respectively. generate_report TRUE (default), generate report. report_path character scalar, file path generated report. NULL (default), report saved new temporary directory. report_formats character vector specifying output format report. Supported values \"md\", \"pdf\", \"html\", \"json\". ... Additional arguments passed statistical tests frequency analysis functions. See details framework_eda() framework_ffa() complete list.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/framework_full.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Orchestrate the Full FFA Framework — framework_full","text":"recommendations: See framework_eda(). summary: See framework_ffa(). submodules: list lists results. list contains: name: Either \"Change Point Detection\", \"Trend Detection\", \"Distribution Selection\", \"Parameter Estimation\", \"Uncertainty Quantification\", \"Model Assessment\". start: first year homogeneous subperiod. end: last year homogeneous subperiod. Additional items specific submodule.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Model Assessment — model_assessment","title":"Model Assessment — model_assessment","text":"Computes various metrics assessing quality fitted flood frequency model. Metrics include accuracy (residual statistics), fitting efficiency (information criteria), uncertainty (coverage based metrics using confidence intervals). NS-FFA: metrics computed normalized empirical/theoretical quantiles, determined based selected distribution family. Therefore, metrics stationary nonstationary models compared.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model Assessment — model_assessment","text":"","code":"model_assessment(   data,   distribution,   method,   prior = NULL,   ns_years = NULL,   ns_structure = NULL,   alpha = 0.05,   pp_formula = \"Weibull\",   ci = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model Assessment — model_assessment","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. pp_formula Character string specifying plotting position formula. Must \"Weibull\" (default), \"Blom\", \"Cunnane\", \"Gringorten\", \"Hazen\". ci S-FFA . Dataframe containing return periods (column periods) confidence intervals (columns lower upper). Dataframes format can generated uncertainty_bootstrap(), uncertainty_rfpl(), uncertainty_rfgpl().","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model Assessment — model_assessment","text":"List containing results model assessment: data: data argument. q_theoretical: theoretical return level estimates based plotting positions. Normalized nonstationary models. q_empirical: empirical return levels. Normalized nonstationary models. metrics: list model assessment metrics (see details).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model Assessment — model_assessment","text":"metrics computed models: AIC_MLL: Akaike Information Criterion, computed using maximum log-likelihood. BIC_MLL: Bayesian Information Criterion, computed using maximum log-likelihood. R2: Coefficient determination linear regression estimates vs. data. RMSE: Root mean squared error quantile estimates. bias: Mean bias quantile estimates. AIC_RMSE: Akaike Information Criterion, computed using RMSE. BIC_RMSE: Bayesian Information Criterion, computed using RMSE. metrics computed  ci argument provided: AW: Average width confidence interval(s). POC: Percent observations covered confidence interval(s). CWI: Confidence width index, metric combines AW POC.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/model_assessment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model Assessment — model_assessment","text":"","code":"# Initialize example data and params data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 10)  # Perform uncertainty analysis ci <- uncertainty_bootstrap(data, \"NOR\", \"L-moments\")$ci  # Run model assessment model_assessment(data, \"NOR\", \"L-moments\", ci = ci) #> $data #>   [1] 108.11776  98.44905  91.99071  75.23320  86.10714 108.21163  99.17586 #>   [8]  93.73108  89.23005  93.14664 103.55095 109.96582 109.94133  89.48270 #>  [15] 100.77882 105.86229  96.05944 105.74290 101.84364  88.81079  88.19487 #>  [22] 104.83221 107.28678  90.25614  85.70304  87.53543  75.85501  81.29131 #>  [29] 112.34168 102.36275  97.20200  95.89982 114.17581 106.12786  80.78296 #>  [36] 101.99865  90.26977  68.72037  96.84019  94.40152  94.10852  90.60605 #>  [43] 104.78407  91.14503 101.86453  88.78454  95.55080  98.17331 100.36910 #>  [50] 102.09306  98.87816  96.74392  75.56170 101.86518 117.44204  99.59156 #>  [57]  98.69751  95.69942  88.03281  98.55958 110.30797  96.95703 106.25070 #>  [64] 101.96883 110.42065  93.68646 103.34383  94.88873  94.56708  86.10628 #>  [71] 110.11812 101.27535 101.56512 103.04107 111.97045 102.72246  91.78099 #>  [78] 103.24926 107.68759 105.03399  83.06022 111.48481 101.06242 104.15816 #>  [85] 104.91312 106.74244 103.73173 112.11088 106.51197 117.53953 100.23531 #>  [92] 105.69572  94.61341 101.11590  90.87626 100.45123 108.96800  87.22664 #>  [99] 111.80982  85.37089 #>  #> $q_theoretical #>   [1] 120.93439 118.31418 116.65210 115.40201 114.38531 113.52007 112.76153 #>   [8] 112.08244 111.46492 110.89656 110.36839 109.87371 109.40737 108.96529 #>  [15] 108.54425 108.14158 107.75511 107.38300 107.02371 106.67591 106.33846 #>  [22] 106.01037 105.69078 105.37892 105.07411 104.77575 104.48330 104.19626 #>  [29] 103.91420 103.63671 103.36341 103.09398 102.82810 102.56547 102.30583 #>  [36] 102.04893 101.79452 101.54240 101.29233 101.04414 100.79762 100.55259 #>  [43] 100.30889 100.06633  99.82476  99.58402  99.34395  99.10440  98.86522 #>  [50]  98.62626  98.38737  98.14841  97.90923  97.66968  97.42961  97.18887 #>  [57]  96.94729  96.70474  96.46103  96.21601  95.96949  95.72129  95.47123 #>  [64]  95.21910  94.96470  94.70780  94.44816  94.18553  93.91964  93.65021 #>  [71]  93.37692  93.09942  92.81736  92.53033  92.23787  91.93951  91.63471 #>  [78]  91.32285  91.00326  90.67517  90.33772  89.98992  89.63062  89.25852 #>  [85]  88.87204  88.46938  88.04833  87.60626  87.13991  86.64523  86.11707 #>  [92]  85.54871  84.93118  84.25209  83.49355  82.62831  81.61162  80.36153 #>  [99]  78.69945  76.07924 #>  #> $q_empirical #>   [1] 117.53953 117.44204 114.17581 112.34168 112.11088 111.97045 111.80982 #>   [8] 111.48481 110.42065 110.30797 110.11812 109.96582 109.94133 108.96800 #>  [15] 108.21163 108.11776 107.68759 107.28678 106.74244 106.51197 106.25070 #>  [22] 106.12786 105.86229 105.74290 105.69572 105.03399 104.91312 104.83221 #>  [29] 104.78407 104.15816 103.73173 103.55095 103.34383 103.24926 103.04107 #>  [36] 102.72246 102.36275 102.09306 101.99865 101.96883 101.86518 101.86453 #>  [43] 101.84364 101.56512 101.27535 101.11590 101.06242 100.77882 100.45123 #>  [50] 100.36910 100.23531  99.59156  99.17586  98.87816  98.69751  98.55958 #>  [57]  98.44905  98.17331  97.20200  96.95703  96.84019  96.74392  96.05944 #>  [64]  95.89982  95.69942  95.55080  94.88873  94.61341  94.56708  94.40152 #>  [71]  94.10852  93.73108  93.68646  93.14664  91.99071  91.78099  91.14503 #>  [78]  90.87626  90.60605  90.26977  90.25614  89.48270  89.23005  88.81079 #>  [85]  88.78454  88.19487  88.03281  87.53543  87.22664  86.10714  86.10628 #>  [92]  85.70304  85.37089  83.06022  81.29131  80.78296  75.85501  75.56170 #>  [99]  75.23320  68.72037 #>  #> $metrics #> $metrics$AIC_MLL #> [1] 740.5313 #>  #> $metrics$BIC_MLL #> [1] 745.7416 #>  #> $metrics$R2 #> [1] 0.976168 #>  #> $metrics$RMSE #> [1] 1.50706 #>  #> $metrics$bias #> [1] -3.552714e-15 #>  #> $metrics$AIC_RMSE #> [1] 45.01606 #>  #> $metrics$BIC_RMSE #> [1] 50.2264 #>  #> $metrics$AW #> [1] 4.459609 #>  #> $metrics$POC #> [1] 95.91837 #>  #> $metrics$CWI #> [1] 4.378445 #>  #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/mu_sigma.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Location and Scale of Kappa Distribution — mu_sigma","title":"Compute Location and Scale of Kappa Distribution — mu_sigma","text":"Compute Location Scale Kappa Distribution","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/mu_sigma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Location and Scale of Kappa Distribution — mu_sigma","text":"","code":"mu_sigma(l1, l2, k, h)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-alpha.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'alpha' — param-alpha","title":"Parameter 'alpha' — param-alpha","text":"Parameter 'alpha'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-alpha.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'alpha' — param-alpha","text":"alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-data.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'data' — param-data","title":"Parameter 'data' — param-data","text":"Parameter 'data'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'data' — param-data","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-distribution.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'distribution' — param-distribution","title":"Parameter 'distribution' — param-distribution","text":"Parameter 'distribution'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-distribution.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'distribution' — param-distribution","text":"distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-generate-report.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'generate_report' — param-generate-report","title":"Parameter 'generate_report' — param-generate-report","text":"Parameter 'generate_report'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-generate-report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'generate_report' — param-generate-report","text":"generate_report TRUE (default), generate report.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'method' — param-method","title":"Parameter 'method' — param-method","text":"Parameter 'method'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'method' — param-method","text":"method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slice.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_slice' — param-ns-slice","title":"Parameter 'ns_slice' — param-ns-slice","text":"Parameter 'ns_slice'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_slice' — param-ns-slice","text":"ns_slice NS-FFA : Numeric scalar specifying year evaluate  quantiles nonstationary probability distribution. ns_slice element ns_years argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slices.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_slices' — param-ns-slices","title":"Parameter 'ns_slices' — param-ns-slices","text":"Parameter 'ns_slices'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-slices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_slices' — param-ns-slices","text":"ns_slices NS-FFA : Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-splits.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_splits' — param-ns-splits","title":"Parameter 'ns_splits' — param-ns-splits","text":"Parameter 'ns_splits'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-splits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_splits' — param-ns-splits","text":"ns_splits integer vector years used split data homogeneous subperiods. S-FFA, set NULL (default). NS-FFA, specify integer vector years physical justification change points, NULL years exist. R, integers suffix L, 1950L valid input ns_splits, 1950 (since R may interpret floating point number).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-structure.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_structure' — param-ns-structure","title":"Parameter 'ns_structure' — param-ns-structure","text":"Parameter 'ns_structure'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-structure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_structure' — param-ns-structure","text":"ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-structures.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_structures' — param-ns-structures","title":"Parameter 'ns_structures' — param-ns-structures","text":"Parameter 'ns_structures'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-structures.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_structures' — param-ns-structures","text":"ns_structures S-FFA, set NULL (default) use stationary model homogeneous subperiods. NS-FFA, provide list length(ns_splits) + 1 sublists specifying nonstationary model structure homogeneous subperiod. sublist must contain logical elements location scale, indicating monotonic trends mean variability, respectively.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-years.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'ns_years' — param-ns-years","title":"Parameter 'ns_years' — param-ns-years","text":"Parameter 'ns_years'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-ns-years.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'ns_years' — param-ns-years","text":"ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-p.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'p' — param-p","title":"Parameter 'p' — param-p","text":"Parameter 'p'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'p' — param-p","text":"p Numeric vector probabilities 0 1 missing values.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-params.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'params' — param-params","title":"Parameter 'params' — param-params","text":"Parameter 'params'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'params' — param-params","text":"params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-periods.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'periods' — param-periods","title":"Parameter 'periods' — param-periods","text":"Parameter 'periods'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-periods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'periods' — param-periods","text":"periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'prior' — param-prior","title":"Parameter 'prior' — param-prior","text":"Parameter 'prior'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'prior' — param-prior","text":"prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-q.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'q' — param-q","title":"Parameter 'q' — param-q","text":"Parameter 'q'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-q.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'q' — param-q","text":"q Numeric vector quantiles missing values.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-report-formats.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'report_formats' — param-report-formats","title":"Parameter 'report_formats' — param-report-formats","text":"Parameter 'report_formats'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-report-formats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'report_formats' — param-report-formats","text":"report_formats character vector specifying output format report. Supported values \"md\", \"pdf\", \"html\", \"json\".","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-report-path.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'report_path' — param-report-path","title":"Parameter 'report_path' — param-report-path","text":"Parameter 'report_path'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-report-path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'report_path' — param-report-path","text":"report_path character scalar, file path generated report. NULL (default), report saved new temporary directory.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'samples' — param-samples","title":"Parameter 'samples' — param-samples","text":"Parameter 'samples'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'samples' — param-samples","text":"samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-tolerance.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'tolerance' — param-tolerance","title":"Parameter 'tolerance' — param-tolerance","text":"Parameter 'tolerance'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-tolerance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'tolerance' — param-tolerance","text":"tolerance log-likelihood tolerance Regula-Falsi convergence (default 0.01).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-years.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter 'years' — param-years","title":"Parameter 'years' — param-years","text":"Parameter 'years'","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/param-years.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter 'years' — param-years","text":"years Numeric vector observation years corresponding data. Must length data strictly increasing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Annual Maximum Series Data — plot_ams_data","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"Produces scatterplot annual maximum series data time, optionally overlaid sample mean/variability Sen's trend estimator mean/variability.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"","code":"plot_ams_data(   data,   years,   plot_mean = \"None\",   plot_variability = \"None\",   show_line = TRUE,   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. years Numeric vector observation years corresponding data. Must length data strictly increasing. plot_mean \"None\" (default), mean plotted. \"Constant\", black line plotted sample mean. \"Trend\", trend mean estimated using eda_sens_trend() plotted blue line. plot_variability \"None\" (default), variability plotted. \"Constant\", dashed black lines plotted one standard deviation /sample mean. \"Trend\", trend variability estimated data_mw_variability() eda_sens_trend() plotted dashed blue line. show_line TRUE (default), fitted line drawn data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"ggplot; plot containing: Gray points year’s annual maximum series value. gray line connecting data show_line = TRUE. solid black line representing constant mean, plot_mean == \"Constant\". solid blue line representing trend mean, plot_mean == \"Trend\". dashed black line representing constant variability, plot_variability == \"Constant\". dashed blue line representing trend variability, plot_variability == \"Trend\".","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_ams_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Annual Maximum Series Data — plot_ams_data","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) plot_ams_data(data, years, plot_mean = \"Trend\", plot_variability = \"Constant\")"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"Generates histogram bootstrapped Mann–Kendall S‐statistics vertical lines indicating observed S‐statistic confidence bounds.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"","code":"plot_bbmk_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"results List BB‐MK test results generated eda_bbmk_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"ggplot; plot containing: gray histogram distribution bootstrapped S‐statistics. red vertical line lower upper confidence bounds. black vertical line observed S‐statistic.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_bbmk_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Block‐Bootstrap Mann–Kendall Test Results — plot_bbmk_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- eda_bbmk_test(data, samples = 1000L) plot_bbmk_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"Generates plot L-moment ratios L-skewness x-axis L-kurtosis y-axis. Plots sample log-sample L-moment ratios alongside theoretical L-moment ratios set candidate distributions. Also includes small inset around L-moment ratios recommended distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"","code":"plot_lmom_diagram(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"results List distribution selection results generated select_ldistance(), select_lkurtosis(), select_zstatistic(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"ggplot; plot object containing L-moment ratio diagram, : L-moment ratio curves 3-parameter distribution. Points L-moment ratios 2-parameter distribution. Sample log-sample L-moment ratio \\((t_3, t_4)\\) points.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_lmom_diagram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot L-Moment Ratio Diagram — plot_lmom_diagram","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- select_ldistance(data) plot_lmom_diagram(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"Constructs two‐panel visualization MKS test. upper panel plots normalized progressive regressive Mann–Kendall S‐statistics time, dashed confidence bounds potential trend‐change points. lower panel contains annual maximum series data change points highlighted.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"","code":"plot_mks_test(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"results list generated eda_mks_test(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'top_xlabel', 'top_ylabel', 'bottom_xlabel' 'bottom_ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"patchwork object two ggplot2 panels stacked vertically.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_mks_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Mann–Kendall–Sneyers (MKS) Test Results — plot_mks_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- eda_mks_test(data, years) plot_mks_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Model Assessment for NS-FFA — plot_nsffa_assessment","title":"Plot Model Assessment for NS-FFA — plot_nsffa_assessment","text":"Creates normalized detrended quantile–quantile plot (worm plot) comparing empirical annual maximum series data quantile estimates fitted, parametric, nonstationary model. Confidence intervals also provided.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Model Assessment for NS-FFA — plot_nsffa_assessment","text":"","code":"plot_nsffa_assessment(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Model Assessment for NS-FFA — plot_nsffa_assessment","text":"results List; model assessment results generated model_assessment(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Model Assessment for NS-FFA — plot_nsffa_assessment","text":"ggplot; plot containing: black line representing model deviation empirical quantiles. Red points denoting estimated quantiles empirical quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_assessment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Model Assessment for NS-FFA — plot_nsffa_assessment","text":"","code":"# Initialize example data and params data <- rnorm(n = 100, mean = 100, sd = 10) + seq(from = 1, to = 100) years <- seq(from = 1901, to = 2000) structure <- list(location = TRUE, scale = FALSE)  # Evaluate model diagnostics results <- model_assessment(data, \"NOR\", \"MLE\", NULL, years, structure)  # Generate a model assessment plot plot_nsffa_assessment(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"Generates plot effective return periods x-axis effective return levels (annual maxima magnitudes) y-axis. slice displayed distinct color. Confidence bounds shown semi-transparent  ribbons, point estimates  overlaid solid lines. Return periods logarithmic scale.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"","code":"plot_nsffa_estimates(   results,   slices = c(1900, 1940, 1980, 2020),   periods = c(2, 5, 10, 20, 50, 100),   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle() fitted model confidence intervals generated uncertainty_bootstrap(), uncertainty_rfpl(), uncertainty_rfgpl(). slices Default time slices plotting return levels confidence intervals provided. periods Numeric vector used set return periods FFA. entries must greater equal 1. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"ggplot; plot one line ribbon per slice.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Estimated Return Levels for NS-FFA — plot_nsffa_estimates","text":"","code":"# Fit a nonstationary model   data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  results <- fit_mle(      data,       \"GEV\",       ns_years = years,       ns_structure = ns_structure )  # Generate the plot plot_nsffa_estimates(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"Generates plot showing probability densities nonstationary model selected time slices (left panel) data (right panel).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"","code":"plot_nsffa_fit(   results,   slices = c(1925, 1950, 1975, 2000),   show_line = TRUE,   ... )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle(). slices Years plot nonstationary probability model. show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"ggplot; plot showing: likelihood function distribution plotted vertically left panel. data, connected line show_line == TRUE, right panel.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_nsffa_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Fitted Probability Distributions for NS-FFA — plot_nsffa_fit","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) + seq(1, 100) years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  results <- fit_mle(      data,       \"GEV\",       ns_years = years,       ns_structure = ns_structure )  plot_nsffa_fit(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"Creates two‐panel visualization Mann–Whitney–Pettitt test. upper panel plots Pettitt \\(U_t\\) statistic time along significance threshold potential change point. lower panel displays annual maximum series data optional trend line, period mean(s), potential change point(s).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"","code":"plot_pettitt_test(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"results list generated eda_pettitt_test(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'top_xlabel', 'top_ylabel', 'bottom_xlabel' 'bottom_ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"patchwork object two ggplot2 panels stacked vertically.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_pettitt_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Results from the Pettitt Change‐Point Test — plot_pettitt_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- eda_pettitt_test(data, years) plot_pettitt_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Runs Test Results — plot_runs_test","title":"Plot Runs Test Results — plot_runs_test","text":"Generates residual plot Sen's estimator applied annual maximum series data (variability data) horizontal dashed line zero annotation indicating p-value Runs test.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Runs Test Results — plot_runs_test","text":"","code":"plot_runs_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Runs Test Results — plot_runs_test","text":"results list runs test results generated eda_runs_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Runs Test Results — plot_runs_test","text":"ggplot; plot containing: Black points residual year. red dashed horizontal line \\(y = 0\\). text annotation “Runs p-value: X.XXX” plot area.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_runs_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Runs Test Results — plot_runs_test","text":"","code":"# Initialize data and years data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000)  # Generate the runs test plot  sens_trend <- eda_sens_trend(data, years) results <- eda_runs_test(sens_trend$residuals, years) plot_runs_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Model Assessment for S-FFA — plot_sffa_assessment","title":"Plot Model Assessment for S-FFA — plot_sffa_assessment","text":"Creates quantile–quantile plot comparing observed annual maximum series data quantile estimates fitted parametric model. 1:1 line drawn black parametric model estimates plotted semi‐transparent red points.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Model Assessment for S-FFA — plot_sffa_assessment","text":"","code":"plot_sffa_assessment(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Model Assessment for S-FFA — plot_sffa_assessment","text":"results List; model assessment results generated model_assessment(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Model Assessment for S-FFA — plot_sffa_assessment","text":"ggplot; plot containing: black line representing model deviation empirical quantiles. Red points denoting estimated quantiles empirical quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_assessment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Model Assessment for S-FFA — plot_sffa_assessment","text":"","code":"# Initialize example data data <- rnorm(n = 100, mean = 100, sd = 10)  # Evaluate model diagnostics results <- model_assessment(data, \"NOR\", \"L-moments\")  # Generate a model assessment plot plot_sffa_assessment(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"Generates plot return periods x-axis return levels (annual maxima magnitudes) y-axis S-FFA. confidence bound shown semi-transparent ribbon, point estimates overlaid solid line. Return periods shown logarithmic scale.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"","code":"plot_sffa_estimates(results, periods = c(2, 5, 10, 20, 50, 100), ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle() fitted model confidence intervals generated uncertainty_bootstrap(), uncertainty_rfpl(), uncertainty_rfgpl(). periods Numeric vector used set return periods FFA. entries must greater equal 1. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"ggplot; plot showing: solid black line point estimates produced model. semi-transparent gray ribbon indicating confidence interval, given.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Estimated Return Levels for S-FFA — plot_sffa_estimates","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- fit_lmoments(data, \"WEI\") plot_sffa_estimates(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"Generates plot showing probability density stationary model (left panel) data (right panel).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"","code":"plot_sffa_fit(results, show_line = TRUE, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"results fitted flood frequency model generated fit_lmoments(), fit_mle() fit_gmle(). show_line TRUE (default), draw fitted line data. ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"ggplot; plot showing: likelihood function distribution plotted vertically left panel. data, connected line show_line == TRUE, right panel.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_sffa_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Fitted Probability Distribution for S-FFA — plot_sffa_fit","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) years <- seq(from = 1901, to = 2000) results <- fit_lmoments(data, \"WEI\") plot_sffa_fit(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"Visualizes Spearman’s rho serial correlation coefficients shaded points indicating statistical significance.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"","code":"plot_spearman_test(results, ...)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"results list generated eda_spearman_test(). ... Optional named arguments: 'title', 'xlabel', 'ylabel'.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"ggplot; plot showing: Vertical segments \\(y=0\\) \\(\\rho\\) value lag. Filled circles lag, filled black serial correlation detected.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/plot_spearman_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Spearman’s Rho Autocorrelation — plot_spearman_test","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) results <- eda_spearman_test(data) plot_spearman_test(results)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Distance Method for Distribution Selection — select_ldistance","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"Selects distribution set candidate distributions minimizing Euclidean distance theoretical L-moment ratios \\((\\tau_3, \\tau_4)\\) sample L-moment ratios \\((t_3, t_4)\\). NS-FFA: select distribution nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure). , method detrend original, nonstationary data internally using data_decomposition() function prior distribution selection.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"","code":"select_ldistance(data, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"list results distribution selection: method: \"L-distance\". decomposed_data: detrended dataset used compute L-moments. S-FFA, data argument. NS-FFA, output data_decomposition(). metrics: list L-distance metrics candidate distribution. recommendation: name distribution smallest L-distance.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"candidate distribution, method computes Euclidean distance sample L-moment ratios (\\(\\tau_3\\), \\(\\tau_4\\)) closest point theoretical distribution's L-moment curve. two-parameter distributions (Gumbel, Normal, Log-Normal), theoretical L-moment ratios compared directly sample L-moment ratios. distribution minimum distance selected. distribution fit log-transformed data (Log-Normal Log-Pearson Type III), L-moment ratios log-transformed sample used instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_ldistance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Distance Method for Distribution Selection — select_ldistance","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_ldistance(data) #> $method #> [1] \"L-distance\" #>  #> $decomposed_data #>   [1] 107.09347 111.33380  91.63655 113.57553  88.15262  96.71245 109.96926 #>   [8]  95.28064  94.79393 105.04564  89.21866 101.68685 101.67021 110.18532 #>  [15]  97.52121 106.62934  92.00706 103.19359 112.05010 106.43435 111.62498 #>  [22]  90.75030  87.44010 101.17884 112.19709  94.26940  88.09143 109.28352 #>  [29] 102.92654  84.25709  92.86221  95.25211 104.71987  86.07771 105.88744 #>  [36]  96.38812  98.28475 111.34012  85.61424  83.39046  95.75677 105.09897 #>  [43]  97.78265  96.43884  95.15888 101.54152 108.00823  92.30195 106.54658 #>  [50] 123.52926 103.63681 104.45167 104.92731  97.62798 117.74801 105.73499 #>  [57]  87.33038 106.28960 103.58367 102.87981 110.55310  99.95650 109.47916 #>  [64]  78.16191 100.11074  96.80422 110.29001 113.98892 101.32930 104.03966 #>  [71]  79.54288 116.02153 108.25178 105.00270  95.39139 100.04212  90.72727 #>  [78] 116.31053  93.67948  88.95316 107.74635 101.10127 102.14657 109.01056 #>  [85] 103.25412  93.44450  96.38329 100.96132 102.06288 106.86254 101.29751 #>  [92] 101.65906 103.89413  82.21160  96.41316  88.69358  84.49661  95.29414 #>  [99] 110.21652  95.51219 #>  #> $metrics #> $metrics$GUM #> [1] 0.2284316 #>  #> $metrics$NOR #> [1] 0.05652286 #>  #> $metrics$LNO #> [1] 0.09746302 #>  #> $metrics$GEV #> [1] 0.003714425 #>  #> $metrics$GLO #> [1] 0.06164513 #>  #> $metrics$GNO #> [1] 0.01760647 #>  #> $metrics$PE3 #> [1] 0.01621452 #>  #> $metrics$LP3 #> [1] 0.01282008 #>  #> $metrics$WEI #> [1] 0.008401841 #>  #>  #> $recommendation #> [1] \"GEV\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":null,"dir":"Reference","previous_headings":"","what":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"Selects probability distribution minimizing absolute distance theoretical L-kurtosis (\\(\\tau_4\\)) sample L-kurtosis (\\(t_4\\)). supports 3-parameter distributions. NS-FFA: select distribution nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure). , method detrend original, nonstationary data internally using data_decomposition() function prior distribution selection.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"","code":"select_lkurtosis(data, ns_years = NULL, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"list results distribution selection: method: \"L-kurtosis\". decomposed_data: detrended dataset used compute L-moments. S-FFA, data argument. NS-FFA, output data_decomposition(). metrics: list L-kurtosis metrics distribution. recommendation: Name distribution smallest L-kurtosis metric.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"method computes distance sample theoretical L-kurtosis values fixed L-skewness. three parameter distributions, shape parameter best replicates sample L-skewness determined using stats::optim().","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_lkurtosis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-Kurtosis Method for Distribution Selection — select_lkurtosis","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_lkurtosis(data) #> $method #> [1] \"L-kurtosis\" #>  #> $decomposed_data #>   [1]  93.60352 110.40346 101.88798  89.91239  95.76346  96.28633  92.88214 #>   [8] 107.66761 100.24811  91.11662 106.52933 103.43808 100.93860 110.27809 #>  [15]  98.62926 102.08267  98.57140 102.35075 103.47996  83.75346 104.88698 #>  [22]  92.63333  75.05650  88.16380  97.45606  90.25658  99.95407 126.05796 #>  [29] 105.80371 112.20856 108.26051  87.51531 112.79890 101.79532 100.69774 #>  [36]  94.59874  92.52886 106.65356 102.37895  78.83040 113.09512 101.76962 #>  [43]  87.93563 100.03565 116.09386 108.88120 100.53488  93.86536  84.78745 #>  [50] 104.43879 119.64609  88.08352 102.16198 101.59475 108.50008 103.25873 #>  [57]  74.92009 114.19124  98.33760  89.44035 102.32344  83.51807 114.32718 #>  [64] 104.70174 118.28867 101.53764  73.90265  98.52786  99.60387 114.10128 #>  [71]  94.80521  77.24338 118.15420  96.81166 120.67107  91.90085 109.02063 #>  [78] 111.29125 101.25185 101.97204 105.04875 101.59453 107.52622  95.95371 #>  [85] 105.78080 102.50401  99.46820  96.22555 104.76594  89.81868 112.29107 #>  [92]  96.09028 102.93663  75.41348  96.22050 103.39956 109.32393 100.77930 #>  [99]  98.63497  95.30955 #>  #> $metrics #> $metrics$GEV #> [1] 0.08524815 #>  #> $metrics$GLO #> [1] 0.0183023 #>  #> $metrics$GNO #> [1] 0.0625777 #>  #> $metrics$PE3 #> [1] 0.06473996 #>  #> $metrics$LP3 #> [1] 0.07141426 #>  #> $metrics$WEI #> [1] 0.07021915 #>  #>  #> $recommendation #> [1] \"GLO\" #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":null,"dir":"Reference","previous_headings":"","what":"Z-Statistic Method for Distribution Selection — select_zstatistic","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"Selects best-fit distribution comparing bias-corrected Z-statistic sample L-kurtosis (\\(\\tau_4\\)) theoretical L-moments set candidate distributions. distribution smallest absolute Z-statistic selected. NS-FFA: select distribution nonstationary model, include observation years (ns_years) nonstationary model structure (ns_structure). , method detrend original, nonstationary data internally using data_decomposition() function prior distribution selection.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"","code":"select_zstatistic(data, ns_years = NULL, ns_structure = NULL, samples = 10000L)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. samples Integer scalar. number bootstrap samples. Default 10000.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"list results distribution selection: method: \"Z-selection\". decomposed_data: detrended dataset used compute L-moments. S-FFA, data argument. NS-FFA, output data_decomposition(). metrics: List computed Z-statistics candidate distribution. recommendation: Name distribution smallest Z-statistic. reg_params: Kappa distribution parameters data. reg_bias_t4: Bias L-kurtosis bootstrap. reg_std_t4: Standard deviation L-kurtosis bootstrap. log_params: Kappa distribution parameters log-transformed data. log_bias_t4: Bias L-kurtosis bootstrap using log_params. log_std_t4: Standard deviation L-kurtosis bootstrap using log_params.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"First, method fits four-parameter Kappa distribution original log-transformed data. , bootstrapping used estimate bias variance L-kurtosis. values, along difference sample theoretical L-kurtosis, used compute Z-statistic distribution.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/select_zstatistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Z-Statistic Method for Distribution Selection — select_zstatistic","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) select_zstatistic(data) #> $method #> [1] \"Z-statistic\" #>  #> $decomposed_data #>   [1] 108.46015 107.24958 101.17380 115.17878 100.48625  93.96213  84.40808 #>   [8]  94.33495 104.48243  92.09158  84.75779 106.39260  88.13787 102.65497 #>  [15]  89.25667 111.51548 123.18602 109.23480 108.39826  95.96181  93.45547 #>  [22]  98.95412  81.54312 100.81003 105.16527 107.33136 105.38797  95.60419 #>  [29] 102.40490 104.49495  78.84581 119.48319 106.81061  91.73682 107.50677 #>  [36] 101.43231  94.81273  93.39844  99.84991 105.99509 105.41103 112.38625 #>  [43] 109.05877 108.87397 106.26721 109.05813 106.73623 101.05394  99.82153 #>  [50]  89.31985 107.93599 100.47284 121.40463  95.28911  87.67504  95.45363 #>  [57]  92.68710 104.28608  97.24062 117.85477 128.66187 115.44697  81.82928 #>  [64] 105.55251 104.54792  98.46370 101.69646 107.14534  89.82659  96.33812 #>  [71]  99.35319 103.36448 102.99345 108.05845 115.88706 101.88099  90.27166 #>  [78]  90.94695 100.33448 104.28727 101.15612  77.60913 109.71337  90.89458 #>  [85]  96.01451  90.94567  96.34790 104.43368 103.14414 101.89257  91.76334 #>  [92] 106.41107 105.11925  91.95652 109.68356 105.88925 105.38664  98.80253 #>  [99] 117.03117  99.89794 #>  #> $metrics #> $metrics$GEV #> [1] -1.573403 #>  #> $metrics$GLO #> [1] 0.1706968 #>  #> $metrics$GNO #> [1] -1.056235 #>  #> $metrics$PE3 #> [1] -1.06734 #>  #> $metrics$LP3 #> [1] -1.013761 #>  #> $metrics$WEI #> [1] -1.393823 #>  #>  #> $recommendation #> [1] \"GLO\" #>  #> $reg_params #> [1] 101.12117933   5.78188429   0.06658877  -0.78841285 #>  #> $reg_bias_t4 #> [1] 0.0002458638 #>  #> $reg_std_t4 #> [1] 0.03594635 #>  #> $log_params #> [1]  4.61509327  0.05887982  0.13361006 -0.73988063 #>  #> $log_bias_t4 #> [1] -0.0002018031 #>  #> $log_std_t4 #> [1] 0.03820009 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/sumquad_tau3tau4.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","title":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","text":"Compute L-moment Distance Kappa Distribution","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/sumquad_tau3tau4.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute L-moment Distance for Kappa Distribution — sumquad_tau3tau4","text":"","code":"sumquad_tau3tau4(k.h, t3.t4)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":null,"dir":"Reference","previous_headings":"","what":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"Computes return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using parametric bootstrap. function supports many probability models parameter estimation methods. NS-FFA: perform uncertainty quantification nonstationary model, include observation years (ns_years), nonstationary model structure (ns_structure), list years compute return level estimates confidence intervals (ns_slices).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"","code":"uncertainty_bootstrap(   data,   distribution,   method,   prior = NULL,   ns_years = NULL,   ns_structure = NULL,   ns_slices = NULL,   alpha = 0.05,   samples = 10000L,   periods = c(2, 5, 10, 20, 50, 100) )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". method Character scalar specifying estimation method. Must \"L-moments\", \"MLE\", \"GMLE\". prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. ns_slices NS-FFA : Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. samples Integer scalar. number bootstrap samples. Default 10000. periods Numeric vector used set return periods FFA. entries must greater equal 1.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"list containing following six items: method: \"Bootstrap\" distribution: distribution argument. params: fitted parameters. ns_structure: ns_structure argument, given. ns_slices: ns_slices argument, given. ci: dataframe containing confidence intervals (S-FFA ) ci_list: list dataframes containing confidence intervals (NS-FFA ). dataframe(s) ci ci_list four columns: estimates: Estimated quantiles return period. lower: Lower bound confidence interval return period. upper: Upper bound confidence interval return period. periods: periods argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"Bootstrap samples obtained fitted distribution via inverse transform sampling. bootstrapped sample, parameters re-estimated based method argument. , bootstrapped parameters used compute new set bootstrapped quantiles. Confidence intervals obtained empirical nonexceedance probabilities bootstrapped quantiles.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"parametric bootstrap known give unreasonably wide confidence intervals small datasets. method yields confidence interval least 5 times greater magnitude return levels, return error recommend uncertainty_rfpl() uncertainty_rfgpl() alternatives.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_bootstrap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parametric Bootstrap Uncertainty Quantification — uncertainty_bootstrap","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_bootstrap(data, \"WEI\", \"L-moments\") #> $method #> [1] \"Bootstrap\" #>  #> $distribution #> [1] \"WEI\" #>  #> $params #> [1] 79.289610 24.235689  2.072522 #>  #> $ns_structure #> NULL #>  #> $ns_slices #> NULL #>  #> $ci #>   periods estimates     lower    upper #> 1       2  99.59695  97.19585 102.0640 #> 2       5 109.78095 106.85013 112.7648 #> 3      10 115.53275 111.92003 119.3044 #> 4      20 120.43962 115.92648 125.2442 #> 5      50 126.09451 120.30734 132.4924 #> 6     100 129.92731 123.15385 137.6791 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"Calculates return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using regula-falsi generalized profile likelihood root‐finding method GEV distribution. NS-FFA: perform uncertainty quantification nonstationary model, include observation years (ns_years), nonstationary model structure (ns_structure), list years compute return level estimates confidence intervals (ns_slices).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"","code":"uncertainty_rfgpl(   data,   prior,   ns_years = NULL,   ns_structure = NULL,   ns_slices = NULL,   alpha = 0.05,   periods = c(2, 5, 10, 20, 50, 100),   tolerance = 0.01 )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. ns_slices NS-FFA : Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. periods Numeric vector used set return periods FFA. entries must greater equal 1. tolerance log-likelihood tolerance Regula-Falsi convergence (default 0.01).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"list containing following six items: method: \"RFGPL\" distribution: \"GEV\" params: fitted parameters. ns_structure: ns_structure argument, given. ns_slices: ns_slices argument, given. ci: dataframe containing confidence intervals (S-FFA ) ci_list: list dataframes containing confidence intervals (NS-FFA ). dataframe(s) ci ci_list four columns: estimates: Estimated quantiles return period. lower: Lower bound confidence interval return period. upper: Upper bound confidence interval return period. periods: periods argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"Uses fit_gmle() obtain maximum generalized log‐likelihood. Defines objective function \\(f(y_p, p)\\) reparameterizing generalized log-likelihood. Iteratively brackets root rescaling initial guesses 0.05 \\(f(y_p, p)\\) changes sign. Uses regula-falsi method solve \\(f(y_p, p) = 0\\) return period probability. Returns lower upper confidence bounds significance level alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"RFGPL uncertainty quantification can numerically unstable datasets. function encounters issue, return error recommend uncertainty_bootstrap() instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151 Vidrio-Sahagún, C.T., , J. & Pietroniro, . Multi-distribution regula-falsi profile likelihood method nonstationary hydrological frequency analysis. Stochastic Environmental Research Risk Assessment 38, 843–867 (2024). doi:10.1007/s00477-023-02603-0","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfgpl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regula-Falsi Generalized Profile Likelihood Uncertainty Quantification — uncertainty_rfgpl","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_rfgpl(data, c(6, 9)) #> $method #> [1] \"RFGPL\" #>  #> $distribution #> [1] \"GEV\" #>  #> $params #> [1] 94.8057579 12.7161970  0.1017774 #>  #> $ns_structure #> NULL #>  #> $ns_slices #> NULL #>  #> $ci #>   periods estimates     lower    upper #> 1       2  99.55443  96.63859 102.7040 #> 2       5 115.41217 111.00705 120.5315 #> 3      10 126.96414 121.19155 133.8164 #> 4      20 138.90570 131.57452 147.7554 #> 5      50 155.72063 145.92495 167.6549 #> 6     100 169.40853 157.41913 184.1089 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":null,"dir":"Reference","previous_headings":"","what":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"Calculates return level estimates confidence intervals specified return periods (defaults 2, 5, 10, 20, 50, 100 years) using regula-falsi profile likelihood root‐finding method. NS-FFA: perform uncertainty quantification nonstationary model, include observation years (ns_years), nonstationary model structure (ns_structure), list years compute return level estimates confidence intervals (ns_slices).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"","code":"uncertainty_rfpl(   data,   distribution,   ns_years = NULL,   ns_structure = NULL,   ns_slices = NULL,   alpha = 0.05,   periods = c(2, 5, 10, 20, 50, 100),   tolerance = 0.01 )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend. ns_slices NS-FFA : Numeric vector specifying years evaluate return levels confidence intervals nonstationary probability distribution. ns_slices elements ns_years argument. alpha Numeric scalar \\([0.01, 0.1]\\). significance level confidence intervals hypothesis tests. Default 0.05. periods Numeric vector used set return periods FFA. entries must greater equal 1. tolerance log-likelihood tolerance Regula-Falsi convergence (default 0.01).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"list containing following four items: method: \"RFPL\" distribution: distribution argument. params: fitted parameters. ns_structure: ns_structure argument, given. ns_slices: ns_slices argument, given. ci: dataframe containing confidence intervals (S-FFA ) ci_list: list dataframes containing confidence intervals (NS-FFA ). dataframe(s) ci ci_list four columns: estimates: Estimated quantiles return period. lower: Lower bound confidence interval return period. upper: Upper bound confidence interval return period. periods: periods argument.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"Uses fit_mle() obtain maximum log‐likelihood. Defines objective function \\(f(y_p, p)\\) reparameterizing log-likelihood. Iteratively brackets root rescaling initial guesses 0.05 \\(f(y_p, p)\\) changes sign. Uses regula-falsi method solve \\(f(y_p, p) = 0\\) return period probability. Returns lower upper confidence bounds significance level alpha.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"RFPL uncertainty quantification can numerically unstable datasets. function encounters issue, return error recommend using parametric bootstrap method uncertainty_bootstrap() instead.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"Vidrio-Sahagún, C.T., , J. Enhanced profile likelihood method nonstationary hydrological frequency analysis, Advances Water Resources 161, 10451 (2022). doi:10.1016/j.advwatres.2022.104151 Vidrio-Sahagún, C.T., , J. & Pietroniro, . Multi-distribution regula-falsi profile likelihood method nonstationary hydrological frequency analysis. Stochastic Environmental Research Risk Assessment 38, 843–867 (2024). doi:10.1007/s00477-023-02603-0","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/uncertainty_rfpl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regula-Falsi Profile Likelihood Uncertainty Quantification — uncertainty_rfpl","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) uncertainty_rfpl(data, \"GLO\") #> $method #> [1] \"RFPL\" #>  #> $distribution #> [1] \"GLO\" #>  #> $params #> [1] 101.9869489   5.9714069   0.1510906 #>  #> $ns_structure #> NULL #>  #> $ns_slices #> NULL #>  #> $ci #>   periods estimates     lower    upper #> 1       2  101.9869  99.73336 104.1409 #> 2       5  109.4556 107.47229 111.5811 #> 3      10  113.1519 111.08046 116.1748 #> 4      20  116.1792 113.76140 120.7106 #> 5      50  119.5574 116.40696 126.6877 #> 6     100  121.7703 117.93577 131.2453 #>"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Functions for Probability Models — utils_cdf","title":"Cumulative Distribution Functions for Probability Models — utils_cdf","text":"Compute probabilities quantiles stationary nonstationary models. NS-FFA: compute probabilities nonstationary model, specify time slice (ns_slice) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Functions for Probability Models — utils_cdf","text":"","code":"utils_cdf(q, distribution, params, ns_slice = 0, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Functions for Probability Models — utils_cdf","text":"q Numeric vector quantiles missing values. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. ns_slice NS-FFA : Numeric scalar specifying year evaluate  quantiles nonstationary probability distribution. ns_slice element ns_years argument. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_cdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Distribution Functions for Probability Models — utils_cdf","text":"numeric vector quantiles length q.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_cdf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution Functions for Probability Models — utils_cdf","text":"","code":"q <- seq(1, 10) params <- c(1, 1, 1) utils_cdf(q, \"GEV\", params) #>  [1] 0.3678794 0.6065307 0.7165313 0.7788008 0.8187308 0.8464817 0.8668779 #>  [8] 0.8824969 0.8948393 0.9048374"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"Computes generalized log-likelihood stationary nonstationary variants Generalized Extreme Value (GEV) distribution geophysical (Beta) prior distribution shape parameter (Martins Stedinger, 2000). NS-FFA: compute generalized log-likelihood nonstationary probability model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"","code":"utils_generalized_likelihood(   data,   params,   prior,   ns_years = NULL,   ns_structure = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. prior Numeric vector length 2. Specifies parameters Beta prior shape parameter \\(\\kappa\\). ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"Numeric scalar. generalized log-likelihood value.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"generalized log-likelihood defined sum (1) log-likelihood (2) log-density Beta prior parameters \\((p, q)\\). contribution prior : $$\\log \\pi(\\kappa) = (p-1) \\log(0.5-\\kappa) + (q-1) \\log(0.5+\\kappa) - \\log (\\beta(p, q))$$","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"El Adlouni, S., Ouarda, T.B.M.J., Zhang, X., Roy, R., Bobee, B., 2007. Generalized maximum likelihood estimators nonstationary generalized extreme value model. Water Resources Research 43 (3), 1–13. doi:10.1029/2005WR004545 Martins, E. S., Stedinger, J. R. (2000). Generalized maximum-likelihood generalized extreme-value quantile estimators hydrologic data. Water Resources Research, 36(3), 737–744. doi:10.1029/1999WR900330","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_generalized_likelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Log-Likelihood Functions for GEV Models — utils_generalized_likelihood","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 10, 0.1) prior <- c(1, 1)  # Compute the generalized log-likelihood utils_generalized_likelihood(data, params, prior) #> [1] -411.0723"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"Compute log-likelihood stationary nonstationary probability models. NS-FFA: compute log-likelihood nonstationary probability model, include observation years (ns_years) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"","code":"utils_log_likelihood(   data,   distribution,   params,   ns_years = NULL,   ns_structure = NULL )"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. ns_years NS-FFA : Numeric vector observation years corresponding data. Must length data strictly increasing. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"Numeric scalar. log-likelihood value.","code":""},{"path":[]},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_log_likelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood Functions for Probability Models — utils_log_likelihood","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) params <- c(100, 1, 10) ns_years <- seq(from = 1901, to = 2000) ns_structure <- list(location = TRUE, scale = FALSE)  # Compute the log-likelihood utils_log_likelihood(data, \"NOR\", params, ns_years, ns_structure) #> [1] -384.815"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Functions for Probability Models — utils_quantiles","title":"Quantile Functions for Probability Models — utils_quantiles","text":"Compute quantiles stationary nonstationary probability models. NS-FFA: compute quantiles nonstationary probability model, specify time slice (ns_slice) nonstationary model structure (ns_structure).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Functions for Probability Models — utils_quantiles","text":"","code":"utils_quantiles(p, distribution, params, ns_slice = 0, ns_structure = NULL)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Functions for Probability Models — utils_quantiles","text":"p Numeric vector probabilities 0 1 missing values. distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure. ns_slice NS-FFA : Numeric scalar specifying year evaluate  quantiles nonstationary probability distribution. ns_slice element ns_years argument. ns_structure NS-FFA : Named list indicating distribution parameters modeled nonstationary. Must contain two logical scalars: location: TRUE, location parameter linear temporal trend. scale: TRUE, scale parameter linear temporal trend.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Functions for Probability Models — utils_quantiles","text":"numeric vector quantiles length p.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Functions for Probability Models — utils_quantiles","text":"","code":"p <- runif(n = 100) params <- c(1, 1, 1) utils_quantiles(p, \"GEV\", params) #>   [1]   0.7449720   0.8006997   6.4605130   4.2354795   1.7069833   3.5726220 #>   [7]   0.7457033   4.4277932  13.9344347   1.0814305   0.8106945   1.8309980 #>  [13]  45.1187015   1.2136530   2.4485925   0.1823871  44.6464904  42.0391697 #>  [19]  40.0788151   0.7526790   0.9474955   0.6083237   0.7199473   0.9669532 #>  [25]   7.7998405   2.4265620   0.2261922   0.3723459  21.6732308 395.9278391 #>  [31]   1.9716244   3.6538059   4.9917506   0.5964725   1.9662502   0.5232789 #>  [37]   8.7803652   7.7422978   1.0784973   2.3520442  52.2756147   0.4447122 #>  [43]   1.7195182   3.6610685   8.8129367   0.4661800   0.4225514   0.4239579 #>  [49]   1.0327364   0.3045034   1.8240031   2.3203218   2.0867131   1.8761336 #>  [55]   9.5386837   1.7270419   0.5286169   0.1986658   4.6216791   2.3066335 #>  [61]   3.1784872   3.4942847  11.6457782   1.9462189   2.3734740   0.2422027 #>  [67]   1.6340084   2.3064114   0.5521217   4.2012845   0.2602349   2.1994602 #>  [73]   1.8434039   3.1044798   2.6432254   0.5536387   1.2007635   0.5671011 #>  [79]   8.4425541   0.5895482   0.7729137   5.2514130   0.9667564   1.9995614 #>  [85]   0.2853811   0.6014948   0.4700584   0.8759660   0.7907561   0.8095502 #>  [91]   1.1267387   0.9088418   4.9260793   0.3288626   0.8418634   0.3126978 #>  [97]  10.9972492   0.4174596   0.2256656   2.7560965"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample L-moments — utils_sample_lmoments","title":"Sample L-moments — utils_sample_lmoments","text":"Computes first four sample L-moments L-moment ratios numeric vector data. L-moments linear combinations order statistics provide robust alternatives conventional moments, advantages parameter estimation heavy-tailed skewed distributions.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample L-moments — utils_sample_lmoments","text":"","code":"utils_sample_lmoments(data)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample L-moments — utils_sample_lmoments","text":"data Numeric vector observed annual maximum series values. Must strictly positive, finite, missing.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample L-moments — utils_sample_lmoments","text":"numeric vector containing first four sample L-moments L-moment ratios: \\(l_1\\): L-mean \\(l_2\\): L-variance \\(t_3\\): L-skewness \\(t_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sample L-moments — utils_sample_lmoments","text":"Given probability weighted moments \\(\\beta_0, \\beta_1, \\beta_2, \\beta_3\\), first four sample L-moments : \\(l_1 = \\beta_0\\) \\(l_2 = 2\\beta_1 - \\beta_0\\) \\(l_3 = 6\\beta_2 - 6\\beta_1 + \\beta_0\\) \\(l_4 = 20\\beta_3 - 30\\beta_2 + 12\\beta_1 - \\beta_0\\) , sample L-skewness \\(t_3 = l_3 / l_2\\) sample L-kurtosis \\(t_4 = l_4 / l_2\\).","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample L-moments — utils_sample_lmoments","text":"Hosking, J. R. M. (1990). L-moments: Analysis estimation distributions using linear combinations order statistics. Journal Royal Statistical Society: Series B (Methodological), 52(1), 105–124.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_sample_lmoments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample L-moments — utils_sample_lmoments","text":"","code":"data <- rnorm(n = 100, mean = 100, sd = 10) utils_sample_lmoments(data) #> [1] 101.05510033   5.89867986   0.03534039   0.14664387"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":null,"dir":"Reference","previous_headings":"","what":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"Computes first four L-moments L-moment ratios stationary probability models.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"","code":"utils_theoretical_lmoments(distribution, params)"},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"distribution three-character code indicating distribution family. Must \"GUM\", \"\", \"LNO\", \"GEV\", \"GLO\", \"GNO\", \"PE3\", \"LP3\", \"WEI\". params Numeric vector distribution parameters, order (location, scale, shape). length must 2 5, depending specified distribution structure.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"numeric vector four elements: \\(\\lambda_1\\): L-mean \\(\\lambda_2\\): L-variance \\(\\tau_3\\): L-skewness \\(\\tau_4\\): L-kurtosis","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"distributions \"GUM\", \"\", \"GEV\", \"GLO\", \"WEI\" closed-form solutions L-moments L-moment ratios terms parameters. distributions \"GNO\" \"PE3\" use rational approximations L-moment ratios Hosking (1997). L-moments ratios \"LNO\" \"LP3\" distributions compared log-transformed data thus identical \"\" \"PE3\" distributions respectively.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"Hosking, J.R.M. & Wallis, J.R., 1997. Regional frequency analysis: approach based L-Moments. Cambridge University Press, New York, USA.","code":""},{"path":"https://rileywheadon.github.io/ffa-package/reference/utils_theoretical_lmoments.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Theoretical L-moments of Probability Distributions — utils_theoretical_lmoments","text":"","code":"utils_theoretical_lmoments(\"GEV\", c(1, 1, 1)) #> [1]  1.0000000  0.5000000 -0.3333333  0.1666667"}]
